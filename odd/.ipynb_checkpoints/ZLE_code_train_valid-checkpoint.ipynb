{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xXp-L947DlL"
   },
   "source": [
    "#Distance Estimator\n",
    "To estimate the real distance(unit: meter) of the object\n",
    "\n",
    "__Input__: Bounding box coordinates(xmin, ymin, xmax, ymax)   \n",
    "__Output__: 3D location z of carmera coordinates(z_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LiXtU2475cb"
   },
   "source": [
    "## Load Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J4GISwk4884Q"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import category_encoders as ce\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from custom_datasets import CustomDataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./weights', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJxQzId_79SS"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../datasets/kitti_train_2.csv')\n",
    "df_valid = pd.read_csv('../datasets/kitti_valid_2.csv')\n",
    "df_test = pd.read_csv('../datasets/kitti_test_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zloc 조건\n",
    "#df_train = df_train[df_train['zloc']<90]\n",
    "#df_valid = df_valid[df_valid['zloc']<90]\n",
    "#df_test = df_test[df_test['zloc']<90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['person', 'car', 'truck', 'train', 'bicycle', 'Misc'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encoding\n",
    "class_dummy = pd.get_dummies(df_train['class'])\n",
    "df_train = pd.concat([df_train, class_dummy], axis=1)\n",
    "\n",
    "class_dummy = pd.get_dummies(df_valid['class'])\n",
    "df_valid = pd.concat([df_valid, class_dummy], axis=1)\n",
    "\n",
    "class_dummy = pd.get_dummies(df_test['class'])\n",
    "df_test = pd.concat([df_test, class_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrVd\n",
    "#df_train = pd.concat([df_train, df_valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_label = le.fit_transform(df_train['class'])\n",
    "df_train['class_num'] = train_label\n",
    "\n",
    "valid_label = le.fit_transform(df_valid['class'])\n",
    "df_valid['class_num'] = valid_label\n",
    "\n",
    "test_label = le.fit_transform(df_test['class'])\n",
    "df_test['class_num'] = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21037 entries, 0 to 21036\n",
      "Data columns (total 25 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   filename         21037 non-null  object \n",
      " 1   class            21037 non-null  object \n",
      " 2   xmin             21037 non-null  float64\n",
      " 3   ymin             21037 non-null  float64\n",
      " 4   xmax             21037 non-null  float64\n",
      " 5   ymax             21037 non-null  float64\n",
      " 6   angle            21037 non-null  float64\n",
      " 7   zloc             21037 non-null  float64\n",
      " 8   weather          21037 non-null  object \n",
      " 9   depth_y          21037 non-null  int64  \n",
      " 10  depth_x          21037 non-null  int64  \n",
      " 11  depth_mean       21037 non-null  float64\n",
      " 12  depth_min        21037 non-null  float64\n",
      " 13  depth_median     21037 non-null  float64\n",
      " 14  depth_max        21037 non-null  float64\n",
      " 15  depth_mean_trim  21037 non-null  float64\n",
      " 16  width            21037 non-null  float64\n",
      " 17  height           21037 non-null  float64\n",
      " 18  Misc             21037 non-null  uint8  \n",
      " 19  bicycle          21037 non-null  uint8  \n",
      " 20  car              21037 non-null  uint8  \n",
      " 21  person           21037 non-null  uint8  \n",
      " 22  train            21037 non-null  uint8  \n",
      " 23  truck            21037 non-null  uint8  \n",
      " 24  class_num        21037 non-null  int32  \n",
      "dtypes: float64(13), int32(1), int64(2), object(3), uint8(6)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = ['xmin','ymin','xmax','ymax', 'width', 'height','depth_mean_trim', 'depth_mean','Misc', 'bicycle', 'car', 'person', 'train', 'truck']\n",
    "val_length = len(variable)\n",
    "batch_sz = 32\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# train\n",
    "train_dataset = CustomDataset(df_train, variable, scaler=True, train=True, onehot=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_sz, shuffle=True)\n",
    "# train_sclaer\n",
    "scaler_train = train_dataset.scaler\n",
    "\n",
    "# valid\n",
    "valid_dataset = CustomDataset(df_valid, variable, True, train=scaler_train, onehot=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_sz, shuffle=True)\n",
    "\n",
    "# test\n",
    "test_dataset = CustomDataset(df_test, variable, True, train=scaler_train, onehot=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=len(df_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_length # 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -4.6205e-01,  6.7629e-01, -4.7325e-01,  4.5346e-01, -2.9326e-02,\n",
      "          1.9829e-01, -7.5977e-01, -7.2957e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          1.1102e+00,  4.8830e-01,  2.3656e+00,  2.3567e+00,  3.8905e+00,\n",
      "          2.2725e+00, -1.2963e+00, -1.3673e+00, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          2.5721e-01, -3.9147e-01,  2.2356e-01, -8.5198e-01, -1.0767e-01,\n",
      "         -7.3332e-01,  1.1954e+00,  1.0117e+00, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          1.9989e-01,  2.6757e-01, -2.9289e-03, -5.4604e-01, -6.3304e-01,\n",
      "         -6.8275e-01,  2.9443e-01,  2.4991e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.9301e-01, -6.6896e-01, -2.8545e-01, -6.2362e-01, -2.8516e-01,\n",
      "         -3.7983e-01, -2.7144e-01, -2.0604e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.8859e+00,  9.5828e-01, -1.5550e+00,  8.2757e-01,  1.0515e+00,\n",
      "          4.7511e-01, -9.3024e-01, -9.8064e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          2.9162e-01, -5.9587e-02,  7.8060e-02, -8.4082e-01, -6.6752e-01,\n",
      "         -8.5781e-01,  1.2564e+00,  1.2614e+00, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          3.8211e-01, -2.0954e-01,  1.2000e-01, -8.6968e-01, -8.1956e-01,\n",
      "         -8.2655e-01,  1.5119e+00,  1.5928e+00, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          2.5013e+00,  1.2333e+00,  2.3693e+00,  1.2002e+00, -4.4019e-01,\n",
      "          7.5325e-01, -1.1635e+00, -1.2612e+00, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.8824e+00,  3.9887e+00, -1.4018e+00,  2.3777e+00,  1.5167e+00,\n",
      "          8.5806e-01, -1.3471e+00, -1.4414e+00, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          3.7853e-01, -2.2230e+00,  2.9638e-01, -5.5636e-01, -2.5993e-01,\n",
      "          3.2844e-01,  2.0297e-01,  1.9489e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -2.2911e-01, -7.1360e-02, -3.5553e-01, -7.3636e-01, -3.9041e-01,\n",
      "         -7.4337e-01,  4.4457e-01,  4.9204e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.8088e+00,  9.1420e-01, -1.7268e+00, -4.5153e-02,  2.7646e-01,\n",
      "         -4.2253e-01,  3.5370e-02,  3.8213e-02, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -9.0464e-01, -3.1538e-01, -8.7018e-01, -7.7148e-01,  1.1790e-01,\n",
      "         -6.8007e-01,  5.7410e-01,  5.5792e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          1.0940e+00, -1.3891e+00,  9.9469e-01,  1.4377e+00, -3.2178e-01,\n",
      "          2.0785e+00, -1.0891e+00, -1.1008e+00,  2.6234e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          3.1258e-01, -7.2643e-01,  2.5754e-02, -5.4767e-01, -8.9558e-01,\n",
      "         -2.7656e-01, -1.2405e-01, -2.7224e-03,  2.6234e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.6781e+00,  1.4447e+00, -1.1142e+00,  1.6618e+00,  1.7731e+00,\n",
      "          1.1508e+00, -1.1078e+00, -1.2037e+00, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.7994e-01,  3.4751e-01, -4.8508e-01, -4.7907e-01, -3.2241e-01,\n",
      "         -6.4528e-01,  5.5493e-01,  5.3502e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -4.2360e-01,  3.4710e-01, -6.1983e-01, -6.0075e-01, -6.0517e-01,\n",
      "         -7.7279e-01,  8.0258e-01,  8.4210e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -4.5049e-02,  2.3934e-01, -3.3443e-01, -7.9124e-01, -8.9931e-01,\n",
      "         -9.2845e-01,  2.0399e+00,  1.9550e+00, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.8842e+00,  6.9572e-01, -1.3750e+00,  2.3643e+00,  1.6057e+00,\n",
      "          2.1953e+00, -1.2178e+00, -1.3120e+00, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.8844e+00,  4.5555e-01, -1.6098e+00,  3.5911e-01,  8.7628e-01,\n",
      "          1.8987e-01, -6.8504e-01, -7.5045e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.2331e+00,  1.2161e+00, -1.0380e+00,  4.9800e-01,  6.2113e-01,\n",
      "          2.3511e-02, -6.1057e-01, -6.9752e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -7.3712e-01,  1.4079e-01, -9.8462e-01, -8.9846e-01, -7.6084e-01,\n",
      "         -1.0005e+00,  1.9982e+00,  1.9265e+00, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.8855e+00,  7.3932e-01, -1.9110e+00, -2.2989e-01, -5.7064e-02,\n",
      "         -5.4461e-01,  8.7698e-02, -1.9430e-02, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -6.2695e-01,  3.7976e-01, -8.0540e-01, -5.2893e-01, -5.4744e-01,\n",
      "         -7.1083e-01,  7.6237e-01,  6.7724e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.3170e+00,  9.6738e-01, -6.4652e-01,  2.0684e+00,  2.1006e+00,\n",
      "          1.7734e+00, -1.1720e+00, -1.1220e+00, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          8.1445e-02,  4.5800e-01, -1.6127e-01, -5.6780e-01, -7.5569e-01,\n",
      "         -7.8372e-01,  1.1606e+00,  9.7121e-01, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          1.6823e+00, -7.6154e-01,  1.6275e+00,  1.0406e+00, -1.9019e-01,\n",
      "          1.4044e+00, -1.1346e+00, -1.2408e+00,  2.6234e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.6390e-02,  3.9704e-01, -1.7915e-01, -3.4538e-01, -4.4349e-01,\n",
      "         -5.2533e-01,  3.0776e-02, -1.5526e-02, -3.8119e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.1786e+00,  9.4207e-02, -1.3883e+00,  6.5700e-01, -6.3807e-01,\n",
      "          6.5072e-01, -8.7526e-01, -8.8464e-01,  2.6234e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          1.0425e-01,  6.8998e-02, -1.4814e-01, -9.3121e-01, -7.8604e-01,\n",
      "         -1.0054e+00,  2.1793e+00,  2.0661e+00, -3.8119e-01]])\n",
      "torch.Size([32, 14])\n",
      "tensor([[14.6000],\n",
      "        [ 5.6700],\n",
      "        [41.0700],\n",
      "        [32.0900],\n",
      "        [29.2700],\n",
      "        [12.2000],\n",
      "        [47.1300],\n",
      "        [45.1100],\n",
      "        [ 7.7100],\n",
      "        [ 3.2300],\n",
      "        [33.0900],\n",
      "        [43.3600],\n",
      "        [26.5600],\n",
      "        [39.2200],\n",
      "        [ 7.1900],\n",
      "        [23.9100],\n",
      "        [ 9.2500],\n",
      "        [33.1900],\n",
      "        [39.8300],\n",
      "        [59.0600],\n",
      "        [ 6.6300],\n",
      "        [14.6400],\n",
      "        [15.6700],\n",
      "        [54.4500],\n",
      "        [26.6700],\n",
      "        [38.4200],\n",
      "        [ 7.8300],\n",
      "        [45.5200],\n",
      "        [ 8.3500],\n",
      "        [26.6400],\n",
      "        [11.6400],\n",
      "        [63.0500]])\n"
     ]
    }
   ],
   "source": [
    "# look dataset\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    print(batch[0])\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_18WIN49vj6"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6SqWrYRLCdaO"
   },
   "outputs": [],
   "source": [
    "class Zloc_Estimaotor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True, bidirectional=False)\n",
    "        \n",
    "        #Layer\n",
    "        layersize=[512, 256, 128, 64]\n",
    "        layerlist= []\n",
    "        n_in=hidden_dim\n",
    "        for i in layersize:\n",
    "            layerlist.append(nn.Linear(n_in,i))\n",
    "            layerlist.append(nn.ReLU())\n",
    "            #layerlist.append(nn.BatchNorm1d(i))\n",
    "            #layerlist.append(nn.Dropout(0.2))\n",
    "            n_in=i           \n",
    "        layerlist.append(nn.Linear(layersize[-1],1))\n",
    "        #layerlist.append(nn.Sigmoid())\n",
    "        \n",
    "        self.fc=nn.Sequential(*layerlist)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, hn = self.rnn(x)\n",
    "        output = self.fc(out[:,-1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zloc_Estimaotor_s(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Layer\n",
    "        layersize=[32,64,128,256,128,64,32]\n",
    "        layerlist= []\n",
    "        n_in=input_dim\n",
    "        for i in layersize:\n",
    "            layerlist.append(nn.Linear(n_in,i))\n",
    "            layerlist.append(nn.HardTanh())\n",
    "            #layerlist.append(nn.BatchNorm1d(i))\n",
    "            #layerlist.append(nn.Dropout(0.2))\n",
    "            n_in=i           \n",
    "        layerlist.append(nn.Linear(layersize[-1],1))\n",
    "        #layerlist.append(nn.Sigmoid())\n",
    "        \n",
    "        self.fc=nn.Sequential(*layerlist)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #out, hn = self.rnn(x)\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make  variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zloc_Estimaotor(\n",
       "  (rnn): LSTM(14, 756, num_layers=3, batch_first=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=756, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.init as init\n",
    "#def weight_init(m):\n",
    "#    if isinstance(m, nn.Linear): # nn.Linear에 있는 가중치에만 적용\n",
    "#        init.kaiming_uniform_(m.weight.data) # He initialization\n",
    "\n",
    "# variable \n",
    "input_dim = val_length\n",
    "hidden_dim = 756\n",
    "layer_dim = 3\n",
    "        \n",
    "model = Zloc_Estimaotor(input_dim, hidden_dim, layer_dim)\n",
    "#model = Zloc_Estimaotor_s(input_dim)\n",
    "#model.apply(weight_init)\n",
    "loss_fn = nn.MSELoss()\n",
    "#loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.5,\n",
    "                                                       patience = 10,\n",
    "                                                       mode='min', # 우리는 낮아지는 값을 기대\n",
    "                                                       verbose=True,\n",
    "                                                       min_lr=1e-6)\n",
    "from early_stopping import EarlyStopping\n",
    "early_stopping = EarlyStopping(40, verbose=True)   \n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12051329"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train parameters\n",
    "def count_parameter(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameter(model) # 5686657"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7pqhZ4a9y99"
   },
   "source": [
    "## Make Train, Valid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, idx_interval):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_rmse = 0\n",
    "    \n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inp = batch[0].reshape(len(batch[0]),1,-1)\n",
    "        \n",
    "        prediction = model(inp.to(device))\n",
    "        loss = loss_fn(prediction, batch[1].to(device)).cpu()\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        if idx % idx_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}] \\t Train Loss(MSE): {:.4f} \\t Train RMSE: {:.4f}\".format(epoch, batch_sz*(idx+1), \\\n",
    "                                                                            len(train_dataloader)*batch_sz, \\\n",
    "                                                                            loss.item(), np.sqrt(loss.item())))\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_rmse = np.sqrt(train_loss)\n",
    "        \n",
    "    return train_loss, train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    valid_loss = 0\n",
    "    valid_rmse = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(valid_dataloader):\n",
    "            inp = batch[0].reshape(len(batch[0]),1,-1)\n",
    "            predictions = model(inp.to(device))\n",
    "            loss = loss_fn(predictions, batch[1].to(device)).cpu()\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "    valid_loss /= len(valid_dataloader)\n",
    "    valid_rmse = np.sqrt(valid_loss)\n",
    "    \n",
    "    return valid_loss,valid_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [32/21056] \t Train Loss(MSE): 18.5732 \t Train RMSE: 4.3097\n",
      "Train Epoch: 1 [6432/21056] \t Train Loss(MSE): 2.7765 \t Train RMSE: 1.6663\n",
      "Train Epoch: 1 [12832/21056] \t Train Loss(MSE): 6.2368 \t Train RMSE: 2.4974\n",
      "Train Epoch: 1 [19232/21056] \t Train Loss(MSE): 2.7052 \t Train RMSE: 1.6448\n",
      "[Epoch: 1 \t Valid MSE: 3.9150 \t Valid RMSE: 1.9786]\n",
      "[Epoch: 1 \t Train MSE: 3.3271 \t Train RMSE: 1.8240]\n",
      "Validation loss decreased (inf --> 1.978627).  Saving model ...\n",
      "Train Epoch: 2 [32/21056] \t Train Loss(MSE): 4.8492 \t Train RMSE: 2.2021\n",
      "Train Epoch: 2 [6432/21056] \t Train Loss(MSE): 2.2896 \t Train RMSE: 1.5131\n",
      "Train Epoch: 2 [12832/21056] \t Train Loss(MSE): 2.8419 \t Train RMSE: 1.6858\n",
      "Train Epoch: 2 [19232/21056] \t Train Loss(MSE): 2.0593 \t Train RMSE: 1.4350\n",
      "[Epoch: 2 \t Valid MSE: 2.2015 \t Valid RMSE: 1.4837]\n",
      "[Epoch: 2 \t Train MSE: 2.6982 \t Train RMSE: 1.6426]\n",
      "Validation loss decreased (1.978627 --> 1.483729).  Saving model ...\n",
      "Train Epoch: 3 [32/21056] \t Train Loss(MSE): 1.5015 \t Train RMSE: 1.2254\n",
      "Train Epoch: 3 [6432/21056] \t Train Loss(MSE): 2.0494 \t Train RMSE: 1.4316\n",
      "Train Epoch: 3 [12832/21056] \t Train Loss(MSE): 2.3174 \t Train RMSE: 1.5223\n",
      "Train Epoch: 3 [19232/21056] \t Train Loss(MSE): 2.4278 \t Train RMSE: 1.5581\n",
      "[Epoch: 3 \t Valid MSE: 2.5208 \t Valid RMSE: 1.5877]\n",
      "[Epoch: 3 \t Train MSE: 2.4670 \t Train RMSE: 1.5707]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 4 [32/21056] \t Train Loss(MSE): 2.1397 \t Train RMSE: 1.4628\n",
      "Train Epoch: 4 [6432/21056] \t Train Loss(MSE): 2.4421 \t Train RMSE: 1.5627\n",
      "Train Epoch: 4 [12832/21056] \t Train Loss(MSE): 2.3710 \t Train RMSE: 1.5398\n",
      "Train Epoch: 4 [19232/21056] \t Train Loss(MSE): 1.5352 \t Train RMSE: 1.2390\n",
      "[Epoch: 4 \t Valid MSE: 2.1640 \t Valid RMSE: 1.4711]\n",
      "[Epoch: 4 \t Train MSE: 2.3410 \t Train RMSE: 1.5300]\n",
      "Validation loss decreased (1.483729 --> 1.471054).  Saving model ...\n",
      "Train Epoch: 5 [32/21056] \t Train Loss(MSE): 1.7879 \t Train RMSE: 1.3371\n",
      "Train Epoch: 5 [6432/21056] \t Train Loss(MSE): 2.8653 \t Train RMSE: 1.6927\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13168/3726719781.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEpoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtrain_mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mvalid_mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13168/1457608073.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, idx_interval)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13168/2762956455.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py38\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py38\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py38\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Epoch = 500\n",
    "best_rmse = 99999\n",
    "best_train_rmse = 99999\n",
    "\n",
    "train_mse_list = []\n",
    "train_rmse_list = []\n",
    "valid_mse_list = []\n",
    "valid_rmse_list = []\n",
    "\n",
    "for epoch in range(1,(Epoch+1)):\n",
    "    train_mse, train_rmse = train(model, train_dataloader, 200)\n",
    "    valid_mse, valid_rmse = evaluate(model, valid_dataloader)\n",
    "\n",
    "    print(\"[Epoch: {} \\t Valid MSE: {:.4f} \\t Valid RMSE: {:.4f}]\".format(epoch, valid_mse, valid_rmse))\n",
    "    print(\"[Epoch: {} \\t Train MSE: {:.4f} \\t Train RMSE: {:.4f}]\".format(epoch, train_mse, train_rmse))\n",
    "    \n",
    "    scheduler.step(valid_mse)       \n",
    "    # Save model\n",
    "    if valid_rmse < best_rmse:\n",
    "        path = \"./weights/ODD_LSTM_512_R2.pth\"\n",
    "        torch.save(model.state_dict(), path) # 모델의 가중치만 저장 구조는 저장 x..?\n",
    "        best_rmse = valid_rmse\n",
    "        best_train_rmse = train_rmse\n",
    "        \n",
    "    train_mse_list.append(train_mse)\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    valid_mse_list.append(valid_mse)\n",
    "    valid_rmse_list.append(valid_rmse)\n",
    "    \n",
    "    early_stopping(valid_rmse, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Valid best:',best_rmse)\n",
    "print('Train best:',best_train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(train_mse_list, ls='-', color='blue', label='train')\n",
    "ax1.set_ylim(0,30)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(valid_mse_list, ls='--', color='red', label='valid')\n",
    "ax2.set_ylim(0,30)\n",
    "\n",
    "ax1.set_title('MSE error')\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(train_rmse_list, ls='-', color='blue', label='train')\n",
    "ax1.set_ylim(0,7)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(valid_rmse_list, ls='--', color='red', label='valid')\n",
    "ax2.set_ylim(0,7)\n",
    "ax1.set_title('RMSE error')\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 가져오기\n",
    "model = Zloc_Estimaotor(input_dim, hidden_dim,layer_dim)\n",
    "model.load_state_dict(torch.load('./weights/ODD_LSTM_512_R2.pth'))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=len(df_train), shuffle=False)\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    train_pred = batch[0]\n",
    "predict_zloc = model(train_pred.reshape(-1,1,input_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['predict'] = predict_zloc.cpu().detach().numpy()\n",
    "df_train[['zloc','predict']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "abs0 = np.abs(df_train.zloc-df_train.predict)\n",
    "abs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(abs0/len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=len(df_train), shuffle=False)\n",
    "for idx, batch in enumerate(valid_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    valid_pred = batch[0]\n",
    "predict_zloc = model(valid_pred.reshape(-1,1,input_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['predict'] = predict_zloc.cpu().detach().numpy()\n",
    "df_valid[['zloc','predict']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs0 = np.abs(df_valid.zloc-df_valid.predict)\n",
    "abs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(abs0/len(df_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse, test_rmse = evaluate(model, test_dataloader)\n",
    "print('Test MSE: {:4f} \\t Test RMSE: {:4f}'.format(test_mse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look dataset\n",
    "for idx, batch in enumerate(test_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    test_pred = batch[0]\n",
    "predict_zloc = model(test_pred.reshape(-1,1,input_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['predict'] = predict_zloc.cpu().detach().numpy()\n",
    "df_test[['zloc','predict']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "abs0 = np.abs(df_test.zloc-df_test.predict)\n",
    "abs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(abs0/len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind='scatter', x='zloc', y='depth_mean', marker='o', alpha=0.3, s=50, figsize=(20,10), color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind='scatter', x='predict', y='zloc', marker='o', alpha=0.3, s=50, figsize=(10,10), color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.plot(kind='scatter', x='predict', y='zloc', marker='o', alpha=0.3, s=50, figsize=(10,10), color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3GgQX9wAHsY2zHAbVwAG/",
   "name": "DistanceEstimator.ipynb",
   "provenance": [
    {
     "file_id": "1WN5OSA-TXiMkTLDr9xyt2F7Z_Hd16-b4",
     "timestamp": 1649567852353
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
