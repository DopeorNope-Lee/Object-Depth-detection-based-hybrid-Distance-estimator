{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xXp-L947DlL"
   },
   "source": [
    "#Distance Estimator\n",
    "To estimate the real distance(unit: meter) of the object\n",
    "\n",
    "__Input__: Bounding box coordinates(xmin, ymin, xmax, ymax)   \n",
    "__Output__: 3D location z of carmera coordinates(z_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LiXtU2475cb"
   },
   "source": [
    "## Load Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J4GISwk4884Q"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from custom_datasets import CustomDataset\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./weights', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJxQzId_79SS"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../datasets/kitti_train.csv')\n",
    "df_valid = pd.read_csv('../datasets/kitti_valid.csv')\n",
    "df_test = pd.read_csv('../datasets/kitti_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['person', 'car', 'truck', 'train', 'bicycle', 'Misc'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encoding\n",
    "class_dummy = pd.get_dummies(df_train['class'])\n",
    "df_train = pd.concat([df_train, class_dummy], axis=1)\n",
    "\n",
    "class_dummy = pd.get_dummies(df_valid['class'])\n",
    "df_valid = pd.concat([df_valid, class_dummy], axis=1)\n",
    "\n",
    "class_dummy = pd.get_dummies(df_test['class'])\n",
    "df_test = pd.concat([df_test, class_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22022 entries, 0 to 22021\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   filename    22022 non-null  object \n",
      " 1   class       22022 non-null  object \n",
      " 2   xmin        22022 non-null  float64\n",
      " 3   ymin        22022 non-null  float64\n",
      " 4   xmax        22022 non-null  float64\n",
      " 5   ymax        22022 non-null  float64\n",
      " 6   angle       22022 non-null  float64\n",
      " 7   zloc        22022 non-null  float64\n",
      " 8   weather     22022 non-null  object \n",
      " 9   depth_y     22022 non-null  int64  \n",
      " 10  depth_mean  22022 non-null  float64\n",
      " 11  depth_x     22022 non-null  int64  \n",
      " 12  depth_min   22022 non-null  float64\n",
      " 13  width       22022 non-null  float64\n",
      " 14  height      22022 non-null  float64\n",
      " 15  Misc        22022 non-null  uint8  \n",
      " 16  bicycle     22022 non-null  uint8  \n",
      " 17  car         22022 non-null  uint8  \n",
      " 18  person      22022 non-null  uint8  \n",
      " 19  train       22022 non-null  uint8  \n",
      " 20  truck       22022 non-null  uint8  \n",
      "dtypes: float64(10), int64(2), object(3), uint8(6)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = ['width', 'height', 'depth_mean', 'depth_min', 'Misc', 'bicycle', 'car', 'person', 'train', 'truck']\n",
    "batch_sz = 8\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# train\n",
    "train_dataset = CustomDataset(df_train, variable)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_sz, shuffle=True)\n",
    "\n",
    "# valid\n",
    "valid_dataset = CustomDataset(df_valid, variable)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_sz, shuffle=True)\n",
    "\n",
    "# train\n",
    "test_dataset = CustomDataset(df_test, variable)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_sz, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 24.6759,  14.4393,   8.8445,   8.5643,   0.0000,   0.0000,   1.0000,\n",
      "           0.0000,   0.0000,   0.0000],\n",
      "        [ 49.9677,  14.7209,   4.6949,   3.4180,   0.0000,   0.0000,   1.0000,\n",
      "           0.0000,   0.0000,   0.0000],\n",
      "        [ 76.0463,  64.4582,   4.1528,   3.1694,   0.0000,   0.0000,   0.0000,\n",
      "           0.0000,   0.0000,   1.0000],\n",
      "        [ 87.4794,  40.5914,   3.1512,   2.7837,   0.0000,   0.0000,   1.0000,\n",
      "           0.0000,   0.0000,   0.0000],\n",
      "        [ 66.0756,  19.0608,   4.7666,   3.0124,   0.0000,   0.0000,   1.0000,\n",
      "           0.0000,   0.0000,   0.0000],\n",
      "        [ 33.6621,  26.3322,   4.7512,   3.6130,   0.0000,   0.0000,   1.0000,\n",
      "           0.0000,   0.0000,   0.0000],\n",
      "        [130.6615,  80.1897,   2.4384,   1.7792,   0.0000,   0.0000,   1.0000,\n",
      "           0.0000,   0.0000,   0.0000],\n",
      "        [ 61.3220,  36.6520,   4.7757,   2.3093,   0.0000,   0.0000,   1.0000,\n",
      "           0.0000,   0.0000,   0.0000]])\n",
      "torch.Size([8, 10])\n",
      "tensor([[72.6500],\n",
      "        [57.7600],\n",
      "        [32.2200],\n",
      "        [22.8700],\n",
      "        [52.9100],\n",
      "        [47.9700],\n",
      "        [15.0100],\n",
      "        [36.0700]])\n"
     ]
    }
   ],
   "source": [
    "# look dataset\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    print(batch[0])\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HxfoPh3l9n7f"
   },
   "outputs": [],
   "source": [
    "# standardized data\n",
    "#scalar = StandardScaler()\n",
    "#X_train = scalar.fit_transform(X_train)\n",
    "#y_train = scalar.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_18WIN49vj6"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6SqWrYRLCdaO"
   },
   "outputs": [],
   "source": [
    "class DistanceEstimator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistanceEstimator, self).__init__()\n",
    "        \n",
    "        #Layer\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(10,32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(32,64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(64,128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(128,256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(16,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make  variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistanceEstimator(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (15): ReLU()\n",
       "    (16): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistanceEstimator()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.1,\n",
    "                                                       patience = 8,\n",
    "                                                       mode='min', # 우리는 낮아지는 값을 기대\n",
    "                                                       verbose=True)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87585"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train parameters\n",
    "def count_parameter(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameter(model) # 87585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7pqhZ4a9y99"
   },
   "source": [
    "## Make Train, Valid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, idx_interval):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_rmse = 0\n",
    "    \n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        prediction = model(batch[0].to(device))\n",
    "        loss = loss_fn(prediction, batch[1].to(device)).cpu()\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        train_rmse += np.sqrt(loss.item())\n",
    "        \n",
    "        if idx % idx_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}] \\t Train Loss(MSE): {:.4f} \\t Train RMSE: {:.4f}\".format(epoch, batch_sz*(idx+1), \\\n",
    "                                                                            len(train_dataloader)*batch_sz, \\\n",
    "                                                                            loss.item(), np.sqrt(loss.item())))\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_rmse /= len(train_dataloader)\n",
    "        \n",
    "    return train_loss, train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    valid_loss = 0\n",
    "    valid_rmse = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(valid_dataloader):\n",
    "            predictions = model(batch[0].to(device))\n",
    "            loss = loss_fn(predictions, batch[1].to(device)).cpu()\n",
    "            valid_loss += loss.item()\n",
    "            valid_rmse += np.sqrt(loss.item())\n",
    "            \n",
    "    valid_loss /= len(valid_dataloader)\n",
    "    valid_rmse /= len(valid_dataloader)\n",
    "    \n",
    "    return valid_loss,valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IIL0JPDXAvST"
   },
   "outputs": [],
   "source": [
    "# Function to save the model \n",
    "def saveModel(model): \n",
    "    path = \"./weights/ODD_basic.pth\" \n",
    "    torch.save(model.state_dict(), path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [8/22024] \t Train Loss(MSE): 1887.4092 \t Train RMSE: 43.4443\n",
      "Train Epoch: 1 [2008/22024] \t Train Loss(MSE): 125.1494 \t Train RMSE: 11.1870\n",
      "Train Epoch: 1 [4008/22024] \t Train Loss(MSE): 17.0961 \t Train RMSE: 4.1347\n",
      "Train Epoch: 1 [6008/22024] \t Train Loss(MSE): 81.1805 \t Train RMSE: 9.0100\n",
      "Train Epoch: 1 [8008/22024] \t Train Loss(MSE): 34.0513 \t Train RMSE: 5.8353\n",
      "Train Epoch: 1 [10008/22024] \t Train Loss(MSE): 5.0420 \t Train RMSE: 2.2454\n",
      "Train Epoch: 1 [12008/22024] \t Train Loss(MSE): 83.3136 \t Train RMSE: 9.1276\n",
      "Train Epoch: 1 [14008/22024] \t Train Loss(MSE): 25.9815 \t Train RMSE: 5.0972\n",
      "Train Epoch: 1 [16008/22024] \t Train Loss(MSE): 12.1833 \t Train RMSE: 3.4905\n",
      "Train Epoch: 1 [18008/22024] \t Train Loss(MSE): 18.1848 \t Train RMSE: 4.2644\n",
      "Train Epoch: 1 [20008/22024] \t Train Loss(MSE): 6.0508 \t Train RMSE: 2.4598\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11704/2998254186.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEpoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtrain_mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mvalid_mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11704/3945703811.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, idx_interval)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py38\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    215\u001b[0m                             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Epoch = 100\n",
    "best_rmse = 99999\n",
    "\n",
    "train_mse_list = []\n",
    "train_rmse_list = []\n",
    "valid_mse_list = []\n",
    "valid_rmse_list = []\n",
    "\n",
    "for epoch in range(1,(Epoch+1)):\n",
    "    train_mse, train_rmse = train(model, train_dataloader, 250)\n",
    "    valid_mse, valid_rmse = evaluate(model, valid_dataloader)\n",
    "\n",
    "    print(\"[Epoch: {} \\t Valid MSE: {:.4f} \\t Valid RMSE: {:.4f}]\".format(epoch, valid_mse, valid_rmse))\n",
    "    \n",
    "    scheduler.step(valid_mse)\n",
    "\n",
    "    # Save model\n",
    "    if valid_rmse < best_rmse:\n",
    "        path = \"./weights/ODD_basic.pth\" \n",
    "        torch.save(model.state_dict(), path) # 모델의 가중치만 저장 구조는 저장 x..?\n",
    "        \n",
    "    train_mse_list.append(train_mse)\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    valid_mse_list.append(valid_mse)\n",
    "    valid_rmse_list.append(valid_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(train_mse_list, ls='-', color='blue', label='train')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(valid_mse_list, ls='--', color='red', label='valid')\n",
    "ax1.set_title('MSE error')\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(train_rmse_list, ls='-', color='blue', label='train')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(valid_rmse_list, ls='--', color='red', label='valid')\n",
    "ax1.set_title('RMSE error')\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistanceEstimator(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (15): ReLU()\n",
       "    (16): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치 가져오기\n",
    "model = DistanceEstimator()\n",
    "model.load_state_dict(torch.load('./weights/ODD_basic.pth'))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 17.149220 \t Test RMSE: 3.442605\n"
     ]
    }
   ],
   "source": [
    "test_mse, test_rmse = evaluate(model, test_dataloader)\n",
    "print('Test MSE: {:4f} \\t Test RMSE: {:4f}'.format(test_mse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_zloc = model(torch.FloatTensor(df_test[variable].values).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zloc</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.91</td>\n",
       "      <td>45.816387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.82</td>\n",
       "      <td>36.278297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.98</td>\n",
       "      <td>6.413482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.39</td>\n",
       "      <td>13.523090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.04</td>\n",
       "      <td>13.328783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.00</td>\n",
       "      <td>20.019951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.09</td>\n",
       "      <td>19.818882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.50</td>\n",
       "      <td>41.965740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.45</td>\n",
       "      <td>24.500395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51.44</td>\n",
       "      <td>53.706333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.42</td>\n",
       "      <td>6.219694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.59</td>\n",
       "      <td>19.388678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.49</td>\n",
       "      <td>18.553383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32.38</td>\n",
       "      <td>33.099266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39.15</td>\n",
       "      <td>34.295254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>43.40</td>\n",
       "      <td>44.559780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40.74</td>\n",
       "      <td>42.192814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46.75</td>\n",
       "      <td>40.663918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21.32</td>\n",
       "      <td>21.040201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>35.62</td>\n",
       "      <td>31.902283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>54.18</td>\n",
       "      <td>45.604717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.99</td>\n",
       "      <td>8.445634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.27</td>\n",
       "      <td>14.777857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>37.26</td>\n",
       "      <td>41.244106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>41.47</td>\n",
       "      <td>42.662365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.46</td>\n",
       "      <td>8.802952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19.53</td>\n",
       "      <td>21.075314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>32.32</td>\n",
       "      <td>30.188717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>74.57</td>\n",
       "      <td>71.314415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14.09</td>\n",
       "      <td>13.924215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>23.57</td>\n",
       "      <td>22.575628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>46.10</td>\n",
       "      <td>48.425831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.56</td>\n",
       "      <td>7.736032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.66</td>\n",
       "      <td>4.783658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52.48</td>\n",
       "      <td>55.715382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.15</td>\n",
       "      <td>10.374205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14.99</td>\n",
       "      <td>13.158325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>11.74</td>\n",
       "      <td>11.675116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>22.51</td>\n",
       "      <td>21.746344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>22.68</td>\n",
       "      <td>23.485241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28.65</td>\n",
       "      <td>30.208923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>37.65</td>\n",
       "      <td>34.295254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>41.10</td>\n",
       "      <td>31.438530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>24.88</td>\n",
       "      <td>26.007612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>62.34</td>\n",
       "      <td>58.380642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>30.51</td>\n",
       "      <td>28.044022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>37.94</td>\n",
       "      <td>36.010811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>22.52</td>\n",
       "      <td>22.630947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>53.34</td>\n",
       "      <td>51.899349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>21.43</td>\n",
       "      <td>25.939844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     zloc    predict\n",
       "0   44.91  45.816387\n",
       "1   33.82  36.278297\n",
       "2    3.98   6.413482\n",
       "3   11.39  13.523090\n",
       "4   13.04  13.328783\n",
       "5   21.00  20.019951\n",
       "6   21.09  19.818882\n",
       "7   48.50  41.965740\n",
       "8   22.45  24.500395\n",
       "9   51.44  53.706333\n",
       "10   6.42   6.219694\n",
       "11  19.59  19.388678\n",
       "12  20.49  18.553383\n",
       "13  32.38  33.099266\n",
       "14  39.15  34.295254\n",
       "15  43.40  44.559780\n",
       "16  40.74  42.192814\n",
       "17  46.75  40.663918\n",
       "18  21.32  21.040201\n",
       "19  35.62  31.902283\n",
       "20  54.18  45.604717\n",
       "21   7.99   8.445634\n",
       "22  15.27  14.777857\n",
       "23  37.26  41.244106\n",
       "24  41.47  42.662365\n",
       "25   7.46   8.802952\n",
       "26  19.53  21.075314\n",
       "27  32.32  30.188717\n",
       "28  74.57  71.314415\n",
       "29  14.09  13.924215\n",
       "30  23.57  22.575628\n",
       "31  46.10  48.425831\n",
       "32   8.56   7.736032\n",
       "33   2.66   4.783658\n",
       "34  52.48  55.715382\n",
       "35  10.15  10.374205\n",
       "36  14.99  13.158325\n",
       "37  11.74  11.675116\n",
       "38  22.51  21.746344\n",
       "39  22.68  23.485241\n",
       "40  28.65  30.208923\n",
       "41  37.65  34.295254\n",
       "42  41.10  31.438530\n",
       "43  24.88  26.007612\n",
       "44  62.34  58.380642\n",
       "45  30.51  28.044022\n",
       "46  37.94  36.010811\n",
       "47  22.52  22.630947\n",
       "48  53.34  51.899349\n",
       "49  21.43  25.939844"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predict'] = predict_zloc.cpu().detach().numpy()\n",
    "df_test[['zloc','predict']].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwdFu-xwEdAU"
   },
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def train_model(model, train_dataloader, valid_dataloader, loss_fn, lr=1e-5, batch_size=512, epochs=100, validate=False):\n",
    "\n",
    "  \n",
    "  # Convert model parameters and buffers to CPU or Cuda\n",
    "  model.to(device)\n",
    "\n",
    "  best_rmse = np.Inf\n",
    "  print(\"Begin training...\") \n",
    "  for epoch in range(1, epochs+1): \n",
    "    running_train_loss = 0.0 \n",
    "    running_rmse = 0.0 \n",
    "    running_vall_loss = 0.0 \n",
    "    total = 0 \n",
    "\n",
    "    for batch_ind, samples in enumerate(train_dataloader):\n",
    "      x_train, y_train = samples\n",
    "      optimizer.zero_grad()\n",
    "      pred = model.forward(x_train)\n",
    "      train_loss = loss_fn(pred, y_train)\n",
    "      train_loss.backward()\n",
    "      optimizer.step()\n",
    "      running_train_loss += train_loss.item()\n",
    "\n",
    "    train_loss_value = running_train_loss/len(train_dataloader)\n",
    "    with torch.no_grad(): \n",
    "      model.eval() \n",
    "      for data in valid_dataloader: \n",
    "        inputs, outputs = data \n",
    "        predicted_outputs = model(inputs) \n",
    "        val_loss = loss_fn(predicted_outputs, outputs) \n",
    "      \n",
    "        # The label with the highest value will be our prediction \n",
    "        running_vall_loss += val_loss.item()  \n",
    "        total += outputs.size(0) \n",
    "        rmse = mean_squared_error(outputs, predicted_outputs)**0.5\n",
    "        running_rmse += rmse\n",
    "\n",
    "    # Calculate validation loss value \n",
    "    val_loss_value = running_vall_loss/len(valid_dataloader)  \n",
    "    rmse = running_rmse / total\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "      saveModel(model)\n",
    "      best_rmse = rmse\n",
    "\n",
    "    # Print the statistics of the epoch \n",
    "    print('Epoch {0}/{1} - loss: {2:.4f} / val_loss: {3:.4f} - RMSE: {4:.4f}'.format(epoch, epochs, train_loss_value, val_loss_value,rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3dgdPwJGdnQ"
   },
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "valid_dataset = TensorDataset(X_valid, y_valid)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE5K6pUX-LG3"
   },
   "source": [
    "model = DistanceEstimator()\n",
    "#optimizer = torch.optim.Adam(model.parameters, lr=1e-5)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1664546,
     "status": "ok",
     "timestamp": 1649523139093,
     "user": {
      "displayName": "박선영",
      "userId": "02522110649935123410"
     },
     "user_tz": -540
    },
    "id": "bqPh_Uj9BzeV",
    "outputId": "97271dc0-8ed0-474d-97f9-ec6c20901ef6"
   },
   "source": [
    "train_model(model, train_dataloader, valid_dataloader, loss_func, epochs=100, batch_size=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9b6kPgY96vK"
   },
   "source": [
    "##Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kr-YyzYXBGsw"
   },
   "source": [
    "def predict(test_dataloader): \n",
    "    # Load the model that we saved at the end of the training loop \n",
    "    model = DistanceEstimator()\n",
    "    path = \"NetModel.pth\" \n",
    "    model.load_state_dict(torch.load(path)) \n",
    "     \n",
    "    running_rmse = 0 \n",
    "    total = 0 \n",
    "    pred = []\n",
    " \n",
    "    with torch.no_grad(): \n",
    "      for data in test_dataloader: \n",
    "        inputs, outputs = data \n",
    "        outputs = outputs.to(torch.float32) \n",
    "        predicted_outputs = model(inputs) \n",
    "        pred.append(float(predicted_outputs))\n",
    "        total += outputs.size(0) \n",
    "        rmse = mean_squared_error(outputs, predicted_outputs)**0.5\n",
    "        running_rmse += rmse\n",
    " \n",
    "      print('RMSE:',running_rmse / total)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ssK71esE-9q"
   },
   "source": [
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1649523483055,
     "user": {
      "displayName": "박선영",
      "userId": "02522110649935123410"
     },
     "user_tz": -540
    },
    "id": "v_EkCScgFxpb",
    "outputId": "f22a38a2-970e-4bf8-a9c0-e38ebc050db5"
   },
   "source": [
    "pred = predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1649523490608,
     "user": {
      "displayName": "박선영",
      "userId": "02522110649935123410"
     },
     "user_tz": -540
    },
    "id": "H1V6NrWNGQFu",
    "outputId": "4ed81376-c6ec-47b2-9351-fb34cc87c884"
   },
   "source": [
    "#Result with prediction\n",
    "df_test['zloc_pred'] = pred\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJgfmokyGc5B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3GgQX9wAHsY2zHAbVwAG/",
   "name": "DistanceEstimator.ipynb",
   "provenance": [
    {
     "file_id": "1WN5OSA-TXiMkTLDr9xyt2F7Z_Hd16-b4",
     "timestamp": 1649567852353
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
