{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xXp-L947DlL"
   },
   "source": [
    "#Distance Estimator\n",
    "To estimate the real distance(unit: meter) of the object\n",
    "\n",
    "__Input__: Bounding box coordinates(xmin, ymin, xmax, ymax)   \n",
    "__Output__: 3D location z of carmera coordinates(z_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LiXtU2475cb"
   },
   "source": [
    "## Load Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J4GISwk4884Q"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import category_encoders as ce\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from custom_datasets import CustomDataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./weights', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJxQzId_79SS"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../datasets/kitti_train.csv')\n",
    "df_valid = pd.read_csv('../datasets/kitti_valid.csv')\n",
    "df_test = pd.read_csv('../datasets/kitti_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['person', 'car', 'truck', 'train', 'bicycle', 'Misc'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encoding\n",
    "class_dummy = pd.get_dummies(df_train['class'])\n",
    "df_train = pd.concat([df_train, class_dummy], axis=1)\n",
    "\n",
    "class_dummy = pd.get_dummies(df_valid['class'])\n",
    "df_valid = pd.concat([df_valid, class_dummy], axis=1)\n",
    "\n",
    "class_dummy = pd.get_dummies(df_test['class'])\n",
    "df_test = pd.concat([df_test, class_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding\n",
    "#encoder= ce.OrdinalEncoder(cols=['Degree'],return_df=True,\n",
    "#                           mapping=[{'col':'class', \n",
    "#                                'mapping':{'Misc':0, 'person':1, 'bicycle':2, 'car':3, 'train':4, 'truck': 4}}])\n",
    "#df_train = encoder.fit_transform(df_train)\n",
    "#df_valid = encoder.fit_transform(df_valid)\n",
    "#df_test = encoder.fit_transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22022 entries, 0 to 22021\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   filename    22022 non-null  object \n",
      " 1   class       22022 non-null  object \n",
      " 2   xmin        22022 non-null  float64\n",
      " 3   ymin        22022 non-null  float64\n",
      " 4   xmax        22022 non-null  float64\n",
      " 5   ymax        22022 non-null  float64\n",
      " 6   angle       22022 non-null  float64\n",
      " 7   zloc        22022 non-null  float64\n",
      " 8   weather     22022 non-null  object \n",
      " 9   depth_y     22022 non-null  int64  \n",
      " 10  depth_mean  22022 non-null  float64\n",
      " 11  depth_x     22022 non-null  int64  \n",
      " 12  depth_min   22022 non-null  float64\n",
      " 13  width       22022 non-null  float64\n",
      " 14  height      22022 non-null  float64\n",
      " 15  Misc        22022 non-null  uint8  \n",
      " 16  bicycle     22022 non-null  uint8  \n",
      " 17  car         22022 non-null  uint8  \n",
      " 18  person      22022 non-null  uint8  \n",
      " 19  train       22022 non-null  uint8  \n",
      " 20  truck       22022 non-null  uint8  \n",
      "dtypes: float64(10), int64(2), object(3), uint8(6)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = ['xmin','ymin','xmax','ymax','width', 'height','depth_min','depth_mean', 'Misc', 'bicycle','car','person','train','truck']\n",
    "val_length = len(variable)\n",
    "batch_sz = 48 \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# train\n",
    "train_dataset = CustomDataset(df_train, variable, scaler=True, train=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_sz, shuffle=True)\n",
    "# train_sclaer\n",
    "scaler_train = train_dataset.scaler\n",
    "\n",
    "# valid\n",
    "valid_dataset = CustomDataset(df_valid, variable, True, train=scaler_train)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_sz, shuffle=True)\n",
    "\n",
    "# train\n",
    "test_dataset = CustomDataset(df_test, variable, True, train=scaler_train)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=len(df_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_length # 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8812e+00,  7.0806e-01, -1.9596e+00, -2.4911e-01, -2.0734e-01,\n",
      "         -5.5150e-01,  1.4939e-01,  1.5609e-02, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-7.0772e-01,  5.5088e-02, -6.8562e-01, -3.0127e-01,  8.3128e-02,\n",
      "         -3.3858e-01, -4.7969e-01, -2.3809e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-2.5421e-01,  9.4120e-02, -5.4476e-01, -8.9646e-01, -9.0215e-01,\n",
      "         -9.7889e-01,  1.0326e+00,  7.3955e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 6.3357e-01, -1.7908e-01,  4.3778e-01, -5.1056e-01, -6.2396e-01,\n",
      "         -4.6214e-01, -1.4027e-01,  1.9811e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 1.7852e+00, -1.2054e+00,  2.3800e+00,  2.3992e+00,  1.8217e+00,\n",
      "          3.0106e+00, -1.1396e+00, -1.3239e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-1.7900e+00, -1.3563e-01, -8.7460e-01,  2.3343e+00,  2.8939e+00,\n",
      "          2.5041e+00, -1.0323e+00, -1.2376e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-1.9748e-01, -8.5696e-01, -4.2692e-01, -6.3498e-01, -7.1247e-01,\n",
      "         -3.1480e-01, -8.8476e-01,  1.3044e-02, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 4.1749e-02,  2.8551e-01, -1.4615e-01, -4.8299e-01, -5.8751e-01,\n",
      "         -6.2364e-01, -3.3010e-01,  3.5209e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-1.6099e+00, -1.1271e+00, -1.5706e+00,  1.6723e+00,  1.5488e-01,\n",
      "          2.2161e+00, -1.0181e+00, -1.1797e+00, -8.0560e-02, -7.4329e-02,\n",
      "         -2.2480e+00,  2.6341e+00, -8.0274e-02, -1.4606e-01],\n",
      "        [-1.3774e+00,  7.7687e-01, -5.7168e-01,  2.0174e+00,  2.5431e+00,\n",
      "          1.7976e+00, -1.0657e+00, -1.2501e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 1.4309e+00,  1.4308e+00,  2.3767e+00,  2.4021e+00,  2.9245e+00,\n",
      "          1.9331e+00, -1.1944e+00, -1.3560e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-1.6382e-02, -1.3383e-01, -2.8073e-01, -7.8295e-01, -8.2505e-01,\n",
      "         -7.6639e-01,  7.9158e-01,  6.7969e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 2.7720e-01, -1.5133e-01,  3.2795e-02, -9.1865e-01, -7.6863e-01,\n",
      "         -9.0155e-01,  1.7574e+00,  1.3305e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 6.2272e-02,  3.2258e-01, -2.3482e-01, -7.0911e-01, -9.2886e-01,\n",
      "         -8.7601e-01,  6.8527e-01,  5.7414e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 1.5389e+00, -3.5270e-02,  1.6300e+00, -6.6635e-02,  2.5388e-01,\n",
      "         -5.5439e-02, -1.0648e+00, -8.6731e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-1.6438e-01, -1.9177e-01, -2.9502e-01, -6.2852e-01, -4.0461e-01,\n",
      "         -5.8066e-01,  6.9871e-01,  5.5295e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-9.5013e-01, -3.7390e-01, -1.1243e+00, -9.2384e-01, -5.2492e-01,\n",
      "         -8.1578e-01, -8.4850e-02,  1.0342e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-2.5112e-01,  1.0332e-01, -3.6663e-01, -3.5381e-01, -3.5567e-01,\n",
      "         -4.1347e-01,  2.5123e-01,  1.3176e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 1.4875e+00, -3.4141e-01,  1.3245e+00, -9.9283e-01, -5.3868e-01,\n",
      "         -9.0146e-01,  1.2678e+00,  1.1427e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-1.8808e+00,  3.8869e+00, -1.6746e+00,  2.4312e+00,  6.8125e-01,\n",
      "          9.5704e-01, -1.2328e+00, -1.3727e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-1.3696e+00, -6.2770e-01, -1.3737e+00,  2.4468e+00,  1.4525e-02,\n",
      "          2.8238e+00, -1.1204e+00, -1.3614e+00, -8.0560e-02, -7.4329e-02,\n",
      "         -2.2480e+00,  2.6341e+00, -8.0274e-02, -1.4606e-01],\n",
      "        [-7.1836e-01,  4.7059e-01, -7.1490e-01, -3.1660e-01,  2.5136e-02,\n",
      "         -5.2497e-01,  4.7943e-01,  3.7680e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 2.4088e+00, -1.6381e+00,  2.2517e+00,  9.2725e-01, -5.3842e-01,\n",
      "          1.6440e+00, -1.0302e+00, -1.2258e+00, -8.0560e-02, -7.4329e-02,\n",
      "         -2.2480e+00,  2.6341e+00, -8.0274e-02, -1.4606e-01],\n",
      "        [ 2.9617e-01,  1.1295e-01,  5.1058e-02, -8.0491e-01, -7.7124e-01,\n",
      "         -8.9058e-01,  1.9914e+00,  1.6728e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-3.6453e-01,  7.5730e-01, -5.2233e-01, -1.1436e-01, -4.8543e-01,\n",
      "         -4.3034e-01, -1.9504e-01, -3.0155e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-4.9089e-02, -1.4855e+00, -2.9412e-01, -1.4864e+00, -7.6408e-01,\n",
      "         -9.5022e-01,  2.8482e+00,  2.3655e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 6.9608e-01, -5.7900e-01,  4.3875e-01, -2.7001e-01, -8.1735e-01,\n",
      "         -4.5901e-02, -2.1921e-01, -4.6557e-01, -8.0560e-02, -7.4329e-02,\n",
      "         -2.2480e+00,  2.6341e+00, -8.0274e-02, -1.4606e-01],\n",
      "        [ 1.3249e-01,  3.3507e-01, -2.9046e-02, -4.0879e-01, -5.0700e-01,\n",
      "         -5.6612e-01,  2.9651e-01,  3.1079e-02, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-1.8811e+00,  1.6974e+00, -1.8838e+00,  1.1580e+00,  2.9175e-02,\n",
      "          5.1895e-01, -8.3913e-01, -9.6030e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-7.6722e-02, -1.1295e-01, -2.9152e-01, -8.6184e-01, -6.6915e-01,\n",
      "         -8.5770e-01,  2.0466e+00,  1.8780e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 1.0635e+00, -8.1739e-02,  9.4175e-01, -8.2656e-01, -4.0140e-01,\n",
      "         -8.3348e-01, -2.4025e-01,  8.5491e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-1.8809e+00, -2.6331e-01, -1.6594e+00,  1.3260e+00,  7.2904e-01,\n",
      "          1.4988e+00, -8.8519e-01, -1.0950e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 1.4872e-01,  8.2463e-02, -8.1859e-02, -7.9718e-01, -7.2291e-01,\n",
      "         -8.6997e-01,  1.7083e+00,  1.5516e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 9.1224e-01,  8.6717e-01,  1.4750e+00,  1.8334e+00,  1.7388e+00,\n",
      "          1.5676e+00, -9.4851e-01, -1.1853e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 4.8455e-01, -6.6761e-02,  2.5914e-01, -8.1384e-01, -7.1347e-01,\n",
      "         -8.2629e-01,  1.1849e+00,  8.0168e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 7.6343e-02, -1.6756e+00, -1.6435e-01, -4.2140e-01, -7.5305e-01,\n",
      "          2.4476e-01, -2.9969e-01, -4.8665e-01, -8.0560e-02, -7.4329e-02,\n",
      "         -2.2480e+00,  2.6341e+00, -8.0274e-02, -1.4606e-01],\n",
      "        [-3.4641e-01,  4.6315e-01, -4.2204e-01, -3.5709e-01, -2.2922e-01,\n",
      "         -5.6438e-01, -6.0910e-01,  2.6110e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 1.2302e-01, -2.8543e-01, -1.6882e-01, -5.4066e-01, -9.1367e-01,\n",
      "         -4.5012e-01,  3.3543e-01,  1.1160e-01, -8.0560e-02, -7.4329e-02,\n",
      "         -2.2480e+00,  2.6341e+00, -8.0274e-02, -1.4606e-01],\n",
      "        [ 8.5716e-01, -2.6100e-01,  1.4635e+00,  1.9442e+00,  1.8760e+00,\n",
      "          2.1462e+00, -1.0240e+00, -1.1555e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 1.8039e-02, -2.7466e-01, -2.4241e-01, -8.4347e-01, -8.1357e-01,\n",
      "         -7.7215e-01,  1.0584e+00,  1.0291e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-9.7602e-01,  9.1785e-02, -6.8568e-01,  5.3539e-01,  9.2600e-01,\n",
      "          5.2396e-01, -1.0144e+00, -1.0248e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 3.8074e-01, -5.0562e-01,  6.3409e-02, -1.1573e+00, -9.9840e-01,\n",
      "         -1.0066e+00,  1.9514e+00,  1.6986e+00, -8.0560e-02, -7.4329e-02,\n",
      "         -2.2480e+00,  2.6341e+00, -8.0274e-02, -1.4606e-01],\n",
      "        [-4.9557e-01, -1.2659e+00, -5.4764e-01,  1.2307e+00, -1.5271e-01,\n",
      "          1.8098e+00, -8.6727e-01, -8.6401e-01, -8.0560e-02, -7.4329e-02,\n",
      "         -2.2480e+00,  2.6341e+00, -8.0274e-02, -1.4606e-01],\n",
      "        [ 6.7579e-01, -4.5406e-01,  5.2407e-01, -5.3448e-01, -4.8720e-01,\n",
      "         -3.7452e-01,  2.5085e-01,  1.0109e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-2.8811e-01,  7.7564e-02, -3.6853e-01, -7.6544e-01, -2.4535e-01,\n",
      "         -8.3467e-01,  3.8761e-01,  1.0454e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [-1.8811e+00,  3.8174e+00, -1.9874e+00,  1.9594e+00, -2.9429e-01,\n",
      "          4.9062e-01, -9.3576e-01, -1.1524e+00, -8.0560e-02,  1.3454e+01,\n",
      "         -2.2480e+00, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 8.2386e-01,  1.2588e+00,  1.1576e+00,  1.5047e+00,  1.0257e+00,\n",
      "          1.0623e+00, -8.4449e-01, -1.0946e+00, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01],\n",
      "        [ 9.4120e-01,  1.6272e-01,  1.1585e+00, -1.3422e-01,  6.5960e-01,\n",
      "         -2.0748e-01, -4.7608e-01, -4.1550e-01, -8.0560e-02, -7.4329e-02,\n",
      "          4.4485e-01, -3.7963e-01, -8.0274e-02, -1.4606e-01]])\n",
      "torch.Size([48, 14])\n",
      "tensor([[27.7800],\n",
      "        [23.8900],\n",
      "        [53.6600],\n",
      "        [37.4300],\n",
      "        [ 5.0700],\n",
      "        [ 7.8400],\n",
      "        [27.8200],\n",
      "        [29.7300],\n",
      "        [ 7.3600],\n",
      "        [ 7.5700],\n",
      "        [ 4.1800],\n",
      "        [37.7700],\n",
      "        [46.7200],\n",
      "        [44.6800],\n",
      "        [17.6800],\n",
      "        [31.3700],\n",
      "        [45.5500],\n",
      "        [25.9800],\n",
      "        [43.1500],\n",
      "        [ 1.7400],\n",
      "        [ 4.6500],\n",
      "        [30.0000],\n",
      "        [ 7.7200],\n",
      "        [48.2100],\n",
      "        [23.1800],\n",
      "        [67.5500],\n",
      "        [18.9600],\n",
      "        [26.1300],\n",
      "        [ 8.5700],\n",
      "        [53.2200],\n",
      "        [41.0600],\n",
      "        [ 9.2800],\n",
      "        [45.9500],\n",
      "        [ 8.4000],\n",
      "        [43.4200],\n",
      "        [16.0000],\n",
      "        [30.1800],\n",
      "        [26.2900],\n",
      "        [ 8.5300],\n",
      "        [58.8400],\n",
      "        [12.5600],\n",
      "        [58.9600],\n",
      "        [ 8.5600],\n",
      "        [28.5100],\n",
      "        [45.5100],\n",
      "        [ 7.4600],\n",
      "        [10.3400],\n",
      "        [20.5800]])\n"
     ]
    }
   ],
   "source": [
    "# look dataset\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    print(batch[0])\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_18WIN49vj6"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6SqWrYRLCdaO"
   },
   "outputs": [],
   "source": [
    "class Zloc_Estimaotor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True, bidirectional=False)\n",
    "        \n",
    "        #Layer\n",
    "        layersize=[256, 128, 64, 32]\n",
    "        layerlist= []\n",
    "        n_in=hidden_dim\n",
    "        for i in layersize:\n",
    "            layerlist.append(nn.Linear(n_in,i))\n",
    "            layerlist.append(nn.Hardswish())\n",
    "            #layerlist.append(nn.BatchNorm1d(i))\n",
    "            #layerlist.append(nn.Dropout(0.2))\n",
    "            n_in=i           \n",
    "        layerlist.append(nn.Linear(layersize[-1],1))\n",
    "        #layerlist.append(nn.Sigmoid())\n",
    "        \n",
    "        self.fc=nn.Sequential(*layerlist)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, hn = self.rnn(x)\n",
    "        output = self.fc(out[:,-1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make  variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zloc_Estimaotor(\n",
       "  (rnn): LSTM(14, 512, num_layers=3, batch_first=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): Hardswish()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): Hardswish()\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): Hardswish()\n",
       "    (8): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.init as init\n",
    "#def weight_init(m):\n",
    "#    if isinstance(m, nn.Linear): # nn.Linear에 있는 가중치에만 적용\n",
    "#        init.kaiming_uniform_(m.weight.data) # He initialization\n",
    "\n",
    "# variable \n",
    "input_dim = val_length\n",
    "hidden_dim = 512\n",
    "layer_dim = 3\n",
    "        \n",
    "model = Zloc_Estimaotor(input_dim, hidden_dim, layer_dim)\n",
    "#model.apply(weight_init)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.5,\n",
    "                                                       patience = 10,\n",
    "                                                       mode='min', # 우리는 낮아지는 값을 기대\n",
    "                                                       verbose=True,\n",
    "                                                       min_lr=1e-6)\n",
    "from early_stopping import EarlyStopping\n",
    "early_stopping = EarlyStopping(40, verbose=True)   \n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5458433"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train parameters\n",
    "def count_parameter(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameter(model) # 5686657"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7pqhZ4a9y99"
   },
   "source": [
    "## Make Train, Valid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, idx_interval):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_rmse = 0\n",
    "    \n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inp = batch[0].reshape(len(batch[0]),1,-1)\n",
    "        \n",
    "        prediction = model(inp.to(device))\n",
    "        loss = loss_fn(prediction, batch[1].to(device)).cpu()\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        if idx % idx_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}] \\t Train Loss(MSE): {:.4f} \\t Train RMSE: {:.4f}\".format(epoch, batch_sz*(idx+1), \\\n",
    "                                                                            len(train_dataloader)*batch_sz, \\\n",
    "                                                                            loss.item(), np.sqrt(loss.item())))\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_rmse = np.sqrt(train_loss)\n",
    "        \n",
    "    return train_loss, train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    valid_loss = 0\n",
    "    valid_rmse = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(valid_dataloader):\n",
    "            inp = batch[0].reshape(len(batch[0]),1,-1)\n",
    "            predictions = model(inp.to(device))\n",
    "            loss = loss_fn(predictions, batch[1].to(device)).cpu()\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "    valid_loss /= len(valid_dataloader)\n",
    "    valid_rmse = np.sqrt(valid_loss)\n",
    "    \n",
    "    return valid_loss,valid_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [48/22032] \t Train Loss(MSE): 1122.5914 \t Train RMSE: 33.5051\n",
      "Train Epoch: 1 [9648/22032] \t Train Loss(MSE): 53.0123 \t Train RMSE: 7.2810\n",
      "Train Epoch: 1 [19248/22032] \t Train Loss(MSE): 21.5518 \t Train RMSE: 4.6424\n",
      "[Epoch: 1 \t Valid MSE: 19.3708 \t Valid RMSE: 4.4012]\n",
      "[Epoch: 1 \t Train MSE: 50.8739 \t Train RMSE: 7.1326]\n",
      "Validation loss decreased (inf --> 50.873864).  Saving model ...\n",
      "Train Epoch: 2 [48/22032] \t Train Loss(MSE): 9.2294 \t Train RMSE: 3.0380\n",
      "Train Epoch: 2 [9648/22032] \t Train Loss(MSE): 37.2345 \t Train RMSE: 6.1020\n",
      "Train Epoch: 2 [19248/22032] \t Train Loss(MSE): 21.7251 \t Train RMSE: 4.6610\n",
      "[Epoch: 2 \t Valid MSE: 31.1941 \t Valid RMSE: 5.5852]\n",
      "[Epoch: 2 \t Train MSE: 22.0941 \t Train RMSE: 4.7004]\n",
      "Validation loss decreased (50.873864 --> 22.094051).  Saving model ...\n",
      "Train Epoch: 3 [48/22032] \t Train Loss(MSE): 16.7337 \t Train RMSE: 4.0907\n",
      "Train Epoch: 3 [9648/22032] \t Train Loss(MSE): 16.5812 \t Train RMSE: 4.0720\n",
      "Train Epoch: 3 [19248/22032] \t Train Loss(MSE): 52.5896 \t Train RMSE: 7.2519\n",
      "[Epoch: 3 \t Valid MSE: 18.9852 \t Valid RMSE: 4.3572]\n",
      "[Epoch: 3 \t Train MSE: 18.4859 \t Train RMSE: 4.2995]\n",
      "Validation loss decreased (22.094051 --> 18.485902).  Saving model ...\n",
      "Train Epoch: 4 [48/22032] \t Train Loss(MSE): 15.2523 \t Train RMSE: 3.9054\n",
      "Train Epoch: 4 [9648/22032] \t Train Loss(MSE): 10.1897 \t Train RMSE: 3.1921\n",
      "Train Epoch: 4 [19248/22032] \t Train Loss(MSE): 11.7107 \t Train RMSE: 3.4221\n",
      "[Epoch: 4 \t Valid MSE: 84.8790 \t Valid RMSE: 9.2130]\n",
      "[Epoch: 4 \t Train MSE: 19.7792 \t Train RMSE: 4.4474]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 5 [48/22032] \t Train Loss(MSE): 99.5258 \t Train RMSE: 9.9763\n",
      "Train Epoch: 5 [9648/22032] \t Train Loss(MSE): 19.3223 \t Train RMSE: 4.3957\n",
      "Train Epoch: 5 [19248/22032] \t Train Loss(MSE): 13.5803 \t Train RMSE: 3.6852\n",
      "[Epoch: 5 \t Valid MSE: 16.4385 \t Valid RMSE: 4.0544]\n",
      "[Epoch: 5 \t Train MSE: 17.5951 \t Train RMSE: 4.1947]\n",
      "Validation loss decreased (18.485902 --> 17.595138).  Saving model ...\n",
      "Train Epoch: 6 [48/22032] \t Train Loss(MSE): 10.4831 \t Train RMSE: 3.2378\n",
      "Train Epoch: 6 [9648/22032] \t Train Loss(MSE): 14.9740 \t Train RMSE: 3.8696\n",
      "Train Epoch: 6 [19248/22032] \t Train Loss(MSE): 30.0523 \t Train RMSE: 5.4820\n",
      "[Epoch: 6 \t Valid MSE: 16.1914 \t Valid RMSE: 4.0239]\n",
      "[Epoch: 6 \t Train MSE: 17.4191 \t Train RMSE: 4.1736]\n",
      "Validation loss decreased (17.595138 --> 17.419101).  Saving model ...\n",
      "Train Epoch: 7 [48/22032] \t Train Loss(MSE): 6.9240 \t Train RMSE: 2.6313\n",
      "Train Epoch: 7 [9648/22032] \t Train Loss(MSE): 22.1899 \t Train RMSE: 4.7106\n",
      "Train Epoch: 7 [19248/22032] \t Train Loss(MSE): 18.1322 \t Train RMSE: 4.2582\n",
      "[Epoch: 7 \t Valid MSE: 18.6621 \t Valid RMSE: 4.3200]\n",
      "[Epoch: 7 \t Train MSE: 16.4398 \t Train RMSE: 4.0546]\n",
      "Validation loss decreased (17.419101 --> 16.439779).  Saving model ...\n",
      "Train Epoch: 8 [48/22032] \t Train Loss(MSE): 14.1651 \t Train RMSE: 3.7637\n",
      "Train Epoch: 8 [9648/22032] \t Train Loss(MSE): 13.6423 \t Train RMSE: 3.6935\n",
      "Train Epoch: 8 [19248/22032] \t Train Loss(MSE): 14.9710 \t Train RMSE: 3.8692\n",
      "[Epoch: 8 \t Valid MSE: 24.2652 \t Valid RMSE: 4.9260]\n",
      "[Epoch: 8 \t Train MSE: 16.4610 \t Train RMSE: 4.0572]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 9 [48/22032] \t Train Loss(MSE): 13.4555 \t Train RMSE: 3.6682\n",
      "Train Epoch: 9 [9648/22032] \t Train Loss(MSE): 18.4239 \t Train RMSE: 4.2923\n",
      "Train Epoch: 9 [19248/22032] \t Train Loss(MSE): 16.5466 \t Train RMSE: 4.0678\n",
      "[Epoch: 9 \t Valid MSE: 17.1268 \t Valid RMSE: 4.1385]\n",
      "[Epoch: 9 \t Train MSE: 15.7474 \t Train RMSE: 3.9683]\n",
      "Validation loss decreased (16.439779 --> 15.747393).  Saving model ...\n",
      "Train Epoch: 10 [48/22032] \t Train Loss(MSE): 26.7268 \t Train RMSE: 5.1698\n",
      "Train Epoch: 10 [9648/22032] \t Train Loss(MSE): 13.6758 \t Train RMSE: 3.6981\n",
      "Train Epoch: 10 [19248/22032] \t Train Loss(MSE): 11.9235 \t Train RMSE: 3.4530\n",
      "[Epoch: 10 \t Valid MSE: 16.7013 \t Valid RMSE: 4.0867]\n",
      "[Epoch: 10 \t Train MSE: 15.3532 \t Train RMSE: 3.9183]\n",
      "Validation loss decreased (15.747393 --> 15.353170).  Saving model ...\n",
      "Train Epoch: 11 [48/22032] \t Train Loss(MSE): 9.0030 \t Train RMSE: 3.0005\n",
      "Train Epoch: 11 [9648/22032] \t Train Loss(MSE): 7.1326 \t Train RMSE: 2.6707\n",
      "Train Epoch: 11 [19248/22032] \t Train Loss(MSE): 22.7744 \t Train RMSE: 4.7723\n",
      "[Epoch: 11 \t Valid MSE: 22.1214 \t Valid RMSE: 4.7033]\n",
      "[Epoch: 11 \t Train MSE: 14.0618 \t Train RMSE: 3.7499]\n",
      "Validation loss decreased (15.353170 --> 14.061790).  Saving model ...\n",
      "Train Epoch: 12 [48/22032] \t Train Loss(MSE): 20.2572 \t Train RMSE: 4.5008\n",
      "Train Epoch: 12 [9648/22032] \t Train Loss(MSE): 15.2485 \t Train RMSE: 3.9049\n",
      "Train Epoch: 12 [19248/22032] \t Train Loss(MSE): 69.3499 \t Train RMSE: 8.3277\n",
      "[Epoch: 12 \t Valid MSE: 17.0668 \t Valid RMSE: 4.1312]\n",
      "[Epoch: 12 \t Train MSE: 14.8983 \t Train RMSE: 3.8598]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 13 [48/22032] \t Train Loss(MSE): 20.5236 \t Train RMSE: 4.5303\n",
      "Train Epoch: 13 [9648/22032] \t Train Loss(MSE): 8.8326 \t Train RMSE: 2.9720\n",
      "Train Epoch: 13 [19248/22032] \t Train Loss(MSE): 19.3473 \t Train RMSE: 4.3986\n",
      "[Epoch: 13 \t Valid MSE: 15.9726 \t Valid RMSE: 3.9966]\n",
      "[Epoch: 13 \t Train MSE: 15.2987 \t Train RMSE: 3.9114]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 14 [48/22032] \t Train Loss(MSE): 12.8765 \t Train RMSE: 3.5884\n",
      "Train Epoch: 14 [9648/22032] \t Train Loss(MSE): 8.5681 \t Train RMSE: 2.9271\n",
      "Train Epoch: 14 [19248/22032] \t Train Loss(MSE): 6.5144 \t Train RMSE: 2.5523\n",
      "[Epoch: 14 \t Valid MSE: 15.6072 \t Valid RMSE: 3.9506]\n",
      "[Epoch: 14 \t Train MSE: 14.4478 \t Train RMSE: 3.8010]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 15 [48/22032] \t Train Loss(MSE): 12.9321 \t Train RMSE: 3.5961\n",
      "Train Epoch: 15 [9648/22032] \t Train Loss(MSE): 11.0975 \t Train RMSE: 3.3313\n",
      "Train Epoch: 15 [19248/22032] \t Train Loss(MSE): 31.5730 \t Train RMSE: 5.6190\n",
      "[Epoch: 15 \t Valid MSE: 15.4548 \t Valid RMSE: 3.9313]\n",
      "[Epoch: 15 \t Train MSE: 13.3631 \t Train RMSE: 3.6556]\n",
      "Validation loss decreased (14.061790 --> 13.363061).  Saving model ...\n",
      "Train Epoch: 16 [48/22032] \t Train Loss(MSE): 17.6761 \t Train RMSE: 4.2043\n",
      "Train Epoch: 16 [9648/22032] \t Train Loss(MSE): 14.9833 \t Train RMSE: 3.8708\n",
      "Train Epoch: 16 [19248/22032] \t Train Loss(MSE): 5.9179 \t Train RMSE: 2.4327\n",
      "[Epoch: 16 \t Valid MSE: 14.8396 \t Valid RMSE: 3.8522]\n",
      "[Epoch: 16 \t Train MSE: 13.2649 \t Train RMSE: 3.6421]\n",
      "Validation loss decreased (13.363061 --> 13.264864).  Saving model ...\n",
      "Train Epoch: 17 [48/22032] \t Train Loss(MSE): 12.0220 \t Train RMSE: 3.4673\n",
      "Train Epoch: 17 [9648/22032] \t Train Loss(MSE): 11.6011 \t Train RMSE: 3.4060\n",
      "Train Epoch: 17 [19248/22032] \t Train Loss(MSE): 7.4025 \t Train RMSE: 2.7207\n",
      "[Epoch: 17 \t Valid MSE: 17.5043 \t Valid RMSE: 4.1838]\n",
      "[Epoch: 17 \t Train MSE: 13.3551 \t Train RMSE: 3.6545]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 18 [48/22032] \t Train Loss(MSE): 20.9284 \t Train RMSE: 4.5748\n",
      "Train Epoch: 18 [9648/22032] \t Train Loss(MSE): 12.1314 \t Train RMSE: 3.4830\n",
      "Train Epoch: 18 [19248/22032] \t Train Loss(MSE): 10.7853 \t Train RMSE: 3.2841\n",
      "[Epoch: 18 \t Valid MSE: 19.7466 \t Valid RMSE: 4.4437]\n",
      "[Epoch: 18 \t Train MSE: 13.3221 \t Train RMSE: 3.6499]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 19 [48/22032] \t Train Loss(MSE): 8.5031 \t Train RMSE: 2.9160\n",
      "Train Epoch: 19 [9648/22032] \t Train Loss(MSE): 21.0149 \t Train RMSE: 4.5842\n",
      "Train Epoch: 19 [19248/22032] \t Train Loss(MSE): 15.7964 \t Train RMSE: 3.9745\n",
      "[Epoch: 19 \t Valid MSE: 14.3010 \t Valid RMSE: 3.7817]\n",
      "[Epoch: 19 \t Train MSE: 13.5984 \t Train RMSE: 3.6876]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 20 [48/22032] \t Train Loss(MSE): 12.7659 \t Train RMSE: 3.5729\n",
      "Train Epoch: 20 [9648/22032] \t Train Loss(MSE): 43.6170 \t Train RMSE: 6.6043\n",
      "Train Epoch: 20 [19248/22032] \t Train Loss(MSE): 10.1217 \t Train RMSE: 3.1815\n",
      "[Epoch: 20 \t Valid MSE: 17.2377 \t Valid RMSE: 4.1518]\n",
      "[Epoch: 20 \t Train MSE: 12.7574 \t Train RMSE: 3.5718]\n",
      "Validation loss decreased (13.264864 --> 12.757406).  Saving model ...\n",
      "Train Epoch: 21 [48/22032] \t Train Loss(MSE): 9.9389 \t Train RMSE: 3.1526\n",
      "Train Epoch: 21 [9648/22032] \t Train Loss(MSE): 16.1981 \t Train RMSE: 4.0247\n",
      "Train Epoch: 21 [19248/22032] \t Train Loss(MSE): 22.3625 \t Train RMSE: 4.7289\n",
      "[Epoch: 21 \t Valid MSE: 14.7153 \t Valid RMSE: 3.8361]\n",
      "[Epoch: 21 \t Train MSE: 12.5818 \t Train RMSE: 3.5471]\n",
      "Validation loss decreased (12.757406 --> 12.581834).  Saving model ...\n",
      "Train Epoch: 22 [48/22032] \t Train Loss(MSE): 9.0864 \t Train RMSE: 3.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [9648/22032] \t Train Loss(MSE): 7.2678 \t Train RMSE: 2.6959\n",
      "Train Epoch: 22 [19248/22032] \t Train Loss(MSE): 7.5252 \t Train RMSE: 2.7432\n",
      "[Epoch: 22 \t Valid MSE: 20.6875 \t Valid RMSE: 4.5484]\n",
      "[Epoch: 22 \t Train MSE: 12.4440 \t Train RMSE: 3.5276]\n",
      "Validation loss decreased (12.581834 --> 12.443999).  Saving model ...\n",
      "Train Epoch: 23 [48/22032] \t Train Loss(MSE): 15.0169 \t Train RMSE: 3.8752\n",
      "Train Epoch: 23 [9648/22032] \t Train Loss(MSE): 11.9881 \t Train RMSE: 3.4624\n",
      "Train Epoch: 23 [19248/22032] \t Train Loss(MSE): 16.2621 \t Train RMSE: 4.0326\n",
      "[Epoch: 23 \t Valid MSE: 25.7189 \t Valid RMSE: 5.0714]\n",
      "[Epoch: 23 \t Train MSE: 12.6265 \t Train RMSE: 3.5534]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 24 [48/22032] \t Train Loss(MSE): 15.8908 \t Train RMSE: 3.9863\n",
      "Train Epoch: 24 [9648/22032] \t Train Loss(MSE): 11.2444 \t Train RMSE: 3.3533\n",
      "Train Epoch: 24 [19248/22032] \t Train Loss(MSE): 11.0845 \t Train RMSE: 3.3293\n",
      "[Epoch: 24 \t Valid MSE: 14.3510 \t Valid RMSE: 3.7883]\n",
      "[Epoch: 24 \t Train MSE: 12.4798 \t Train RMSE: 3.5327]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 25 [48/22032] \t Train Loss(MSE): 14.3734 \t Train RMSE: 3.7912\n",
      "Train Epoch: 25 [9648/22032] \t Train Loss(MSE): 5.9996 \t Train RMSE: 2.4494\n",
      "Train Epoch: 25 [19248/22032] \t Train Loss(MSE): 8.1655 \t Train RMSE: 2.8575\n",
      "[Epoch: 25 \t Valid MSE: 14.8710 \t Valid RMSE: 3.8563]\n",
      "[Epoch: 25 \t Train MSE: 12.2379 \t Train RMSE: 3.4983]\n",
      "Validation loss decreased (12.443999 --> 12.237869).  Saving model ...\n",
      "Train Epoch: 26 [48/22032] \t Train Loss(MSE): 11.6543 \t Train RMSE: 3.4138\n",
      "Train Epoch: 26 [9648/22032] \t Train Loss(MSE): 13.4201 \t Train RMSE: 3.6634\n",
      "Train Epoch: 26 [19248/22032] \t Train Loss(MSE): 6.7696 \t Train RMSE: 2.6018\n",
      "[Epoch: 26 \t Valid MSE: 15.1490 \t Valid RMSE: 3.8922]\n",
      "[Epoch: 26 \t Train MSE: 12.2893 \t Train RMSE: 3.5056]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 27 [48/22032] \t Train Loss(MSE): 8.1829 \t Train RMSE: 2.8606\n",
      "Train Epoch: 27 [9648/22032] \t Train Loss(MSE): 10.8833 \t Train RMSE: 3.2990\n",
      "Train Epoch: 27 [19248/22032] \t Train Loss(MSE): 12.7242 \t Train RMSE: 3.5671\n",
      "[Epoch: 27 \t Valid MSE: 14.1817 \t Valid RMSE: 3.7659]\n",
      "[Epoch: 27 \t Train MSE: 12.0497 \t Train RMSE: 3.4713]\n",
      "Validation loss decreased (12.237869 --> 12.049745).  Saving model ...\n",
      "Train Epoch: 28 [48/22032] \t Train Loss(MSE): 4.3757 \t Train RMSE: 2.0918\n",
      "Train Epoch: 28 [9648/22032] \t Train Loss(MSE): 13.5062 \t Train RMSE: 3.6751\n",
      "Train Epoch: 28 [19248/22032] \t Train Loss(MSE): 12.2493 \t Train RMSE: 3.4999\n",
      "[Epoch: 28 \t Valid MSE: 17.9163 \t Valid RMSE: 4.2328]\n",
      "[Epoch: 28 \t Train MSE: 11.6043 \t Train RMSE: 3.4065]\n",
      "Validation loss decreased (12.049745 --> 11.604318).  Saving model ...\n",
      "Train Epoch: 29 [48/22032] \t Train Loss(MSE): 11.9880 \t Train RMSE: 3.4624\n",
      "Train Epoch: 29 [9648/22032] \t Train Loss(MSE): 20.8454 \t Train RMSE: 4.5657\n",
      "Train Epoch: 29 [19248/22032] \t Train Loss(MSE): 9.5937 \t Train RMSE: 3.0974\n",
      "[Epoch: 29 \t Valid MSE: 16.0123 \t Valid RMSE: 4.0015]\n",
      "[Epoch: 29 \t Train MSE: 12.5489 \t Train RMSE: 3.5424]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 30 [48/22032] \t Train Loss(MSE): 15.6521 \t Train RMSE: 3.9563\n",
      "Train Epoch: 30 [9648/22032] \t Train Loss(MSE): 10.2105 \t Train RMSE: 3.1954\n",
      "Train Epoch: 30 [19248/22032] \t Train Loss(MSE): 6.1364 \t Train RMSE: 2.4772\n",
      "[Epoch: 30 \t Valid MSE: 15.5350 \t Valid RMSE: 3.9414]\n",
      "[Epoch: 30 \t Train MSE: 11.6465 \t Train RMSE: 3.4127]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 31 [48/22032] \t Train Loss(MSE): 7.3223 \t Train RMSE: 2.7060\n",
      "Train Epoch: 31 [9648/22032] \t Train Loss(MSE): 9.4994 \t Train RMSE: 3.0821\n",
      "Train Epoch: 31 [19248/22032] \t Train Loss(MSE): 20.2310 \t Train RMSE: 4.4979\n",
      "[Epoch: 31 \t Valid MSE: 14.4067 \t Valid RMSE: 3.7956]\n",
      "[Epoch: 31 \t Train MSE: 11.6173 \t Train RMSE: 3.4084]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 32 [48/22032] \t Train Loss(MSE): 16.6298 \t Train RMSE: 4.0780\n",
      "Train Epoch: 32 [9648/22032] \t Train Loss(MSE): 12.8137 \t Train RMSE: 3.5796\n",
      "Train Epoch: 32 [19248/22032] \t Train Loss(MSE): 8.5058 \t Train RMSE: 2.9165\n",
      "[Epoch: 32 \t Valid MSE: 17.4475 \t Valid RMSE: 4.1770]\n",
      "[Epoch: 32 \t Train MSE: 11.3587 \t Train RMSE: 3.3703]\n",
      "Validation loss decreased (11.604318 --> 11.358697).  Saving model ...\n",
      "Train Epoch: 33 [48/22032] \t Train Loss(MSE): 6.5019 \t Train RMSE: 2.5499\n",
      "Train Epoch: 33 [9648/22032] \t Train Loss(MSE): 8.7899 \t Train RMSE: 2.9648\n",
      "Train Epoch: 33 [19248/22032] \t Train Loss(MSE): 21.5581 \t Train RMSE: 4.6431\n",
      "[Epoch: 33 \t Valid MSE: 20.8232 \t Valid RMSE: 4.5632]\n",
      "[Epoch: 33 \t Train MSE: 11.3576 \t Train RMSE: 3.3701]\n",
      "Validation loss decreased (11.358697 --> 11.357639).  Saving model ...\n",
      "Train Epoch: 34 [48/22032] \t Train Loss(MSE): 35.5320 \t Train RMSE: 5.9609\n",
      "Train Epoch: 34 [9648/22032] \t Train Loss(MSE): 6.0357 \t Train RMSE: 2.4568\n",
      "Train Epoch: 34 [19248/22032] \t Train Loss(MSE): 10.0598 \t Train RMSE: 3.1717\n",
      "[Epoch: 34 \t Valid MSE: 14.4751 \t Valid RMSE: 3.8046]\n",
      "[Epoch: 34 \t Train MSE: 11.1592 \t Train RMSE: 3.3405]\n",
      "Validation loss decreased (11.357639 --> 11.159181).  Saving model ...\n",
      "Train Epoch: 35 [48/22032] \t Train Loss(MSE): 8.7925 \t Train RMSE: 2.9652\n",
      "Train Epoch: 35 [9648/22032] \t Train Loss(MSE): 7.0972 \t Train RMSE: 2.6641\n",
      "Train Epoch: 35 [19248/22032] \t Train Loss(MSE): 7.3509 \t Train RMSE: 2.7112\n",
      "[Epoch: 35 \t Valid MSE: 15.1630 \t Valid RMSE: 3.8940]\n",
      "[Epoch: 35 \t Train MSE: 11.0589 \t Train RMSE: 3.3255]\n",
      "Validation loss decreased (11.159181 --> 11.058938).  Saving model ...\n",
      "Train Epoch: 36 [48/22032] \t Train Loss(MSE): 8.8597 \t Train RMSE: 2.9765\n",
      "Train Epoch: 36 [9648/22032] \t Train Loss(MSE): 10.9455 \t Train RMSE: 3.3084\n",
      "Train Epoch: 36 [19248/22032] \t Train Loss(MSE): 7.8217 \t Train RMSE: 2.7967\n",
      "[Epoch: 36 \t Valid MSE: 16.8882 \t Valid RMSE: 4.1095]\n",
      "[Epoch: 36 \t Train MSE: 10.9024 \t Train RMSE: 3.3019]\n",
      "Validation loss decreased (11.058938 --> 10.902351).  Saving model ...\n",
      "Train Epoch: 37 [48/22032] \t Train Loss(MSE): 11.0400 \t Train RMSE: 3.3226\n",
      "Train Epoch: 37 [9648/22032] \t Train Loss(MSE): 4.7924 \t Train RMSE: 2.1892\n",
      "Train Epoch: 37 [19248/22032] \t Train Loss(MSE): 7.0373 \t Train RMSE: 2.6528\n",
      "[Epoch: 37 \t Valid MSE: 13.6731 \t Valid RMSE: 3.6977]\n",
      "[Epoch: 37 \t Train MSE: 10.8084 \t Train RMSE: 3.2876]\n",
      "Validation loss decreased (10.902351 --> 10.808420).  Saving model ...\n",
      "Train Epoch: 38 [48/22032] \t Train Loss(MSE): 6.6246 \t Train RMSE: 2.5738\n",
      "Train Epoch: 38 [9648/22032] \t Train Loss(MSE): 6.0021 \t Train RMSE: 2.4499\n",
      "Train Epoch: 38 [19248/22032] \t Train Loss(MSE): 8.4973 \t Train RMSE: 2.9150\n",
      "[Epoch: 38 \t Valid MSE: 13.7641 \t Valid RMSE: 3.7100]\n",
      "[Epoch: 38 \t Train MSE: 11.2915 \t Train RMSE: 3.3603]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 39 [48/22032] \t Train Loss(MSE): 7.5809 \t Train RMSE: 2.7533\n",
      "Train Epoch: 39 [9648/22032] \t Train Loss(MSE): 4.6642 \t Train RMSE: 2.1597\n",
      "Train Epoch: 39 [19248/22032] \t Train Loss(MSE): 11.4536 \t Train RMSE: 3.3843\n",
      "[Epoch: 39 \t Valid MSE: 14.0917 \t Valid RMSE: 3.7539]\n",
      "[Epoch: 39 \t Train MSE: 10.5161 \t Train RMSE: 3.2428]\n",
      "Validation loss decreased (10.808420 --> 10.516066).  Saving model ...\n",
      "Train Epoch: 40 [48/22032] \t Train Loss(MSE): 9.4671 \t Train RMSE: 3.0769\n",
      "Train Epoch: 40 [9648/22032] \t Train Loss(MSE): 7.4212 \t Train RMSE: 2.7242\n",
      "Train Epoch: 40 [19248/22032] \t Train Loss(MSE): 8.0643 \t Train RMSE: 2.8398\n",
      "[Epoch: 40 \t Valid MSE: 14.6536 \t Valid RMSE: 3.8280]\n",
      "[Epoch: 40 \t Train MSE: 10.6263 \t Train RMSE: 3.2598]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 41 [48/22032] \t Train Loss(MSE): 10.1350 \t Train RMSE: 3.1836\n",
      "Train Epoch: 41 [9648/22032] \t Train Loss(MSE): 4.2175 \t Train RMSE: 2.0537\n",
      "Train Epoch: 41 [19248/22032] \t Train Loss(MSE): 9.0842 \t Train RMSE: 3.0140\n",
      "[Epoch: 41 \t Valid MSE: 16.0506 \t Valid RMSE: 4.0063]\n",
      "[Epoch: 41 \t Train MSE: 10.3965 \t Train RMSE: 3.2244]\n",
      "Validation loss decreased (10.516066 --> 10.396510).  Saving model ...\n",
      "Train Epoch: 42 [48/22032] \t Train Loss(MSE): 18.6992 \t Train RMSE: 4.3243\n",
      "Train Epoch: 42 [9648/22032] \t Train Loss(MSE): 14.3243 \t Train RMSE: 3.7847\n",
      "Train Epoch: 42 [19248/22032] \t Train Loss(MSE): 6.9398 \t Train RMSE: 2.6343\n",
      "[Epoch: 42 \t Valid MSE: 14.0525 \t Valid RMSE: 3.7487]\n",
      "[Epoch: 42 \t Train MSE: 10.3251 \t Train RMSE: 3.2133]\n",
      "Validation loss decreased (10.396510 --> 10.325134).  Saving model ...\n",
      "Train Epoch: 43 [48/22032] \t Train Loss(MSE): 5.3275 \t Train RMSE: 2.3081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [9648/22032] \t Train Loss(MSE): 11.6056 \t Train RMSE: 3.4067\n",
      "Train Epoch: 43 [19248/22032] \t Train Loss(MSE): 10.0099 \t Train RMSE: 3.1638\n",
      "[Epoch: 43 \t Valid MSE: 16.1166 \t Valid RMSE: 4.0145]\n",
      "[Epoch: 43 \t Train MSE: 10.2932 \t Train RMSE: 3.2083]\n",
      "Validation loss decreased (10.325134 --> 10.293213).  Saving model ...\n",
      "Train Epoch: 44 [48/22032] \t Train Loss(MSE): 6.3789 \t Train RMSE: 2.5257\n",
      "Train Epoch: 44 [9648/22032] \t Train Loss(MSE): 5.0128 \t Train RMSE: 2.2389\n",
      "Train Epoch: 44 [19248/22032] \t Train Loss(MSE): 5.8954 \t Train RMSE: 2.4280\n",
      "[Epoch: 44 \t Valid MSE: 14.8531 \t Valid RMSE: 3.8540]\n",
      "[Epoch: 44 \t Train MSE: 10.0714 \t Train RMSE: 3.1735]\n",
      "Validation loss decreased (10.293213 --> 10.071405).  Saving model ...\n",
      "Train Epoch: 45 [48/22032] \t Train Loss(MSE): 7.1139 \t Train RMSE: 2.6672\n",
      "Train Epoch: 45 [9648/22032] \t Train Loss(MSE): 11.5747 \t Train RMSE: 3.4022\n",
      "Train Epoch: 45 [19248/22032] \t Train Loss(MSE): 8.5521 \t Train RMSE: 2.9244\n",
      "[Epoch: 45 \t Valid MSE: 17.4558 \t Valid RMSE: 4.1780]\n",
      "[Epoch: 45 \t Train MSE: 10.1297 \t Train RMSE: 3.1827]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 46 [48/22032] \t Train Loss(MSE): 11.3835 \t Train RMSE: 3.3739\n",
      "Train Epoch: 46 [9648/22032] \t Train Loss(MSE): 5.4818 \t Train RMSE: 2.3413\n",
      "Train Epoch: 46 [19248/22032] \t Train Loss(MSE): 8.5514 \t Train RMSE: 2.9243\n",
      "[Epoch: 46 \t Valid MSE: 15.4244 \t Valid RMSE: 3.9274]\n",
      "[Epoch: 46 \t Train MSE: 10.1655 \t Train RMSE: 3.1883]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 47 [48/22032] \t Train Loss(MSE): 11.1855 \t Train RMSE: 3.3445\n",
      "Train Epoch: 47 [9648/22032] \t Train Loss(MSE): 3.7679 \t Train RMSE: 1.9411\n",
      "Train Epoch: 47 [19248/22032] \t Train Loss(MSE): 5.2464 \t Train RMSE: 2.2905\n",
      "[Epoch: 47 \t Valid MSE: 13.9383 \t Valid RMSE: 3.7334]\n",
      "[Epoch: 47 \t Train MSE: 9.9973 \t Train RMSE: 3.1619]\n",
      "Validation loss decreased (10.071405 --> 9.997298).  Saving model ...\n",
      "Train Epoch: 48 [48/22032] \t Train Loss(MSE): 2.5269 \t Train RMSE: 1.5896\n",
      "Train Epoch: 48 [9648/22032] \t Train Loss(MSE): 3.8811 \t Train RMSE: 1.9701\n",
      "Train Epoch: 48 [19248/22032] \t Train Loss(MSE): 4.8522 \t Train RMSE: 2.2028\n",
      "[Epoch: 48 \t Valid MSE: 14.0547 \t Valid RMSE: 3.7490]\n",
      "[Epoch: 48 \t Train MSE: 9.9947 \t Train RMSE: 3.1614]\n",
      "Validation loss decreased (9.997298 --> 9.994665).  Saving model ...\n",
      "Train Epoch: 49 [48/22032] \t Train Loss(MSE): 4.1159 \t Train RMSE: 2.0288\n",
      "Train Epoch: 49 [9648/22032] \t Train Loss(MSE): 7.2245 \t Train RMSE: 2.6878\n",
      "Train Epoch: 49 [19248/22032] \t Train Loss(MSE): 6.1846 \t Train RMSE: 2.4869\n",
      "[Epoch: 49 \t Valid MSE: 13.7522 \t Valid RMSE: 3.7084]\n",
      "[Epoch: 49 \t Train MSE: 9.7008 \t Train RMSE: 3.1146]\n",
      "Validation loss decreased (9.994665 --> 9.700840).  Saving model ...\n",
      "Train Epoch: 50 [48/22032] \t Train Loss(MSE): 7.0867 \t Train RMSE: 2.6621\n",
      "Train Epoch: 50 [9648/22032] \t Train Loss(MSE): 7.8072 \t Train RMSE: 2.7941\n",
      "Train Epoch: 50 [19248/22032] \t Train Loss(MSE): 6.0298 \t Train RMSE: 2.4556\n",
      "[Epoch: 50 \t Valid MSE: 14.1720 \t Valid RMSE: 3.7646]\n",
      "[Epoch: 50 \t Train MSE: 9.8254 \t Train RMSE: 3.1345]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 51 [48/22032] \t Train Loss(MSE): 6.6989 \t Train RMSE: 2.5882\n",
      "Train Epoch: 51 [9648/22032] \t Train Loss(MSE): 5.8708 \t Train RMSE: 2.4230\n",
      "Train Epoch: 51 [19248/22032] \t Train Loss(MSE): 14.5319 \t Train RMSE: 3.8121\n",
      "[Epoch: 51 \t Valid MSE: 14.0843 \t Valid RMSE: 3.7529]\n",
      "[Epoch: 51 \t Train MSE: 9.7155 \t Train RMSE: 3.1170]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 52 [48/22032] \t Train Loss(MSE): 4.1900 \t Train RMSE: 2.0469\n",
      "Train Epoch: 52 [9648/22032] \t Train Loss(MSE): 7.5491 \t Train RMSE: 2.7476\n",
      "Train Epoch: 52 [19248/22032] \t Train Loss(MSE): 10.8888 \t Train RMSE: 3.2998\n",
      "[Epoch: 52 \t Valid MSE: 14.3754 \t Valid RMSE: 3.7915]\n",
      "[Epoch: 52 \t Train MSE: 9.8104 \t Train RMSE: 3.1322]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 53 [48/22032] \t Train Loss(MSE): 9.0258 \t Train RMSE: 3.0043\n",
      "Train Epoch: 53 [9648/22032] \t Train Loss(MSE): 5.7187 \t Train RMSE: 2.3914\n",
      "Train Epoch: 53 [19248/22032] \t Train Loss(MSE): 4.2322 \t Train RMSE: 2.0572\n",
      "[Epoch: 53 \t Valid MSE: 15.0507 \t Valid RMSE: 3.8795]\n",
      "[Epoch: 53 \t Train MSE: 9.7842 \t Train RMSE: 3.1280]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 54 [48/22032] \t Train Loss(MSE): 6.6337 \t Train RMSE: 2.5756\n",
      "Train Epoch: 54 [9648/22032] \t Train Loss(MSE): 8.5221 \t Train RMSE: 2.9193\n",
      "Train Epoch: 54 [19248/22032] \t Train Loss(MSE): 6.8506 \t Train RMSE: 2.6174\n",
      "[Epoch: 54 \t Valid MSE: 13.8098 \t Valid RMSE: 3.7162]\n",
      "[Epoch: 54 \t Train MSE: 9.2498 \t Train RMSE: 3.0414]\n",
      "Validation loss decreased (9.700840 --> 9.249847).  Saving model ...\n",
      "Train Epoch: 55 [48/22032] \t Train Loss(MSE): 3.9757 \t Train RMSE: 1.9939\n",
      "Train Epoch: 55 [9648/22032] \t Train Loss(MSE): 6.2058 \t Train RMSE: 2.4911\n",
      "Train Epoch: 55 [19248/22032] \t Train Loss(MSE): 8.6680 \t Train RMSE: 2.9441\n",
      "[Epoch: 55 \t Valid MSE: 13.7064 \t Valid RMSE: 3.7022]\n",
      "[Epoch: 55 \t Train MSE: 9.4071 \t Train RMSE: 3.0671]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 56 [48/22032] \t Train Loss(MSE): 4.2452 \t Train RMSE: 2.0604\n",
      "Train Epoch: 56 [9648/22032] \t Train Loss(MSE): 9.3258 \t Train RMSE: 3.0538\n",
      "Train Epoch: 56 [19248/22032] \t Train Loss(MSE): 11.9985 \t Train RMSE: 3.4639\n",
      "[Epoch: 56 \t Valid MSE: 13.7517 \t Valid RMSE: 3.7083]\n",
      "[Epoch: 56 \t Train MSE: 9.2592 \t Train RMSE: 3.0429]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 57 [48/22032] \t Train Loss(MSE): 5.8261 \t Train RMSE: 2.4137\n",
      "Train Epoch: 57 [9648/22032] \t Train Loss(MSE): 6.2972 \t Train RMSE: 2.5094\n",
      "Train Epoch: 57 [19248/22032] \t Train Loss(MSE): 8.7664 \t Train RMSE: 2.9608\n",
      "[Epoch: 57 \t Valid MSE: 13.4967 \t Valid RMSE: 3.6738]\n",
      "[Epoch: 57 \t Train MSE: 9.0587 \t Train RMSE: 3.0098]\n",
      "Validation loss decreased (9.249847 --> 9.058745).  Saving model ...\n",
      "Train Epoch: 58 [48/22032] \t Train Loss(MSE): 7.1664 \t Train RMSE: 2.6770\n",
      "Train Epoch: 58 [9648/22032] \t Train Loss(MSE): 8.8357 \t Train RMSE: 2.9725\n",
      "Train Epoch: 58 [19248/22032] \t Train Loss(MSE): 18.6256 \t Train RMSE: 4.3157\n",
      "[Epoch: 58 \t Valid MSE: 14.2808 \t Valid RMSE: 3.7790]\n",
      "[Epoch: 58 \t Train MSE: 9.0350 \t Train RMSE: 3.0058]\n",
      "Validation loss decreased (9.058745 --> 9.034988).  Saving model ...\n",
      "Train Epoch: 59 [48/22032] \t Train Loss(MSE): 5.1574 \t Train RMSE: 2.2710\n",
      "Train Epoch: 59 [9648/22032] \t Train Loss(MSE): 11.7042 \t Train RMSE: 3.4211\n",
      "Train Epoch: 59 [19248/22032] \t Train Loss(MSE): 10.3148 \t Train RMSE: 3.2117\n",
      "[Epoch: 59 \t Valid MSE: 14.7832 \t Valid RMSE: 3.8449]\n",
      "[Epoch: 59 \t Train MSE: 9.6779 \t Train RMSE: 3.1109]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 60 [48/22032] \t Train Loss(MSE): 7.2962 \t Train RMSE: 2.7012\n",
      "Train Epoch: 60 [9648/22032] \t Train Loss(MSE): 10.3126 \t Train RMSE: 3.2113\n",
      "Train Epoch: 60 [19248/22032] \t Train Loss(MSE): 9.2545 \t Train RMSE: 3.0421\n",
      "[Epoch: 60 \t Valid MSE: 14.0332 \t Valid RMSE: 3.7461]\n",
      "[Epoch: 60 \t Train MSE: 10.0482 \t Train RMSE: 3.1699]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 61 [48/22032] \t Train Loss(MSE): 9.3402 \t Train RMSE: 3.0562\n",
      "Train Epoch: 61 [9648/22032] \t Train Loss(MSE): 22.4639 \t Train RMSE: 4.7396\n",
      "Train Epoch: 61 [19248/22032] \t Train Loss(MSE): 8.5697 \t Train RMSE: 2.9274\n",
      "[Epoch: 61 \t Valid MSE: 13.4486 \t Valid RMSE: 3.6672]\n",
      "[Epoch: 61 \t Train MSE: 9.3248 \t Train RMSE: 3.0536]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 62 [48/22032] \t Train Loss(MSE): 4.7550 \t Train RMSE: 2.1806\n",
      "Train Epoch: 62 [9648/22032] \t Train Loss(MSE): 11.9820 \t Train RMSE: 3.4615\n",
      "Train Epoch: 62 [19248/22032] \t Train Loss(MSE): 16.3312 \t Train RMSE: 4.0412\n",
      "[Epoch: 62 \t Valid MSE: 14.3402 \t Valid RMSE: 3.7869]\n",
      "[Epoch: 62 \t Train MSE: 9.3690 \t Train RMSE: 3.0609]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 63 [48/22032] \t Train Loss(MSE): 8.8557 \t Train RMSE: 2.9758\n",
      "Train Epoch: 63 [9648/22032] \t Train Loss(MSE): 7.2473 \t Train RMSE: 2.6921\n",
      "Train Epoch: 63 [19248/22032] \t Train Loss(MSE): 10.2341 \t Train RMSE: 3.1991\n",
      "[Epoch: 63 \t Valid MSE: 16.7004 \t Valid RMSE: 4.0866]\n",
      "[Epoch: 63 \t Train MSE: 9.1471 \t Train RMSE: 3.0244]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 64 [48/22032] \t Train Loss(MSE): 12.4263 \t Train RMSE: 3.5251\n",
      "Train Epoch: 64 [9648/22032] \t Train Loss(MSE): 12.0391 \t Train RMSE: 3.4697\n",
      "Train Epoch: 64 [19248/22032] \t Train Loss(MSE): 7.3865 \t Train RMSE: 2.7178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 64 \t Valid MSE: 13.8308 \t Valid RMSE: 3.7190]\n",
      "[Epoch: 64 \t Train MSE: 9.1291 \t Train RMSE: 3.0214]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 65 [48/22032] \t Train Loss(MSE): 4.5612 \t Train RMSE: 2.1357\n",
      "Train Epoch: 65 [9648/22032] \t Train Loss(MSE): 3.5159 \t Train RMSE: 1.8751\n",
      "Train Epoch: 65 [19248/22032] \t Train Loss(MSE): 2.9507 \t Train RMSE: 1.7178\n",
      "[Epoch: 65 \t Valid MSE: 14.3241 \t Valid RMSE: 3.7847]\n",
      "[Epoch: 65 \t Train MSE: 8.8381 \t Train RMSE: 2.9729]\n",
      "Validation loss decreased (9.034988 --> 8.838101).  Saving model ...\n",
      "Train Epoch: 66 [48/22032] \t Train Loss(MSE): 7.2794 \t Train RMSE: 2.6980\n",
      "Train Epoch: 66 [9648/22032] \t Train Loss(MSE): 4.3786 \t Train RMSE: 2.0925\n",
      "Train Epoch: 66 [19248/22032] \t Train Loss(MSE): 17.8089 \t Train RMSE: 4.2201\n",
      "[Epoch: 66 \t Valid MSE: 14.2947 \t Valid RMSE: 3.7808]\n",
      "[Epoch: 66 \t Train MSE: 8.8200 \t Train RMSE: 2.9698]\n",
      "Validation loss decreased (8.838101 --> 8.819967).  Saving model ...\n",
      "Train Epoch: 67 [48/22032] \t Train Loss(MSE): 5.9255 \t Train RMSE: 2.4342\n",
      "Train Epoch: 67 [9648/22032] \t Train Loss(MSE): 3.2586 \t Train RMSE: 1.8052\n",
      "Train Epoch: 67 [19248/22032] \t Train Loss(MSE): 9.7761 \t Train RMSE: 3.1267\n",
      "[Epoch: 67 \t Valid MSE: 14.4721 \t Valid RMSE: 3.8042]\n",
      "[Epoch: 67 \t Train MSE: 8.5497 \t Train RMSE: 2.9240]\n",
      "Validation loss decreased (8.819967 --> 8.549744).  Saving model ...\n",
      "Train Epoch: 68 [48/22032] \t Train Loss(MSE): 22.9766 \t Train RMSE: 4.7934\n",
      "Train Epoch: 68 [9648/22032] \t Train Loss(MSE): 29.8243 \t Train RMSE: 5.4612\n",
      "Train Epoch: 68 [19248/22032] \t Train Loss(MSE): 13.6126 \t Train RMSE: 3.6895\n",
      "[Epoch: 68 \t Valid MSE: 14.2698 \t Valid RMSE: 3.7775]\n",
      "[Epoch: 68 \t Train MSE: 8.7940 \t Train RMSE: 2.9655]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 69 [48/22032] \t Train Loss(MSE): 8.9917 \t Train RMSE: 2.9986\n",
      "Train Epoch: 69 [9648/22032] \t Train Loss(MSE): 5.0880 \t Train RMSE: 2.2557\n",
      "Train Epoch: 69 [19248/22032] \t Train Loss(MSE): 10.3825 \t Train RMSE: 3.2222\n",
      "[Epoch: 69 \t Valid MSE: 14.5536 \t Valid RMSE: 3.8149]\n",
      "[Epoch: 69 \t Train MSE: 8.6422 \t Train RMSE: 2.9398]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 70 [48/22032] \t Train Loss(MSE): 4.8585 \t Train RMSE: 2.2042\n",
      "Train Epoch: 70 [9648/22032] \t Train Loss(MSE): 7.4235 \t Train RMSE: 2.7246\n",
      "Train Epoch: 70 [19248/22032] \t Train Loss(MSE): 4.3621 \t Train RMSE: 2.0886\n",
      "[Epoch: 70 \t Valid MSE: 15.6919 \t Valid RMSE: 3.9613]\n",
      "[Epoch: 70 \t Train MSE: 9.1431 \t Train RMSE: 3.0237]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 71 [48/22032] \t Train Loss(MSE): 11.6180 \t Train RMSE: 3.4085\n",
      "Train Epoch: 71 [9648/22032] \t Train Loss(MSE): 4.1507 \t Train RMSE: 2.0373\n",
      "Train Epoch: 71 [19248/22032] \t Train Loss(MSE): 19.1867 \t Train RMSE: 4.3803\n",
      "[Epoch: 71 \t Valid MSE: 13.8837 \t Valid RMSE: 3.7261]\n",
      "[Epoch: 71 \t Train MSE: 8.7277 \t Train RMSE: 2.9543]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 72 [48/22032] \t Train Loss(MSE): 7.2122 \t Train RMSE: 2.6855\n",
      "Train Epoch: 72 [9648/22032] \t Train Loss(MSE): 10.9659 \t Train RMSE: 3.3115\n",
      "Train Epoch: 72 [19248/22032] \t Train Loss(MSE): 7.9883 \t Train RMSE: 2.8264\n",
      "[Epoch: 72 \t Valid MSE: 14.3007 \t Valid RMSE: 3.7816]\n",
      "[Epoch: 72 \t Train MSE: 8.2842 \t Train RMSE: 2.8782]\n",
      "Validation loss decreased (8.549744 --> 8.284178).  Saving model ...\n",
      "Train Epoch: 73 [48/22032] \t Train Loss(MSE): 4.8760 \t Train RMSE: 2.2082\n",
      "Train Epoch: 73 [9648/22032] \t Train Loss(MSE): 4.1383 \t Train RMSE: 2.0343\n",
      "Train Epoch: 73 [19248/22032] \t Train Loss(MSE): 7.9135 \t Train RMSE: 2.8131\n",
      "[Epoch: 73 \t Valid MSE: 14.4629 \t Valid RMSE: 3.8030]\n",
      "[Epoch: 73 \t Train MSE: 8.5328 \t Train RMSE: 2.9211]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 74 [48/22032] \t Train Loss(MSE): 3.7679 \t Train RMSE: 1.9411\n",
      "Train Epoch: 74 [9648/22032] \t Train Loss(MSE): 4.7315 \t Train RMSE: 2.1752\n",
      "Train Epoch: 74 [19248/22032] \t Train Loss(MSE): 12.9817 \t Train RMSE: 3.6030\n",
      "[Epoch: 74 \t Valid MSE: 14.2107 \t Valid RMSE: 3.7697]\n",
      "[Epoch: 74 \t Train MSE: 8.1040 \t Train RMSE: 2.8468]\n",
      "Validation loss decreased (8.284178 --> 8.104033).  Saving model ...\n",
      "Train Epoch: 75 [48/22032] \t Train Loss(MSE): 6.8491 \t Train RMSE: 2.6171\n",
      "Train Epoch: 75 [9648/22032] \t Train Loss(MSE): 10.6572 \t Train RMSE: 3.2645\n",
      "Train Epoch: 75 [19248/22032] \t Train Loss(MSE): 21.9755 \t Train RMSE: 4.6878\n",
      "[Epoch: 75 \t Valid MSE: 14.9176 \t Valid RMSE: 3.8623]\n",
      "[Epoch: 75 \t Train MSE: 9.0941 \t Train RMSE: 3.0156]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 76 [48/22032] \t Train Loss(MSE): 7.2209 \t Train RMSE: 2.6872\n",
      "Train Epoch: 76 [9648/22032] \t Train Loss(MSE): 3.8196 \t Train RMSE: 1.9544\n",
      "Train Epoch: 76 [19248/22032] \t Train Loss(MSE): 8.1334 \t Train RMSE: 2.8519\n",
      "[Epoch: 76 \t Valid MSE: 15.8045 \t Valid RMSE: 3.9755]\n",
      "[Epoch: 76 \t Train MSE: 8.8861 \t Train RMSE: 2.9810]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 77 [48/22032] \t Train Loss(MSE): 10.4915 \t Train RMSE: 3.2391\n",
      "Train Epoch: 77 [9648/22032] \t Train Loss(MSE): 7.2577 \t Train RMSE: 2.6940\n",
      "Train Epoch: 77 [19248/22032] \t Train Loss(MSE): 10.3108 \t Train RMSE: 3.2110\n",
      "[Epoch: 77 \t Valid MSE: 14.6924 \t Valid RMSE: 3.8331]\n",
      "[Epoch: 77 \t Train MSE: 8.2071 \t Train RMSE: 2.8648]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 78 [48/22032] \t Train Loss(MSE): 10.3298 \t Train RMSE: 3.2140\n",
      "Train Epoch: 78 [9648/22032] \t Train Loss(MSE): 4.8890 \t Train RMSE: 2.2111\n",
      "Train Epoch: 78 [19248/22032] \t Train Loss(MSE): 6.0138 \t Train RMSE: 2.4523\n",
      "[Epoch: 78 \t Valid MSE: 14.7233 \t Valid RMSE: 3.8371]\n",
      "[Epoch: 78 \t Train MSE: 8.0787 \t Train RMSE: 2.8423]\n",
      "Validation loss decreased (8.104033 --> 8.078675).  Saving model ...\n",
      "Train Epoch: 79 [48/22032] \t Train Loss(MSE): 2.8740 \t Train RMSE: 1.6953\n",
      "Train Epoch: 79 [9648/22032] \t Train Loss(MSE): 6.0333 \t Train RMSE: 2.4563\n",
      "Train Epoch: 79 [19248/22032] \t Train Loss(MSE): 6.6400 \t Train RMSE: 2.5768\n",
      "[Epoch: 79 \t Valid MSE: 14.0906 \t Valid RMSE: 3.7537]\n",
      "[Epoch: 79 \t Train MSE: 7.8692 \t Train RMSE: 2.8052]\n",
      "Validation loss decreased (8.078675 --> 7.869206).  Saving model ...\n",
      "Train Epoch: 80 [48/22032] \t Train Loss(MSE): 4.5476 \t Train RMSE: 2.1325\n",
      "Train Epoch: 80 [9648/22032] \t Train Loss(MSE): 6.9776 \t Train RMSE: 2.6415\n",
      "Train Epoch: 80 [19248/22032] \t Train Loss(MSE): 11.3331 \t Train RMSE: 3.3665\n",
      "[Epoch: 80 \t Valid MSE: 14.1501 \t Valid RMSE: 3.7617]\n",
      "[Epoch: 80 \t Train MSE: 8.0537 \t Train RMSE: 2.8379]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 81 [48/22032] \t Train Loss(MSE): 5.3513 \t Train RMSE: 2.3133\n",
      "Train Epoch: 81 [9648/22032] \t Train Loss(MSE): 4.8755 \t Train RMSE: 2.2080\n",
      "Train Epoch: 81 [19248/22032] \t Train Loss(MSE): 2.5663 \t Train RMSE: 1.6020\n",
      "[Epoch: 81 \t Valid MSE: 13.9045 \t Valid RMSE: 3.7289]\n",
      "[Epoch: 81 \t Train MSE: 7.6593 \t Train RMSE: 2.7675]\n",
      "Validation loss decreased (7.869206 --> 7.659320).  Saving model ...\n",
      "Train Epoch: 82 [48/22032] \t Train Loss(MSE): 3.4467 \t Train RMSE: 1.8565\n",
      "Train Epoch: 82 [9648/22032] \t Train Loss(MSE): 4.6511 \t Train RMSE: 2.1567\n",
      "Train Epoch: 82 [19248/22032] \t Train Loss(MSE): 7.9308 \t Train RMSE: 2.8162\n",
      "[Epoch: 82 \t Valid MSE: 14.4828 \t Valid RMSE: 3.8056]\n",
      "[Epoch: 82 \t Train MSE: 7.7084 \t Train RMSE: 2.7764]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 83 [48/22032] \t Train Loss(MSE): 3.5655 \t Train RMSE: 1.8883\n",
      "Train Epoch: 83 [9648/22032] \t Train Loss(MSE): 34.1555 \t Train RMSE: 5.8443\n",
      "Train Epoch: 83 [19248/22032] \t Train Loss(MSE): 10.0468 \t Train RMSE: 3.1697\n",
      "[Epoch: 83 \t Valid MSE: 14.9180 \t Valid RMSE: 3.8624]\n",
      "[Epoch: 83 \t Train MSE: 7.8418 \t Train RMSE: 2.8003]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 84 [48/22032] \t Train Loss(MSE): 9.8279 \t Train RMSE: 3.1350\n",
      "Train Epoch: 84 [9648/22032] \t Train Loss(MSE): 2.4753 \t Train RMSE: 1.5733\n",
      "Train Epoch: 84 [19248/22032] \t Train Loss(MSE): 4.9282 \t Train RMSE: 2.2199\n",
      "[Epoch: 84 \t Valid MSE: 13.7528 \t Valid RMSE: 3.7085]\n",
      "[Epoch: 84 \t Train MSE: 7.4237 \t Train RMSE: 2.7246]\n",
      "Validation loss decreased (7.659320 --> 7.423713).  Saving model ...\n",
      "Train Epoch: 85 [48/22032] \t Train Loss(MSE): 8.2980 \t Train RMSE: 2.8806\n",
      "Train Epoch: 85 [9648/22032] \t Train Loss(MSE): 5.8609 \t Train RMSE: 2.4209\n",
      "Train Epoch: 85 [19248/22032] \t Train Loss(MSE): 2.9409 \t Train RMSE: 1.7149\n",
      "[Epoch: 85 \t Valid MSE: 14.6081 \t Valid RMSE: 3.8221]\n",
      "[Epoch: 85 \t Train MSE: 7.5462 \t Train RMSE: 2.7470]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 86 [48/22032] \t Train Loss(MSE): 4.9009 \t Train RMSE: 2.2138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 86 [9648/22032] \t Train Loss(MSE): 3.4493 \t Train RMSE: 1.8572\n",
      "Train Epoch: 86 [19248/22032] \t Train Loss(MSE): 5.9565 \t Train RMSE: 2.4406\n",
      "[Epoch: 86 \t Valid MSE: 14.4255 \t Valid RMSE: 3.7981]\n",
      "[Epoch: 86 \t Train MSE: 8.0799 \t Train RMSE: 2.8425]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 87 [48/22032] \t Train Loss(MSE): 5.7288 \t Train RMSE: 2.3935\n",
      "Train Epoch: 87 [9648/22032] \t Train Loss(MSE): 3.8901 \t Train RMSE: 1.9723\n",
      "Train Epoch: 87 [19248/22032] \t Train Loss(MSE): 3.9782 \t Train RMSE: 1.9945\n",
      "[Epoch: 87 \t Valid MSE: 14.1618 \t Valid RMSE: 3.7632]\n",
      "[Epoch: 87 \t Train MSE: 7.5271 \t Train RMSE: 2.7436]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 88 [48/22032] \t Train Loss(MSE): 1.7066 \t Train RMSE: 1.3064\n",
      "Train Epoch: 88 [9648/22032] \t Train Loss(MSE): 30.1688 \t Train RMSE: 5.4926\n",
      "Train Epoch: 88 [19248/22032] \t Train Loss(MSE): 11.0757 \t Train RMSE: 3.3280\n",
      "[Epoch: 88 \t Valid MSE: 14.8363 \t Valid RMSE: 3.8518]\n",
      "[Epoch: 88 \t Train MSE: 7.3358 \t Train RMSE: 2.7085]\n",
      "Validation loss decreased (7.423713 --> 7.335820).  Saving model ...\n",
      "Train Epoch: 89 [48/22032] \t Train Loss(MSE): 4.0934 \t Train RMSE: 2.0232\n",
      "Train Epoch: 89 [9648/22032] \t Train Loss(MSE): 3.4816 \t Train RMSE: 1.8659\n",
      "Train Epoch: 89 [19248/22032] \t Train Loss(MSE): 2.7379 \t Train RMSE: 1.6547\n",
      "[Epoch: 89 \t Valid MSE: 14.7026 \t Valid RMSE: 3.8344]\n",
      "[Epoch: 89 \t Train MSE: 7.0997 \t Train RMSE: 2.6645]\n",
      "Validation loss decreased (7.335820 --> 7.099683).  Saving model ...\n",
      "Train Epoch: 90 [48/22032] \t Train Loss(MSE): 3.3279 \t Train RMSE: 1.8242\n",
      "Train Epoch: 90 [9648/22032] \t Train Loss(MSE): 2.7776 \t Train RMSE: 1.6666\n",
      "Train Epoch: 90 [19248/22032] \t Train Loss(MSE): 4.2062 \t Train RMSE: 2.0509\n",
      "[Epoch: 90 \t Valid MSE: 15.0835 \t Valid RMSE: 3.8837]\n",
      "[Epoch: 90 \t Train MSE: 7.1112 \t Train RMSE: 2.6667]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 91 [48/22032] \t Train Loss(MSE): 2.0386 \t Train RMSE: 1.4278\n",
      "Train Epoch: 91 [9648/22032] \t Train Loss(MSE): 5.8561 \t Train RMSE: 2.4199\n",
      "Train Epoch: 91 [19248/22032] \t Train Loss(MSE): 5.6774 \t Train RMSE: 2.3827\n",
      "[Epoch: 91 \t Valid MSE: 14.7294 \t Valid RMSE: 3.8379]\n",
      "[Epoch: 91 \t Train MSE: 7.1742 \t Train RMSE: 2.6785]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 92 [48/22032] \t Train Loss(MSE): 3.1155 \t Train RMSE: 1.7651\n",
      "Train Epoch: 92 [9648/22032] \t Train Loss(MSE): 33.7314 \t Train RMSE: 5.8079\n",
      "Train Epoch: 92 [19248/22032] \t Train Loss(MSE): 15.7871 \t Train RMSE: 3.9733\n",
      "[Epoch: 92 \t Valid MSE: 14.3483 \t Valid RMSE: 3.7879]\n",
      "[Epoch: 92 \t Train MSE: 7.5165 \t Train RMSE: 2.7416]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 93 [48/22032] \t Train Loss(MSE): 5.4187 \t Train RMSE: 2.3278\n",
      "Train Epoch: 93 [9648/22032] \t Train Loss(MSE): 11.8976 \t Train RMSE: 3.4493\n",
      "Train Epoch: 93 [19248/22032] \t Train Loss(MSE): 4.7095 \t Train RMSE: 2.1701\n",
      "[Epoch: 93 \t Valid MSE: 15.0401 \t Valid RMSE: 3.8782]\n",
      "[Epoch: 93 \t Train MSE: 7.5253 \t Train RMSE: 2.7432]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 94 [48/22032] \t Train Loss(MSE): 4.0172 \t Train RMSE: 2.0043\n",
      "Train Epoch: 94 [9648/22032] \t Train Loss(MSE): 5.3621 \t Train RMSE: 2.3156\n",
      "Train Epoch: 94 [19248/22032] \t Train Loss(MSE): 4.4121 \t Train RMSE: 2.1005\n",
      "[Epoch: 94 \t Valid MSE: 14.8739 \t Valid RMSE: 3.8567]\n",
      "[Epoch: 94 \t Train MSE: 7.0414 \t Train RMSE: 2.6536]\n",
      "Validation loss decreased (7.099683 --> 7.041401).  Saving model ...\n",
      "Train Epoch: 95 [48/22032] \t Train Loss(MSE): 2.2122 \t Train RMSE: 1.4874\n",
      "Train Epoch: 95 [9648/22032] \t Train Loss(MSE): 7.7603 \t Train RMSE: 2.7857\n",
      "Train Epoch: 95 [19248/22032] \t Train Loss(MSE): 3.9342 \t Train RMSE: 1.9835\n",
      "[Epoch: 95 \t Valid MSE: 15.3244 \t Valid RMSE: 3.9146]\n",
      "[Epoch: 95 \t Train MSE: 27.5436 \t Train RMSE: 5.2482]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 96 [48/22032] \t Train Loss(MSE): 5.0815 \t Train RMSE: 2.2542\n",
      "Train Epoch: 96 [9648/22032] \t Train Loss(MSE): 4.6357 \t Train RMSE: 2.1531\n",
      "Train Epoch: 96 [19248/22032] \t Train Loss(MSE): 2.1899 \t Train RMSE: 1.4798\n",
      "[Epoch: 96 \t Valid MSE: 15.5100 \t Valid RMSE: 3.9383]\n",
      "[Epoch: 96 \t Train MSE: 7.4784 \t Train RMSE: 2.7347]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 97 [48/22032] \t Train Loss(MSE): 10.6505 \t Train RMSE: 3.2635\n",
      "Train Epoch: 97 [9648/22032] \t Train Loss(MSE): 12.6541 \t Train RMSE: 3.5573\n",
      "Train Epoch: 97 [19248/22032] \t Train Loss(MSE): 15.5108 \t Train RMSE: 3.9384\n",
      "[Epoch: 97 \t Valid MSE: 16.0344 \t Valid RMSE: 4.0043]\n",
      "[Epoch: 97 \t Train MSE: 7.6730 \t Train RMSE: 2.7700]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 98 [48/22032] \t Train Loss(MSE): 2.7695 \t Train RMSE: 1.6642\n",
      "Train Epoch: 98 [9648/22032] \t Train Loss(MSE): 5.3268 \t Train RMSE: 2.3080\n",
      "Train Epoch: 98 [19248/22032] \t Train Loss(MSE): 9.4633 \t Train RMSE: 3.0763\n",
      "[Epoch: 98 \t Valid MSE: 16.0271 \t Valid RMSE: 4.0034]\n",
      "[Epoch: 98 \t Train MSE: 7.4801 \t Train RMSE: 2.7350]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 99 [48/22032] \t Train Loss(MSE): 2.8658 \t Train RMSE: 1.6929\n",
      "Train Epoch: 99 [9648/22032] \t Train Loss(MSE): 2.2461 \t Train RMSE: 1.4987\n",
      "Train Epoch: 99 [19248/22032] \t Train Loss(MSE): 5.6729 \t Train RMSE: 2.3818\n",
      "[Epoch: 99 \t Valid MSE: 15.3719 \t Valid RMSE: 3.9207]\n",
      "[Epoch: 99 \t Train MSE: 8.0702 \t Train RMSE: 2.8408]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 100 [48/22032] \t Train Loss(MSE): 13.4206 \t Train RMSE: 3.6634\n",
      "Train Epoch: 100 [9648/22032] \t Train Loss(MSE): 4.9276 \t Train RMSE: 2.2198\n",
      "Train Epoch: 100 [19248/22032] \t Train Loss(MSE): 4.3283 \t Train RMSE: 2.0804\n",
      "[Epoch: 100 \t Valid MSE: 16.1939 \t Valid RMSE: 4.0242]\n",
      "[Epoch: 100 \t Train MSE: 8.1538 \t Train RMSE: 2.8555]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 101 [48/22032] \t Train Loss(MSE): 7.4026 \t Train RMSE: 2.7208\n",
      "Train Epoch: 101 [9648/22032] \t Train Loss(MSE): 4.6826 \t Train RMSE: 2.1639\n",
      "Train Epoch: 101 [19248/22032] \t Train Loss(MSE): 4.0632 \t Train RMSE: 2.0157\n",
      "[Epoch: 101 \t Valid MSE: 15.4236 \t Valid RMSE: 3.9273]\n",
      "[Epoch: 101 \t Train MSE: 8.0255 \t Train RMSE: 2.8329]\n",
      "EarlyStopping counter: 7 out of 40\n",
      "Train Epoch: 102 [48/22032] \t Train Loss(MSE): 6.5959 \t Train RMSE: 2.5683\n",
      "Train Epoch: 102 [9648/22032] \t Train Loss(MSE): 15.6137 \t Train RMSE: 3.9514\n",
      "Train Epoch: 102 [19248/22032] \t Train Loss(MSE): 23.2030 \t Train RMSE: 4.8170\n",
      "[Epoch: 102 \t Valid MSE: 15.9924 \t Valid RMSE: 3.9990]\n",
      "[Epoch: 102 \t Train MSE: 8.2266 \t Train RMSE: 2.8682]\n",
      "EarlyStopping counter: 8 out of 40\n",
      "Train Epoch: 103 [48/22032] \t Train Loss(MSE): 11.0424 \t Train RMSE: 3.3230\n",
      "Train Epoch: 103 [9648/22032] \t Train Loss(MSE): 3.8921 \t Train RMSE: 1.9728\n",
      "Train Epoch: 103 [19248/22032] \t Train Loss(MSE): 5.0026 \t Train RMSE: 2.2367\n",
      "[Epoch: 103 \t Valid MSE: 15.2599 \t Valid RMSE: 3.9064]\n",
      "[Epoch: 103 \t Train MSE: 8.0221 \t Train RMSE: 2.8323]\n",
      "EarlyStopping counter: 9 out of 40\n",
      "Train Epoch: 104 [48/22032] \t Train Loss(MSE): 11.9045 \t Train RMSE: 3.4503\n",
      "Train Epoch: 104 [9648/22032] \t Train Loss(MSE): 3.3950 \t Train RMSE: 1.8426\n",
      "Train Epoch: 104 [19248/22032] \t Train Loss(MSE): 7.0761 \t Train RMSE: 2.6601\n",
      "[Epoch: 104 \t Valid MSE: 15.6380 \t Valid RMSE: 3.9545]\n",
      "[Epoch: 104 \t Train MSE: 7.7665 \t Train RMSE: 2.7868]\n",
      "EarlyStopping counter: 10 out of 40\n",
      "Train Epoch: 105 [48/22032] \t Train Loss(MSE): 30.7759 \t Train RMSE: 5.5476\n",
      "Train Epoch: 105 [9648/22032] \t Train Loss(MSE): 14.0057 \t Train RMSE: 3.7424\n",
      "Train Epoch: 105 [19248/22032] \t Train Loss(MSE): 6.7787 \t Train RMSE: 2.6036\n",
      "[Epoch: 105 \t Valid MSE: 16.9553 \t Valid RMSE: 4.1177]\n",
      "[Epoch: 105 \t Train MSE: 7.5776 \t Train RMSE: 2.7527]\n",
      "Epoch   105: reducing learning rate of group 0 to 5.0000e-03.\n",
      "EarlyStopping counter: 11 out of 40\n",
      "Train Epoch: 106 [48/22032] \t Train Loss(MSE): 5.5156 \t Train RMSE: 2.3485\n",
      "Train Epoch: 106 [9648/22032] \t Train Loss(MSE): 12.0709 \t Train RMSE: 3.4743\n",
      "Train Epoch: 106 [19248/22032] \t Train Loss(MSE): 2.2702 \t Train RMSE: 1.5067\n",
      "[Epoch: 106 \t Valid MSE: 15.3051 \t Valid RMSE: 3.9122]\n",
      "[Epoch: 106 \t Train MSE: 6.5287 \t Train RMSE: 2.5551]\n",
      "Validation loss decreased (7.041401 --> 6.528729).  Saving model ...\n",
      "Train Epoch: 107 [48/22032] \t Train Loss(MSE): 3.0560 \t Train RMSE: 1.7481\n",
      "Train Epoch: 107 [9648/22032] \t Train Loss(MSE): 2.3810 \t Train RMSE: 1.5431\n",
      "Train Epoch: 107 [19248/22032] \t Train Loss(MSE): 5.5739 \t Train RMSE: 2.3609\n",
      "[Epoch: 107 \t Valid MSE: 14.6772 \t Valid RMSE: 3.8311]\n",
      "[Epoch: 107 \t Train MSE: 6.2090 \t Train RMSE: 2.4918]\n",
      "Validation loss decreased (6.528729 --> 6.209011).  Saving model ...\n",
      "Train Epoch: 108 [48/22032] \t Train Loss(MSE): 7.7276 \t Train RMSE: 2.7799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 108 [9648/22032] \t Train Loss(MSE): 24.2012 \t Train RMSE: 4.9195\n",
      "Train Epoch: 108 [19248/22032] \t Train Loss(MSE): 3.8107 \t Train RMSE: 1.9521\n",
      "[Epoch: 108 \t Valid MSE: 15.2993 \t Valid RMSE: 3.9114]\n",
      "[Epoch: 108 \t Train MSE: 6.0833 \t Train RMSE: 2.4664]\n",
      "Validation loss decreased (6.209011 --> 6.083284).  Saving model ...\n",
      "Train Epoch: 109 [48/22032] \t Train Loss(MSE): 3.1759 \t Train RMSE: 1.7821\n",
      "Train Epoch: 109 [9648/22032] \t Train Loss(MSE): 3.9198 \t Train RMSE: 1.9798\n",
      "Train Epoch: 109 [19248/22032] \t Train Loss(MSE): 4.3843 \t Train RMSE: 2.0939\n",
      "[Epoch: 109 \t Valid MSE: 15.0432 \t Valid RMSE: 3.8786]\n",
      "[Epoch: 109 \t Train MSE: 5.9250 \t Train RMSE: 2.4341]\n",
      "Validation loss decreased (6.083284 --> 5.925007).  Saving model ...\n",
      "Train Epoch: 110 [48/22032] \t Train Loss(MSE): 5.1749 \t Train RMSE: 2.2748\n",
      "Train Epoch: 110 [9648/22032] \t Train Loss(MSE): 4.3047 \t Train RMSE: 2.0748\n",
      "Train Epoch: 110 [19248/22032] \t Train Loss(MSE): 36.4659 \t Train RMSE: 6.0387\n",
      "[Epoch: 110 \t Valid MSE: 15.8426 \t Valid RMSE: 3.9803]\n",
      "[Epoch: 110 \t Train MSE: 5.9396 \t Train RMSE: 2.4371]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 111 [48/22032] \t Train Loss(MSE): 3.7999 \t Train RMSE: 1.9493\n",
      "Train Epoch: 111 [9648/22032] \t Train Loss(MSE): 4.7084 \t Train RMSE: 2.1699\n",
      "Train Epoch: 111 [19248/22032] \t Train Loss(MSE): 23.7700 \t Train RMSE: 4.8754\n",
      "[Epoch: 111 \t Valid MSE: 15.4646 \t Valid RMSE: 3.9325]\n",
      "[Epoch: 111 \t Train MSE: 6.1063 \t Train RMSE: 2.4711]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 112 [48/22032] \t Train Loss(MSE): 4.0662 \t Train RMSE: 2.0165\n",
      "Train Epoch: 112 [9648/22032] \t Train Loss(MSE): 4.5028 \t Train RMSE: 2.1220\n",
      "Train Epoch: 112 [19248/22032] \t Train Loss(MSE): 15.1789 \t Train RMSE: 3.8960\n",
      "[Epoch: 112 \t Valid MSE: 15.1400 \t Valid RMSE: 3.8910]\n",
      "[Epoch: 112 \t Train MSE: 5.7826 \t Train RMSE: 2.4047]\n",
      "Validation loss decreased (5.925007 --> 5.782562).  Saving model ...\n",
      "Train Epoch: 113 [48/22032] \t Train Loss(MSE): 2.6566 \t Train RMSE: 1.6299\n",
      "Train Epoch: 113 [9648/22032] \t Train Loss(MSE): 4.5853 \t Train RMSE: 2.1413\n",
      "Train Epoch: 113 [19248/22032] \t Train Loss(MSE): 6.3339 \t Train RMSE: 2.5167\n",
      "[Epoch: 113 \t Valid MSE: 14.5636 \t Valid RMSE: 3.8162]\n",
      "[Epoch: 113 \t Train MSE: 5.6828 \t Train RMSE: 2.3839]\n",
      "Validation loss decreased (5.782562 --> 5.682835).  Saving model ...\n",
      "Train Epoch: 114 [48/22032] \t Train Loss(MSE): 8.5209 \t Train RMSE: 2.9191\n",
      "Train Epoch: 114 [9648/22032] \t Train Loss(MSE): 5.4983 \t Train RMSE: 2.3449\n",
      "Train Epoch: 114 [19248/22032] \t Train Loss(MSE): 8.6347 \t Train RMSE: 2.9385\n",
      "[Epoch: 114 \t Valid MSE: 14.8118 \t Valid RMSE: 3.8486]\n",
      "[Epoch: 114 \t Train MSE: 5.7128 \t Train RMSE: 2.3901]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 115 [48/22032] \t Train Loss(MSE): 8.7423 \t Train RMSE: 2.9567\n",
      "Train Epoch: 115 [9648/22032] \t Train Loss(MSE): 2.6020 \t Train RMSE: 1.6131\n",
      "Train Epoch: 115 [19248/22032] \t Train Loss(MSE): 2.8375 \t Train RMSE: 1.6845\n",
      "[Epoch: 115 \t Valid MSE: 14.6346 \t Valid RMSE: 3.8255]\n",
      "[Epoch: 115 \t Train MSE: 5.6377 \t Train RMSE: 2.3744]\n",
      "Validation loss decreased (5.682835 --> 5.637699).  Saving model ...\n",
      "Train Epoch: 116 [48/22032] \t Train Loss(MSE): 5.2361 \t Train RMSE: 2.2882\n",
      "Train Epoch: 116 [9648/22032] \t Train Loss(MSE): 26.4665 \t Train RMSE: 5.1446\n",
      "Train Epoch: 116 [19248/22032] \t Train Loss(MSE): 4.4676 \t Train RMSE: 2.1137\n",
      "[Epoch: 116 \t Valid MSE: 14.8208 \t Valid RMSE: 3.8498]\n",
      "[Epoch: 116 \t Train MSE: 5.5588 \t Train RMSE: 2.3577]\n",
      "Validation loss decreased (5.637699 --> 5.558834).  Saving model ...\n",
      "Train Epoch: 117 [48/22032] \t Train Loss(MSE): 2.9082 \t Train RMSE: 1.7053\n",
      "Train Epoch: 117 [9648/22032] \t Train Loss(MSE): 2.3219 \t Train RMSE: 1.5238\n",
      "Train Epoch: 117 [19248/22032] \t Train Loss(MSE): 1.4138 \t Train RMSE: 1.1890\n",
      "[Epoch: 117 \t Valid MSE: 14.3027 \t Valid RMSE: 3.7819]\n",
      "[Epoch: 117 \t Train MSE: 5.4723 \t Train RMSE: 2.3393]\n",
      "Validation loss decreased (5.558834 --> 5.472273).  Saving model ...\n",
      "Train Epoch: 118 [48/22032] \t Train Loss(MSE): 15.9601 \t Train RMSE: 3.9950\n",
      "Train Epoch: 118 [9648/22032] \t Train Loss(MSE): 3.3935 \t Train RMSE: 1.8422\n",
      "Train Epoch: 118 [19248/22032] \t Train Loss(MSE): 10.5141 \t Train RMSE: 3.2425\n",
      "[Epoch: 118 \t Valid MSE: 14.3014 \t Valid RMSE: 3.7817]\n",
      "[Epoch: 118 \t Train MSE: 5.5064 \t Train RMSE: 2.3466]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 119 [48/22032] \t Train Loss(MSE): 8.2836 \t Train RMSE: 2.8781\n",
      "Train Epoch: 119 [9648/22032] \t Train Loss(MSE): 2.3343 \t Train RMSE: 1.5278\n",
      "Train Epoch: 119 [19248/22032] \t Train Loss(MSE): 22.7946 \t Train RMSE: 4.7744\n",
      "[Epoch: 119 \t Valid MSE: 14.5900 \t Valid RMSE: 3.8197]\n",
      "[Epoch: 119 \t Train MSE: 5.4301 \t Train RMSE: 2.3303]\n",
      "Validation loss decreased (5.472273 --> 5.430129).  Saving model ...\n",
      "Train Epoch: 120 [48/22032] \t Train Loss(MSE): 3.5351 \t Train RMSE: 1.8802\n",
      "Train Epoch: 120 [9648/22032] \t Train Loss(MSE): 6.1936 \t Train RMSE: 2.4887\n",
      "Train Epoch: 120 [19248/22032] \t Train Loss(MSE): 4.7065 \t Train RMSE: 2.1694\n",
      "[Epoch: 120 \t Valid MSE: 14.3175 \t Valid RMSE: 3.7838]\n",
      "[Epoch: 120 \t Train MSE: 5.2349 \t Train RMSE: 2.2880]\n",
      "Validation loss decreased (5.430129 --> 5.234863).  Saving model ...\n",
      "Train Epoch: 121 [48/22032] \t Train Loss(MSE): 3.6141 \t Train RMSE: 1.9011\n",
      "Train Epoch: 121 [9648/22032] \t Train Loss(MSE): 2.7764 \t Train RMSE: 1.6662\n",
      "Train Epoch: 121 [19248/22032] \t Train Loss(MSE): 1.9823 \t Train RMSE: 1.4079\n",
      "[Epoch: 121 \t Valid MSE: 14.7653 \t Valid RMSE: 3.8426]\n",
      "[Epoch: 121 \t Train MSE: 5.2797 \t Train RMSE: 2.2978]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 122 [48/22032] \t Train Loss(MSE): 3.6896 \t Train RMSE: 1.9208\n",
      "Train Epoch: 122 [9648/22032] \t Train Loss(MSE): 3.3573 \t Train RMSE: 1.8323\n",
      "Train Epoch: 122 [19248/22032] \t Train Loss(MSE): 7.9269 \t Train RMSE: 2.8155\n",
      "[Epoch: 122 \t Valid MSE: 14.7788 \t Valid RMSE: 3.8443]\n",
      "[Epoch: 122 \t Train MSE: 5.1337 \t Train RMSE: 2.2658]\n",
      "Validation loss decreased (5.234863 --> 5.133682).  Saving model ...\n",
      "Train Epoch: 123 [48/22032] \t Train Loss(MSE): 3.7312 \t Train RMSE: 1.9316\n",
      "Train Epoch: 123 [9648/22032] \t Train Loss(MSE): 7.4957 \t Train RMSE: 2.7378\n",
      "Train Epoch: 123 [19248/22032] \t Train Loss(MSE): 13.8081 \t Train RMSE: 3.7159\n",
      "[Epoch: 123 \t Valid MSE: 16.4759 \t Valid RMSE: 4.0591]\n",
      "[Epoch: 123 \t Train MSE: 5.1405 \t Train RMSE: 2.2673]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 124 [48/22032] \t Train Loss(MSE): 3.9426 \t Train RMSE: 1.9856\n",
      "Train Epoch: 124 [9648/22032] \t Train Loss(MSE): 4.4341 \t Train RMSE: 2.1057\n",
      "Train Epoch: 124 [19248/22032] \t Train Loss(MSE): 4.7779 \t Train RMSE: 2.1858\n",
      "[Epoch: 124 \t Valid MSE: 14.4708 \t Valid RMSE: 3.8040]\n",
      "[Epoch: 124 \t Train MSE: 5.1575 \t Train RMSE: 2.2710]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 125 [48/22032] \t Train Loss(MSE): 2.6331 \t Train RMSE: 1.6227\n",
      "Train Epoch: 125 [9648/22032] \t Train Loss(MSE): 5.8359 \t Train RMSE: 2.4158\n",
      "Train Epoch: 125 [19248/22032] \t Train Loss(MSE): 15.1341 \t Train RMSE: 3.8903\n",
      "[Epoch: 125 \t Valid MSE: 14.9694 \t Valid RMSE: 3.8690]\n",
      "[Epoch: 125 \t Train MSE: 4.8485 \t Train RMSE: 2.2019]\n",
      "Validation loss decreased (5.133682 --> 4.848494).  Saving model ...\n",
      "Train Epoch: 126 [48/22032] \t Train Loss(MSE): 4.2241 \t Train RMSE: 2.0553\n",
      "Train Epoch: 126 [9648/22032] \t Train Loss(MSE): 2.6122 \t Train RMSE: 1.6162\n",
      "Train Epoch: 126 [19248/22032] \t Train Loss(MSE): 2.3551 \t Train RMSE: 1.5346\n",
      "[Epoch: 126 \t Valid MSE: 14.8902 \t Valid RMSE: 3.8588]\n",
      "[Epoch: 126 \t Train MSE: 4.8308 \t Train RMSE: 2.1979]\n",
      "Validation loss decreased (4.848494 --> 4.830816).  Saving model ...\n",
      "Train Epoch: 127 [48/22032] \t Train Loss(MSE): 7.0820 \t Train RMSE: 2.6612\n",
      "Train Epoch: 127 [9648/22032] \t Train Loss(MSE): 2.2755 \t Train RMSE: 1.5085\n",
      "Train Epoch: 127 [19248/22032] \t Train Loss(MSE): 15.0930 \t Train RMSE: 3.8850\n",
      "[Epoch: 127 \t Valid MSE: 14.4521 \t Valid RMSE: 3.8016]\n",
      "[Epoch: 127 \t Train MSE: 4.9340 \t Train RMSE: 2.2213]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 128 [48/22032] \t Train Loss(MSE): 5.0116 \t Train RMSE: 2.2386\n",
      "Train Epoch: 128 [9648/22032] \t Train Loss(MSE): 3.5921 \t Train RMSE: 1.8953\n",
      "Train Epoch: 128 [19248/22032] \t Train Loss(MSE): 2.7271 \t Train RMSE: 1.6514\n",
      "[Epoch: 128 \t Valid MSE: 14.4612 \t Valid RMSE: 3.8028]\n",
      "[Epoch: 128 \t Train MSE: 4.7442 \t Train RMSE: 2.1781]\n",
      "Validation loss decreased (4.830816 --> 4.744190).  Saving model ...\n",
      "Train Epoch: 129 [48/22032] \t Train Loss(MSE): 8.5429 \t Train RMSE: 2.9228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 129 [9648/22032] \t Train Loss(MSE): 3.2407 \t Train RMSE: 1.8002\n",
      "Train Epoch: 129 [19248/22032] \t Train Loss(MSE): 5.1762 \t Train RMSE: 2.2751\n",
      "[Epoch: 129 \t Valid MSE: 14.8285 \t Valid RMSE: 3.8508]\n",
      "[Epoch: 129 \t Train MSE: 5.0750 \t Train RMSE: 2.2528]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 130 [48/22032] \t Train Loss(MSE): 2.4809 \t Train RMSE: 1.5751\n",
      "Train Epoch: 130 [9648/22032] \t Train Loss(MSE): 2.1363 \t Train RMSE: 1.4616\n",
      "Train Epoch: 130 [19248/22032] \t Train Loss(MSE): 2.9359 \t Train RMSE: 1.7135\n",
      "[Epoch: 130 \t Valid MSE: 14.8984 \t Valid RMSE: 3.8598]\n",
      "[Epoch: 130 \t Train MSE: 4.7356 \t Train RMSE: 2.1761]\n",
      "Validation loss decreased (4.744190 --> 4.735615).  Saving model ...\n",
      "Train Epoch: 131 [48/22032] \t Train Loss(MSE): 2.9548 \t Train RMSE: 1.7190\n",
      "Train Epoch: 131 [9648/22032] \t Train Loss(MSE): 2.9462 \t Train RMSE: 1.7165\n",
      "Train Epoch: 131 [19248/22032] \t Train Loss(MSE): 12.0955 \t Train RMSE: 3.4779\n",
      "[Epoch: 131 \t Valid MSE: 14.5247 \t Valid RMSE: 3.8111]\n",
      "[Epoch: 131 \t Train MSE: 4.6644 \t Train RMSE: 2.1597]\n",
      "Validation loss decreased (4.735615 --> 4.664371).  Saving model ...\n",
      "Train Epoch: 132 [48/22032] \t Train Loss(MSE): 2.2966 \t Train RMSE: 1.5155\n",
      "Train Epoch: 132 [9648/22032] \t Train Loss(MSE): 4.7174 \t Train RMSE: 2.1720\n",
      "Train Epoch: 132 [19248/22032] \t Train Loss(MSE): 1.8034 \t Train RMSE: 1.3429\n",
      "[Epoch: 132 \t Valid MSE: 15.1777 \t Valid RMSE: 3.8959]\n",
      "[Epoch: 132 \t Train MSE: 4.6211 \t Train RMSE: 2.1497]\n",
      "Validation loss decreased (4.664371 --> 4.621137).  Saving model ...\n",
      "Train Epoch: 133 [48/22032] \t Train Loss(MSE): 2.5984 \t Train RMSE: 1.6119\n",
      "Train Epoch: 133 [9648/22032] \t Train Loss(MSE): 3.3744 \t Train RMSE: 1.8370\n",
      "Train Epoch: 133 [19248/22032] \t Train Loss(MSE): 3.6886 \t Train RMSE: 1.9206\n",
      "[Epoch: 133 \t Valid MSE: 14.5772 \t Valid RMSE: 3.8180]\n",
      "[Epoch: 133 \t Train MSE: 4.5982 \t Train RMSE: 2.1443]\n",
      "Validation loss decreased (4.621137 --> 4.598194).  Saving model ...\n",
      "Train Epoch: 134 [48/22032] \t Train Loss(MSE): 3.1545 \t Train RMSE: 1.7761\n",
      "Train Epoch: 134 [9648/22032] \t Train Loss(MSE): 2.7521 \t Train RMSE: 1.6589\n",
      "Train Epoch: 134 [19248/22032] \t Train Loss(MSE): 1.7557 \t Train RMSE: 1.3250\n",
      "[Epoch: 134 \t Valid MSE: 14.9905 \t Valid RMSE: 3.8718]\n",
      "[Epoch: 134 \t Train MSE: 4.3721 \t Train RMSE: 2.0910]\n",
      "Validation loss decreased (4.598194 --> 4.372077).  Saving model ...\n",
      "Train Epoch: 135 [48/22032] \t Train Loss(MSE): 2.4719 \t Train RMSE: 1.5722\n",
      "Train Epoch: 135 [9648/22032] \t Train Loss(MSE): 5.1840 \t Train RMSE: 2.2768\n",
      "Train Epoch: 135 [19248/22032] \t Train Loss(MSE): 1.6684 \t Train RMSE: 1.2917\n",
      "[Epoch: 135 \t Valid MSE: 14.8480 \t Valid RMSE: 3.8533]\n",
      "[Epoch: 135 \t Train MSE: 4.3508 \t Train RMSE: 2.0858]\n",
      "Validation loss decreased (4.372077 --> 4.350759).  Saving model ...\n",
      "Train Epoch: 136 [48/22032] \t Train Loss(MSE): 2.2172 \t Train RMSE: 1.4890\n",
      "Train Epoch: 136 [9648/22032] \t Train Loss(MSE): 3.4282 \t Train RMSE: 1.8515\n",
      "Train Epoch: 136 [19248/22032] \t Train Loss(MSE): 8.2347 \t Train RMSE: 2.8696\n",
      "[Epoch: 136 \t Valid MSE: 14.9287 \t Valid RMSE: 3.8638]\n",
      "[Epoch: 136 \t Train MSE: 4.4031 \t Train RMSE: 2.0983]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 137 [48/22032] \t Train Loss(MSE): 4.1210 \t Train RMSE: 2.0300\n",
      "Train Epoch: 137 [9648/22032] \t Train Loss(MSE): 3.0940 \t Train RMSE: 1.7590\n",
      "Train Epoch: 137 [19248/22032] \t Train Loss(MSE): 2.1005 \t Train RMSE: 1.4493\n",
      "[Epoch: 137 \t Valid MSE: 14.7609 \t Valid RMSE: 3.8420]\n",
      "[Epoch: 137 \t Train MSE: 4.3296 \t Train RMSE: 2.0808]\n",
      "Validation loss decreased (4.350759 --> 4.329629).  Saving model ...\n",
      "Train Epoch: 138 [48/22032] \t Train Loss(MSE): 2.2146 \t Train RMSE: 1.4882\n",
      "Train Epoch: 138 [9648/22032] \t Train Loss(MSE): 2.5434 \t Train RMSE: 1.5948\n",
      "Train Epoch: 138 [19248/22032] \t Train Loss(MSE): 1.4969 \t Train RMSE: 1.2235\n",
      "[Epoch: 138 \t Valid MSE: 15.0089 \t Valid RMSE: 3.8741]\n",
      "[Epoch: 138 \t Train MSE: 4.2483 \t Train RMSE: 2.0611]\n",
      "Validation loss decreased (4.329629 --> 4.248289).  Saving model ...\n",
      "Train Epoch: 139 [48/22032] \t Train Loss(MSE): 2.3829 \t Train RMSE: 1.5437\n",
      "Train Epoch: 139 [9648/22032] \t Train Loss(MSE): 2.4133 \t Train RMSE: 1.5535\n",
      "Train Epoch: 139 [19248/22032] \t Train Loss(MSE): 6.6403 \t Train RMSE: 2.5769\n",
      "[Epoch: 139 \t Valid MSE: 14.8836 \t Valid RMSE: 3.8579]\n",
      "[Epoch: 139 \t Train MSE: 4.3460 \t Train RMSE: 2.0847]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 140 [48/22032] \t Train Loss(MSE): 1.8575 \t Train RMSE: 1.3629\n",
      "Train Epoch: 140 [9648/22032] \t Train Loss(MSE): 4.0303 \t Train RMSE: 2.0076\n",
      "Train Epoch: 140 [19248/22032] \t Train Loss(MSE): 6.5617 \t Train RMSE: 2.5616\n",
      "[Epoch: 140 \t Valid MSE: 14.7454 \t Valid RMSE: 3.8400]\n",
      "[Epoch: 140 \t Train MSE: 4.4208 \t Train RMSE: 2.1026]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 141 [48/22032] \t Train Loss(MSE): 19.5008 \t Train RMSE: 4.4160\n",
      "Train Epoch: 141 [9648/22032] \t Train Loss(MSE): 3.4154 \t Train RMSE: 1.8481\n",
      "Train Epoch: 141 [19248/22032] \t Train Loss(MSE): 2.9853 \t Train RMSE: 1.7278\n",
      "[Epoch: 141 \t Valid MSE: 14.7822 \t Valid RMSE: 3.8448]\n",
      "[Epoch: 141 \t Train MSE: 4.1548 \t Train RMSE: 2.0383]\n",
      "Validation loss decreased (4.248289 --> 4.154842).  Saving model ...\n",
      "Train Epoch: 142 [48/22032] \t Train Loss(MSE): 3.4376 \t Train RMSE: 1.8541\n",
      "Train Epoch: 142 [9648/22032] \t Train Loss(MSE): 0.9757 \t Train RMSE: 0.9878\n",
      "Train Epoch: 142 [19248/22032] \t Train Loss(MSE): 1.0692 \t Train RMSE: 1.0340\n",
      "[Epoch: 142 \t Valid MSE: 15.2400 \t Valid RMSE: 3.9038]\n",
      "[Epoch: 142 \t Train MSE: 3.9357 \t Train RMSE: 1.9839]\n",
      "Validation loss decreased (4.154842 --> 3.935734).  Saving model ...\n",
      "Train Epoch: 143 [48/22032] \t Train Loss(MSE): 4.3631 \t Train RMSE: 2.0888\n",
      "Train Epoch: 143 [9648/22032] \t Train Loss(MSE): 4.6684 \t Train RMSE: 2.1606\n",
      "Train Epoch: 143 [19248/22032] \t Train Loss(MSE): 1.3938 \t Train RMSE: 1.1806\n",
      "[Epoch: 143 \t Valid MSE: 15.0934 \t Valid RMSE: 3.8850]\n",
      "[Epoch: 143 \t Train MSE: 4.0591 \t Train RMSE: 2.0147]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 144 [48/22032] \t Train Loss(MSE): 6.0667 \t Train RMSE: 2.4631\n",
      "Train Epoch: 144 [9648/22032] \t Train Loss(MSE): 2.0945 \t Train RMSE: 1.4473\n",
      "Train Epoch: 144 [19248/22032] \t Train Loss(MSE): 2.5083 \t Train RMSE: 1.5838\n",
      "[Epoch: 144 \t Valid MSE: 14.8584 \t Valid RMSE: 3.8547]\n",
      "[Epoch: 144 \t Train MSE: 4.1036 \t Train RMSE: 2.0257]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 145 [48/22032] \t Train Loss(MSE): 3.1778 \t Train RMSE: 1.7826\n",
      "Train Epoch: 145 [9648/22032] \t Train Loss(MSE): 5.1276 \t Train RMSE: 2.2644\n",
      "Train Epoch: 145 [19248/22032] \t Train Loss(MSE): 1.6261 \t Train RMSE: 1.2752\n",
      "[Epoch: 145 \t Valid MSE: 14.7987 \t Valid RMSE: 3.8469]\n",
      "[Epoch: 145 \t Train MSE: 4.1978 \t Train RMSE: 2.0489]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 146 [48/22032] \t Train Loss(MSE): 3.6002 \t Train RMSE: 1.8974\n",
      "Train Epoch: 146 [9648/22032] \t Train Loss(MSE): 1.9360 \t Train RMSE: 1.3914\n",
      "Train Epoch: 146 [19248/22032] \t Train Loss(MSE): 7.5049 \t Train RMSE: 2.7395\n",
      "[Epoch: 146 \t Valid MSE: 14.8306 \t Valid RMSE: 3.8510]\n",
      "[Epoch: 146 \t Train MSE: 4.0788 \t Train RMSE: 2.0196]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 147 [48/22032] \t Train Loss(MSE): 1.9163 \t Train RMSE: 1.3843\n",
      "Train Epoch: 147 [9648/22032] \t Train Loss(MSE): 9.2196 \t Train RMSE: 3.0364\n",
      "Train Epoch: 147 [19248/22032] \t Train Loss(MSE): 1.2583 \t Train RMSE: 1.1217\n",
      "[Epoch: 147 \t Valid MSE: 15.1882 \t Valid RMSE: 3.8972]\n",
      "[Epoch: 147 \t Train MSE: 3.8628 \t Train RMSE: 1.9654]\n",
      "Validation loss decreased (3.935734 --> 3.862840).  Saving model ...\n",
      "Train Epoch: 148 [48/22032] \t Train Loss(MSE): 2.0115 \t Train RMSE: 1.4183\n",
      "Train Epoch: 148 [9648/22032] \t Train Loss(MSE): 1.2346 \t Train RMSE: 1.1111\n",
      "Train Epoch: 148 [19248/22032] \t Train Loss(MSE): 2.2657 \t Train RMSE: 1.5052\n",
      "[Epoch: 148 \t Valid MSE: 15.6856 \t Valid RMSE: 3.9605]\n",
      "[Epoch: 148 \t Train MSE: 3.7753 \t Train RMSE: 1.9430]\n",
      "Validation loss decreased (3.862840 --> 3.775283).  Saving model ...\n",
      "Train Epoch: 149 [48/22032] \t Train Loss(MSE): 2.0471 \t Train RMSE: 1.4308\n",
      "Train Epoch: 149 [9648/22032] \t Train Loss(MSE): 2.0692 \t Train RMSE: 1.4385\n",
      "Train Epoch: 149 [19248/22032] \t Train Loss(MSE): 9.5273 \t Train RMSE: 3.0866\n",
      "[Epoch: 149 \t Valid MSE: 15.3669 \t Valid RMSE: 3.9201]\n",
      "[Epoch: 149 \t Train MSE: 3.8873 \t Train RMSE: 1.9716]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 150 [48/22032] \t Train Loss(MSE): 4.0658 \t Train RMSE: 2.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 150 [9648/22032] \t Train Loss(MSE): 2.0116 \t Train RMSE: 1.4183\n",
      "Train Epoch: 150 [19248/22032] \t Train Loss(MSE): 2.5834 \t Train RMSE: 1.6073\n",
      "[Epoch: 150 \t Valid MSE: 15.1993 \t Valid RMSE: 3.8986]\n",
      "[Epoch: 150 \t Train MSE: 3.8701 \t Train RMSE: 1.9673]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 151 [48/22032] \t Train Loss(MSE): 2.5149 \t Train RMSE: 1.5858\n",
      "Train Epoch: 151 [9648/22032] \t Train Loss(MSE): 9.0597 \t Train RMSE: 3.0099\n",
      "Train Epoch: 151 [19248/22032] \t Train Loss(MSE): 2.8480 \t Train RMSE: 1.6876\n",
      "[Epoch: 151 \t Valid MSE: 14.7885 \t Valid RMSE: 3.8456]\n",
      "[Epoch: 151 \t Train MSE: 4.2446 \t Train RMSE: 2.0603]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 152 [48/22032] \t Train Loss(MSE): 19.5840 \t Train RMSE: 4.4254\n",
      "Train Epoch: 152 [9648/22032] \t Train Loss(MSE): 3.5298 \t Train RMSE: 1.8788\n",
      "Train Epoch: 152 [19248/22032] \t Train Loss(MSE): 4.0018 \t Train RMSE: 2.0004\n",
      "[Epoch: 152 \t Valid MSE: 14.9248 \t Valid RMSE: 3.8633]\n",
      "[Epoch: 152 \t Train MSE: 4.2679 \t Train RMSE: 2.0659]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 153 [48/22032] \t Train Loss(MSE): 1.7275 \t Train RMSE: 1.3143\n",
      "Train Epoch: 153 [9648/22032] \t Train Loss(MSE): 3.7268 \t Train RMSE: 1.9305\n",
      "Train Epoch: 153 [19248/22032] \t Train Loss(MSE): 16.0886 \t Train RMSE: 4.0111\n",
      "[Epoch: 153 \t Valid MSE: 16.5278 \t Valid RMSE: 4.0654]\n",
      "[Epoch: 153 \t Train MSE: 3.9330 \t Train RMSE: 1.9832]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 154 [48/22032] \t Train Loss(MSE): 7.9465 \t Train RMSE: 2.8190\n",
      "Train Epoch: 154 [9648/22032] \t Train Loss(MSE): 2.4345 \t Train RMSE: 1.5603\n",
      "Train Epoch: 154 [19248/22032] \t Train Loss(MSE): 2.7322 \t Train RMSE: 1.6529\n",
      "[Epoch: 154 \t Valid MSE: 14.7678 \t Valid RMSE: 3.8429]\n",
      "[Epoch: 154 \t Train MSE: 3.8156 \t Train RMSE: 1.9534]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 155 [48/22032] \t Train Loss(MSE): 4.2314 \t Train RMSE: 2.0570\n",
      "Train Epoch: 155 [9648/22032] \t Train Loss(MSE): 6.1079 \t Train RMSE: 2.4714\n",
      "Train Epoch: 155 [19248/22032] \t Train Loss(MSE): 5.8903 \t Train RMSE: 2.4270\n",
      "[Epoch: 155 \t Valid MSE: 14.7558 \t Valid RMSE: 3.8413]\n",
      "[Epoch: 155 \t Train MSE: 3.5172 \t Train RMSE: 1.8754]\n",
      "Validation loss decreased (3.775283 --> 3.517219).  Saving model ...\n",
      "Train Epoch: 156 [48/22032] \t Train Loss(MSE): 2.1954 \t Train RMSE: 1.4817\n",
      "Train Epoch: 156 [9648/22032] \t Train Loss(MSE): 2.0082 \t Train RMSE: 1.4171\n",
      "Train Epoch: 156 [19248/22032] \t Train Loss(MSE): 1.8208 \t Train RMSE: 1.3494\n",
      "[Epoch: 156 \t Valid MSE: 15.0376 \t Valid RMSE: 3.8778]\n",
      "[Epoch: 156 \t Train MSE: 3.5760 \t Train RMSE: 1.8910]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 157 [48/22032] \t Train Loss(MSE): 1.2718 \t Train RMSE: 1.1278\n",
      "Train Epoch: 157 [9648/22032] \t Train Loss(MSE): 2.5671 \t Train RMSE: 1.6022\n",
      "Train Epoch: 157 [19248/22032] \t Train Loss(MSE): 4.7171 \t Train RMSE: 2.1719\n",
      "[Epoch: 157 \t Valid MSE: 15.6462 \t Valid RMSE: 3.9555]\n",
      "[Epoch: 157 \t Train MSE: 3.6527 \t Train RMSE: 1.9112]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 158 [48/22032] \t Train Loss(MSE): 3.6031 \t Train RMSE: 1.8982\n",
      "Train Epoch: 158 [9648/22032] \t Train Loss(MSE): 2.6885 \t Train RMSE: 1.6397\n",
      "Train Epoch: 158 [19248/22032] \t Train Loss(MSE): 5.0046 \t Train RMSE: 2.2371\n",
      "[Epoch: 158 \t Valid MSE: 14.7571 \t Valid RMSE: 3.8415]\n",
      "[Epoch: 158 \t Train MSE: 3.8173 \t Train RMSE: 1.9538]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 159 [48/22032] \t Train Loss(MSE): 2.3427 \t Train RMSE: 1.5306\n",
      "Train Epoch: 159 [9648/22032] \t Train Loss(MSE): 2.9999 \t Train RMSE: 1.7320\n",
      "Train Epoch: 159 [19248/22032] \t Train Loss(MSE): 2.5212 \t Train RMSE: 1.5878\n",
      "[Epoch: 159 \t Valid MSE: 14.9004 \t Valid RMSE: 3.8601]\n",
      "[Epoch: 159 \t Train MSE: 3.6538 \t Train RMSE: 1.9115]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 160 [48/22032] \t Train Loss(MSE): 2.1230 \t Train RMSE: 1.4570\n",
      "Train Epoch: 160 [9648/22032] \t Train Loss(MSE): 10.7693 \t Train RMSE: 3.2817\n",
      "Train Epoch: 160 [19248/22032] \t Train Loss(MSE): 4.4979 \t Train RMSE: 2.1208\n",
      "[Epoch: 160 \t Valid MSE: 14.8167 \t Valid RMSE: 3.8493]\n",
      "[Epoch: 160 \t Train MSE: 3.4522 \t Train RMSE: 1.8580]\n",
      "Validation loss decreased (3.517219 --> 3.452158).  Saving model ...\n",
      "Train Epoch: 161 [48/22032] \t Train Loss(MSE): 1.8930 \t Train RMSE: 1.3759\n",
      "Train Epoch: 161 [9648/22032] \t Train Loss(MSE): 2.5585 \t Train RMSE: 1.5995\n",
      "Train Epoch: 161 [19248/22032] \t Train Loss(MSE): 1.8715 \t Train RMSE: 1.3680\n",
      "[Epoch: 161 \t Valid MSE: 15.6706 \t Valid RMSE: 3.9586]\n",
      "[Epoch: 161 \t Train MSE: 3.5350 \t Train RMSE: 1.8802]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 162 [48/22032] \t Train Loss(MSE): 1.8819 \t Train RMSE: 1.3718\n",
      "Train Epoch: 162 [9648/22032] \t Train Loss(MSE): 4.1626 \t Train RMSE: 2.0402\n",
      "Train Epoch: 162 [19248/22032] \t Train Loss(MSE): 1.4949 \t Train RMSE: 1.2227\n",
      "[Epoch: 162 \t Valid MSE: 15.3134 \t Valid RMSE: 3.9132]\n",
      "[Epoch: 162 \t Train MSE: 3.7176 \t Train RMSE: 1.9281]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 163 [48/22032] \t Train Loss(MSE): 1.5264 \t Train RMSE: 1.2355\n",
      "Train Epoch: 163 [9648/22032] \t Train Loss(MSE): 3.1444 \t Train RMSE: 1.7732\n",
      "Train Epoch: 163 [19248/22032] \t Train Loss(MSE): 5.4322 \t Train RMSE: 2.3307\n",
      "[Epoch: 163 \t Valid MSE: 15.0894 \t Valid RMSE: 3.8845]\n",
      "[Epoch: 163 \t Train MSE: 3.6113 \t Train RMSE: 1.9003]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 164 [48/22032] \t Train Loss(MSE): 20.1151 \t Train RMSE: 4.4850\n",
      "Train Epoch: 164 [9648/22032] \t Train Loss(MSE): 3.2169 \t Train RMSE: 1.7936\n",
      "Train Epoch: 164 [19248/22032] \t Train Loss(MSE): 0.9535 \t Train RMSE: 0.9765\n",
      "[Epoch: 164 \t Valid MSE: 14.7742 \t Valid RMSE: 3.8437]\n",
      "[Epoch: 164 \t Train MSE: 3.6262 \t Train RMSE: 1.9043]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 165 [48/22032] \t Train Loss(MSE): 2.8542 \t Train RMSE: 1.6894\n",
      "Train Epoch: 165 [9648/22032] \t Train Loss(MSE): 1.4396 \t Train RMSE: 1.1998\n",
      "Train Epoch: 165 [19248/22032] \t Train Loss(MSE): 2.4884 \t Train RMSE: 1.5775\n",
      "[Epoch: 165 \t Valid MSE: 15.3986 \t Valid RMSE: 3.9241]\n",
      "[Epoch: 165 \t Train MSE: 3.4277 \t Train RMSE: 1.8514]\n",
      "Validation loss decreased (3.452158 --> 3.427653).  Saving model ...\n",
      "Train Epoch: 166 [48/22032] \t Train Loss(MSE): 2.6786 \t Train RMSE: 1.6366\n",
      "Train Epoch: 166 [9648/22032] \t Train Loss(MSE): 3.2951 \t Train RMSE: 1.8152\n",
      "Train Epoch: 166 [19248/22032] \t Train Loss(MSE): 1.2674 \t Train RMSE: 1.1258\n",
      "[Epoch: 166 \t Valid MSE: 15.4414 \t Valid RMSE: 3.9296]\n",
      "[Epoch: 166 \t Train MSE: 3.5654 \t Train RMSE: 1.8882]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 167 [48/22032] \t Train Loss(MSE): 6.0893 \t Train RMSE: 2.4676\n",
      "Train Epoch: 167 [9648/22032] \t Train Loss(MSE): 3.0375 \t Train RMSE: 1.7429\n",
      "Train Epoch: 167 [19248/22032] \t Train Loss(MSE): 2.6976 \t Train RMSE: 1.6424\n",
      "[Epoch: 167 \t Valid MSE: 15.7770 \t Valid RMSE: 3.9720]\n",
      "[Epoch: 167 \t Train MSE: 3.3626 \t Train RMSE: 1.8337]\n",
      "Validation loss decreased (3.427653 --> 3.362567).  Saving model ...\n",
      "Train Epoch: 168 [48/22032] \t Train Loss(MSE): 6.8322 \t Train RMSE: 2.6139\n",
      "Train Epoch: 168 [9648/22032] \t Train Loss(MSE): 1.7226 \t Train RMSE: 1.3125\n",
      "Train Epoch: 168 [19248/22032] \t Train Loss(MSE): 3.6578 \t Train RMSE: 1.9125\n",
      "[Epoch: 168 \t Valid MSE: 14.8441 \t Valid RMSE: 3.8528]\n",
      "[Epoch: 168 \t Train MSE: 3.2015 \t Train RMSE: 1.7893]\n",
      "Validation loss decreased (3.362567 --> 3.201508).  Saving model ...\n",
      "Train Epoch: 169 [48/22032] \t Train Loss(MSE): 8.5733 \t Train RMSE: 2.9280\n",
      "Train Epoch: 169 [9648/22032] \t Train Loss(MSE): 6.7984 \t Train RMSE: 2.6074\n",
      "Train Epoch: 169 [19248/22032] \t Train Loss(MSE): 1.3413 \t Train RMSE: 1.1582\n",
      "[Epoch: 169 \t Valid MSE: 15.1306 \t Valid RMSE: 3.8898]\n",
      "[Epoch: 169 \t Train MSE: 3.2188 \t Train RMSE: 1.7941]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 170 [48/22032] \t Train Loss(MSE): 6.5244 \t Train RMSE: 2.5543\n",
      "Train Epoch: 170 [9648/22032] \t Train Loss(MSE): 1.2376 \t Train RMSE: 1.1125\n",
      "Train Epoch: 170 [19248/22032] \t Train Loss(MSE): 1.9974 \t Train RMSE: 1.4133\n",
      "[Epoch: 170 \t Valid MSE: 15.0075 \t Valid RMSE: 3.8739]\n",
      "[Epoch: 170 \t Train MSE: 3.2770 \t Train RMSE: 1.8103]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 171 [48/22032] \t Train Loss(MSE): 9.4693 \t Train RMSE: 3.0772\n",
      "Train Epoch: 171 [9648/22032] \t Train Loss(MSE): 2.8877 \t Train RMSE: 1.6993\n",
      "Train Epoch: 171 [19248/22032] \t Train Loss(MSE): 1.7174 \t Train RMSE: 1.3105\n",
      "[Epoch: 171 \t Valid MSE: 14.9647 \t Valid RMSE: 3.8684]\n",
      "[Epoch: 171 \t Train MSE: 3.3417 \t Train RMSE: 1.8280]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 172 [48/22032] \t Train Loss(MSE): 1.7590 \t Train RMSE: 1.3263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 172 [9648/22032] \t Train Loss(MSE): 4.2659 \t Train RMSE: 2.0654\n",
      "Train Epoch: 172 [19248/22032] \t Train Loss(MSE): 3.4612 \t Train RMSE: 1.8604\n",
      "[Epoch: 172 \t Valid MSE: 14.6923 \t Valid RMSE: 3.8331]\n",
      "[Epoch: 172 \t Train MSE: 3.0167 \t Train RMSE: 1.7369]\n",
      "Validation loss decreased (3.201508 --> 3.016738).  Saving model ...\n",
      "Train Epoch: 173 [48/22032] \t Train Loss(MSE): 22.1055 \t Train RMSE: 4.7016\n",
      "Train Epoch: 173 [9648/22032] \t Train Loss(MSE): 1.6235 \t Train RMSE: 1.2742\n",
      "Train Epoch: 173 [19248/22032] \t Train Loss(MSE): 4.6443 \t Train RMSE: 2.1551\n",
      "[Epoch: 173 \t Valid MSE: 15.1654 \t Valid RMSE: 3.8943]\n",
      "[Epoch: 173 \t Train MSE: 3.2312 \t Train RMSE: 1.7975]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 174 [48/22032] \t Train Loss(MSE): 1.5406 \t Train RMSE: 1.2412\n",
      "Train Epoch: 174 [9648/22032] \t Train Loss(MSE): 0.5525 \t Train RMSE: 0.7433\n",
      "Train Epoch: 174 [19248/22032] \t Train Loss(MSE): 1.7889 \t Train RMSE: 1.3375\n",
      "[Epoch: 174 \t Valid MSE: 14.7301 \t Valid RMSE: 3.8380]\n",
      "[Epoch: 174 \t Train MSE: 3.1422 \t Train RMSE: 1.7726]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 175 [48/22032] \t Train Loss(MSE): 1.8177 \t Train RMSE: 1.3482\n",
      "Train Epoch: 175 [9648/22032] \t Train Loss(MSE): 1.4554 \t Train RMSE: 1.2064\n",
      "Train Epoch: 175 [19248/22032] \t Train Loss(MSE): 2.7587 \t Train RMSE: 1.6609\n",
      "[Epoch: 175 \t Valid MSE: 14.5520 \t Valid RMSE: 3.8147]\n",
      "[Epoch: 175 \t Train MSE: 3.0821 \t Train RMSE: 1.7556]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 176 [48/22032] \t Train Loss(MSE): 3.4414 \t Train RMSE: 1.8551\n",
      "Train Epoch: 176 [9648/22032] \t Train Loss(MSE): 1.2554 \t Train RMSE: 1.1205\n",
      "Train Epoch: 176 [19248/22032] \t Train Loss(MSE): 3.2577 \t Train RMSE: 1.8049\n",
      "[Epoch: 176 \t Valid MSE: 15.8217 \t Valid RMSE: 3.9776]\n",
      "[Epoch: 176 \t Train MSE: 3.3326 \t Train RMSE: 1.8255]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 177 [48/22032] \t Train Loss(MSE): 1.8260 \t Train RMSE: 1.3513\n",
      "Train Epoch: 177 [9648/22032] \t Train Loss(MSE): 1.2788 \t Train RMSE: 1.1308\n",
      "Train Epoch: 177 [19248/22032] \t Train Loss(MSE): 3.5013 \t Train RMSE: 1.8712\n",
      "[Epoch: 177 \t Valid MSE: 14.6952 \t Valid RMSE: 3.8334]\n",
      "[Epoch: 177 \t Train MSE: 3.1909 \t Train RMSE: 1.7863]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 178 [48/22032] \t Train Loss(MSE): 1.4118 \t Train RMSE: 1.1882\n",
      "Train Epoch: 178 [9648/22032] \t Train Loss(MSE): 1.5327 \t Train RMSE: 1.2380\n",
      "Train Epoch: 178 [19248/22032] \t Train Loss(MSE): 4.6729 \t Train RMSE: 2.1617\n",
      "[Epoch: 178 \t Valid MSE: 15.1595 \t Valid RMSE: 3.8935]\n",
      "[Epoch: 178 \t Train MSE: 3.0624 \t Train RMSE: 1.7500]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 179 [48/22032] \t Train Loss(MSE): 1.6663 \t Train RMSE: 1.2908\n",
      "Train Epoch: 179 [9648/22032] \t Train Loss(MSE): 1.9879 \t Train RMSE: 1.4099\n",
      "Train Epoch: 179 [19248/22032] \t Train Loss(MSE): 0.9543 \t Train RMSE: 0.9769\n",
      "[Epoch: 179 \t Valid MSE: 14.5823 \t Valid RMSE: 3.8187]\n",
      "[Epoch: 179 \t Train MSE: 3.0077 \t Train RMSE: 1.7343]\n",
      "Validation loss decreased (3.016738 --> 3.007654).  Saving model ...\n",
      "Train Epoch: 180 [48/22032] \t Train Loss(MSE): 1.5994 \t Train RMSE: 1.2647\n",
      "Train Epoch: 180 [9648/22032] \t Train Loss(MSE): 2.4570 \t Train RMSE: 1.5675\n",
      "Train Epoch: 180 [19248/22032] \t Train Loss(MSE): 2.6619 \t Train RMSE: 1.6315\n",
      "[Epoch: 180 \t Valid MSE: 14.6915 \t Valid RMSE: 3.8330]\n",
      "[Epoch: 180 \t Train MSE: 3.0286 \t Train RMSE: 1.7403]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 181 [48/22032] \t Train Loss(MSE): 6.7408 \t Train RMSE: 2.5963\n",
      "Train Epoch: 181 [9648/22032] \t Train Loss(MSE): 1.3697 \t Train RMSE: 1.1704\n",
      "Train Epoch: 181 [19248/22032] \t Train Loss(MSE): 4.7501 \t Train RMSE: 2.1795\n",
      "[Epoch: 181 \t Valid MSE: 15.2845 \t Valid RMSE: 3.9095]\n",
      "[Epoch: 181 \t Train MSE: 3.3627 \t Train RMSE: 1.8338]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 182 [48/22032] \t Train Loss(MSE): 2.3609 \t Train RMSE: 1.5365\n",
      "Train Epoch: 182 [9648/22032] \t Train Loss(MSE): 3.8701 \t Train RMSE: 1.9672\n",
      "Train Epoch: 182 [19248/22032] \t Train Loss(MSE): 1.8859 \t Train RMSE: 1.3733\n",
      "[Epoch: 182 \t Valid MSE: 14.4550 \t Valid RMSE: 3.8020]\n",
      "[Epoch: 182 \t Train MSE: 2.9744 \t Train RMSE: 1.7246]\n",
      "Validation loss decreased (3.007654 --> 2.974355).  Saving model ...\n",
      "Train Epoch: 183 [48/22032] \t Train Loss(MSE): 5.2458 \t Train RMSE: 2.2904\n",
      "Train Epoch: 183 [9648/22032] \t Train Loss(MSE): 1.8525 \t Train RMSE: 1.3611\n",
      "Train Epoch: 183 [19248/22032] \t Train Loss(MSE): 1.9876 \t Train RMSE: 1.4098\n",
      "[Epoch: 183 \t Valid MSE: 14.5502 \t Valid RMSE: 3.8145]\n",
      "[Epoch: 183 \t Train MSE: 2.9320 \t Train RMSE: 1.7123]\n",
      "Validation loss decreased (2.974355 --> 2.932032).  Saving model ...\n",
      "Train Epoch: 184 [48/22032] \t Train Loss(MSE): 2.9125 \t Train RMSE: 1.7066\n",
      "Train Epoch: 184 [9648/22032] \t Train Loss(MSE): 1.3099 \t Train RMSE: 1.1445\n",
      "Train Epoch: 184 [19248/22032] \t Train Loss(MSE): 1.0644 \t Train RMSE: 1.0317\n",
      "[Epoch: 184 \t Valid MSE: 15.1985 \t Valid RMSE: 3.8985]\n",
      "[Epoch: 184 \t Train MSE: 2.7713 \t Train RMSE: 1.6647]\n",
      "Validation loss decreased (2.932032 --> 2.771272).  Saving model ...\n",
      "Train Epoch: 185 [48/22032] \t Train Loss(MSE): 1.6393 \t Train RMSE: 1.2804\n",
      "Train Epoch: 185 [9648/22032] \t Train Loss(MSE): 1.4931 \t Train RMSE: 1.2219\n",
      "Train Epoch: 185 [19248/22032] \t Train Loss(MSE): 2.6624 \t Train RMSE: 1.6317\n",
      "[Epoch: 185 \t Valid MSE: 14.7591 \t Valid RMSE: 3.8418]\n",
      "[Epoch: 185 \t Train MSE: 2.9783 \t Train RMSE: 1.7258]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 186 [48/22032] \t Train Loss(MSE): 2.1513 \t Train RMSE: 1.4667\n",
      "Train Epoch: 186 [9648/22032] \t Train Loss(MSE): 1.5200 \t Train RMSE: 1.2329\n",
      "Train Epoch: 186 [19248/22032] \t Train Loss(MSE): 2.2698 \t Train RMSE: 1.5066\n",
      "[Epoch: 186 \t Valid MSE: 14.6779 \t Valid RMSE: 3.8312]\n",
      "[Epoch: 186 \t Train MSE: 3.3617 \t Train RMSE: 1.8335]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 187 [48/22032] \t Train Loss(MSE): 1.0768 \t Train RMSE: 1.0377\n",
      "Train Epoch: 187 [9648/22032] \t Train Loss(MSE): 1.5341 \t Train RMSE: 1.2386\n",
      "Train Epoch: 187 [19248/22032] \t Train Loss(MSE): 1.7179 \t Train RMSE: 1.3107\n",
      "[Epoch: 187 \t Valid MSE: 14.4605 \t Valid RMSE: 3.8027]\n",
      "[Epoch: 187 \t Train MSE: 3.0426 \t Train RMSE: 1.7443]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 188 [48/22032] \t Train Loss(MSE): 2.1748 \t Train RMSE: 1.4747\n",
      "Train Epoch: 188 [9648/22032] \t Train Loss(MSE): 1.9412 \t Train RMSE: 1.3933\n",
      "Train Epoch: 188 [19248/22032] \t Train Loss(MSE): 1.3728 \t Train RMSE: 1.1717\n",
      "[Epoch: 188 \t Valid MSE: 14.6038 \t Valid RMSE: 3.8215]\n",
      "[Epoch: 188 \t Train MSE: 2.8518 \t Train RMSE: 1.6887]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 189 [48/22032] \t Train Loss(MSE): 1.6311 \t Train RMSE: 1.2771\n",
      "Train Epoch: 189 [9648/22032] \t Train Loss(MSE): 1.1450 \t Train RMSE: 1.0701\n",
      "Train Epoch: 189 [19248/22032] \t Train Loss(MSE): 3.1511 \t Train RMSE: 1.7751\n",
      "[Epoch: 189 \t Valid MSE: 15.5854 \t Valid RMSE: 3.9478]\n",
      "[Epoch: 189 \t Train MSE: 2.6052 \t Train RMSE: 1.6141]\n",
      "Validation loss decreased (2.771272 --> 2.605176).  Saving model ...\n",
      "Train Epoch: 190 [48/22032] \t Train Loss(MSE): 2.4759 \t Train RMSE: 1.5735\n",
      "Train Epoch: 190 [9648/22032] \t Train Loss(MSE): 1.2168 \t Train RMSE: 1.1031\n",
      "Train Epoch: 190 [19248/22032] \t Train Loss(MSE): 2.4742 \t Train RMSE: 1.5730\n",
      "[Epoch: 190 \t Valid MSE: 14.7238 \t Valid RMSE: 3.8372]\n",
      "[Epoch: 190 \t Train MSE: 2.7360 \t Train RMSE: 1.6541]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 191 [48/22032] \t Train Loss(MSE): 2.7919 \t Train RMSE: 1.6709\n",
      "Train Epoch: 191 [9648/22032] \t Train Loss(MSE): 2.1568 \t Train RMSE: 1.4686\n",
      "Train Epoch: 191 [19248/22032] \t Train Loss(MSE): 1.4210 \t Train RMSE: 1.1921\n",
      "[Epoch: 191 \t Valid MSE: 17.1132 \t Valid RMSE: 4.1368]\n",
      "[Epoch: 191 \t Train MSE: 2.7897 \t Train RMSE: 1.6702]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 192 [48/22032] \t Train Loss(MSE): 5.8864 \t Train RMSE: 2.4262\n",
      "Train Epoch: 192 [9648/22032] \t Train Loss(MSE): 6.7635 \t Train RMSE: 2.6007\n",
      "Train Epoch: 192 [19248/22032] \t Train Loss(MSE): 1.0522 \t Train RMSE: 1.0258\n",
      "[Epoch: 192 \t Valid MSE: 14.8843 \t Valid RMSE: 3.8580]\n",
      "[Epoch: 192 \t Train MSE: 2.6914 \t Train RMSE: 1.6406]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 193 [48/22032] \t Train Loss(MSE): 1.6932 \t Train RMSE: 1.3012\n",
      "Train Epoch: 193 [9648/22032] \t Train Loss(MSE): 1.7660 \t Train RMSE: 1.3289\n",
      "Train Epoch: 193 [19248/22032] \t Train Loss(MSE): 1.5437 \t Train RMSE: 1.2425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 193 \t Valid MSE: 14.6940 \t Valid RMSE: 3.8333]\n",
      "[Epoch: 193 \t Train MSE: 2.8743 \t Train RMSE: 1.6954]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 194 [48/22032] \t Train Loss(MSE): 2.5791 \t Train RMSE: 1.6059\n",
      "Train Epoch: 194 [9648/22032] \t Train Loss(MSE): 1.8678 \t Train RMSE: 1.3667\n",
      "Train Epoch: 194 [19248/22032] \t Train Loss(MSE): 4.0577 \t Train RMSE: 2.0144\n",
      "[Epoch: 194 \t Valid MSE: 14.9551 \t Valid RMSE: 3.8672]\n",
      "[Epoch: 194 \t Train MSE: 2.7210 \t Train RMSE: 1.6495]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 195 [48/22032] \t Train Loss(MSE): 0.8614 \t Train RMSE: 0.9281\n",
      "Train Epoch: 195 [9648/22032] \t Train Loss(MSE): 4.3868 \t Train RMSE: 2.0945\n",
      "Train Epoch: 195 [19248/22032] \t Train Loss(MSE): 3.7731 \t Train RMSE: 1.9425\n",
      "[Epoch: 195 \t Valid MSE: 14.8254 \t Valid RMSE: 3.8504]\n",
      "[Epoch: 195 \t Train MSE: 2.6223 \t Train RMSE: 1.6193]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 196 [48/22032] \t Train Loss(MSE): 1.4624 \t Train RMSE: 1.2093\n",
      "Train Epoch: 196 [9648/22032] \t Train Loss(MSE): 1.8994 \t Train RMSE: 1.3782\n",
      "Train Epoch: 196 [19248/22032] \t Train Loss(MSE): 2.5263 \t Train RMSE: 1.5894\n",
      "[Epoch: 196 \t Valid MSE: 14.8495 \t Valid RMSE: 3.8535]\n",
      "[Epoch: 196 \t Train MSE: 2.6465 \t Train RMSE: 1.6268]\n",
      "EarlyStopping counter: 7 out of 40\n",
      "Train Epoch: 197 [48/22032] \t Train Loss(MSE): 0.9407 \t Train RMSE: 0.9699\n",
      "Train Epoch: 197 [9648/22032] \t Train Loss(MSE): 1.4112 \t Train RMSE: 1.1880\n",
      "Train Epoch: 197 [19248/22032] \t Train Loss(MSE): 3.5462 \t Train RMSE: 1.8831\n",
      "[Epoch: 197 \t Valid MSE: 15.2186 \t Valid RMSE: 3.9011]\n",
      "[Epoch: 197 \t Train MSE: 2.7124 \t Train RMSE: 1.6470]\n",
      "EarlyStopping counter: 8 out of 40\n",
      "Train Epoch: 198 [48/22032] \t Train Loss(MSE): 1.5459 \t Train RMSE: 1.2433\n",
      "Train Epoch: 198 [9648/22032] \t Train Loss(MSE): 2.4236 \t Train RMSE: 1.5568\n",
      "Train Epoch: 198 [19248/22032] \t Train Loss(MSE): 2.1966 \t Train RMSE: 1.4821\n",
      "[Epoch: 198 \t Valid MSE: 14.7848 \t Valid RMSE: 3.8451]\n",
      "[Epoch: 198 \t Train MSE: 2.6712 \t Train RMSE: 1.6344]\n",
      "EarlyStopping counter: 9 out of 40\n",
      "Train Epoch: 199 [48/22032] \t Train Loss(MSE): 1.5465 \t Train RMSE: 1.2436\n",
      "Train Epoch: 199 [9648/22032] \t Train Loss(MSE): 0.7218 \t Train RMSE: 0.8496\n",
      "Train Epoch: 199 [19248/22032] \t Train Loss(MSE): 3.3987 \t Train RMSE: 1.8436\n",
      "[Epoch: 199 \t Valid MSE: 14.6144 \t Valid RMSE: 3.8229]\n",
      "[Epoch: 199 \t Train MSE: 2.9001 \t Train RMSE: 1.7030]\n",
      "EarlyStopping counter: 10 out of 40\n",
      "Train Epoch: 200 [48/22032] \t Train Loss(MSE): 1.6953 \t Train RMSE: 1.3020\n",
      "Train Epoch: 200 [9648/22032] \t Train Loss(MSE): 2.0726 \t Train RMSE: 1.4396\n",
      "Train Epoch: 200 [19248/22032] \t Train Loss(MSE): 2.4707 \t Train RMSE: 1.5718\n",
      "[Epoch: 200 \t Valid MSE: 14.4651 \t Valid RMSE: 3.8033]\n",
      "[Epoch: 200 \t Train MSE: 3.1923 \t Train RMSE: 1.7867]\n",
      "Epoch   200: reducing learning rate of group 0 to 2.5000e-03.\n",
      "EarlyStopping counter: 11 out of 40\n",
      "Train Epoch: 201 [48/22032] \t Train Loss(MSE): 6.1836 \t Train RMSE: 2.4867\n",
      "Train Epoch: 201 [9648/22032] \t Train Loss(MSE): 1.8716 \t Train RMSE: 1.3681\n",
      "Train Epoch: 201 [19248/22032] \t Train Loss(MSE): 1.8596 \t Train RMSE: 1.3637\n",
      "[Epoch: 201 \t Valid MSE: 14.3280 \t Valid RMSE: 3.7852]\n",
      "[Epoch: 201 \t Train MSE: 2.3625 \t Train RMSE: 1.5370]\n",
      "Validation loss decreased (2.605176 --> 2.362482).  Saving model ...\n",
      "Train Epoch: 202 [48/22032] \t Train Loss(MSE): 0.7420 \t Train RMSE: 0.8614\n",
      "Train Epoch: 202 [9648/22032] \t Train Loss(MSE): 0.7527 \t Train RMSE: 0.8676\n",
      "Train Epoch: 202 [19248/22032] \t Train Loss(MSE): 0.9758 \t Train RMSE: 0.9878\n",
      "[Epoch: 202 \t Valid MSE: 14.3276 \t Valid RMSE: 3.7852]\n",
      "[Epoch: 202 \t Train MSE: 2.0535 \t Train RMSE: 1.4330]\n",
      "Validation loss decreased (2.362482 --> 2.053534).  Saving model ...\n",
      "Train Epoch: 203 [48/22032] \t Train Loss(MSE): 0.2534 \t Train RMSE: 0.5034\n",
      "Train Epoch: 203 [9648/22032] \t Train Loss(MSE): 3.5315 \t Train RMSE: 1.8792\n",
      "Train Epoch: 203 [19248/22032] \t Train Loss(MSE): 0.6606 \t Train RMSE: 0.8128\n",
      "[Epoch: 203 \t Valid MSE: 14.5433 \t Valid RMSE: 3.8136]\n",
      "[Epoch: 203 \t Train MSE: 1.9839 \t Train RMSE: 1.4085]\n",
      "Validation loss decreased (2.053534 --> 1.983927).  Saving model ...\n",
      "Train Epoch: 204 [48/22032] \t Train Loss(MSE): 0.7569 \t Train RMSE: 0.8700\n",
      "Train Epoch: 204 [9648/22032] \t Train Loss(MSE): 0.7818 \t Train RMSE: 0.8842\n",
      "Train Epoch: 204 [19248/22032] \t Train Loss(MSE): 0.8407 \t Train RMSE: 0.9169\n",
      "[Epoch: 204 \t Valid MSE: 14.8660 \t Valid RMSE: 3.8556]\n",
      "[Epoch: 204 \t Train MSE: 1.9540 \t Train RMSE: 1.3978]\n",
      "Validation loss decreased (1.983927 --> 1.953960).  Saving model ...\n",
      "Train Epoch: 205 [48/22032] \t Train Loss(MSE): 0.8411 \t Train RMSE: 0.9171\n",
      "Train Epoch: 205 [9648/22032] \t Train Loss(MSE): 1.5899 \t Train RMSE: 1.2609\n",
      "Train Epoch: 205 [19248/22032] \t Train Loss(MSE): 1.3121 \t Train RMSE: 1.1455\n",
      "[Epoch: 205 \t Valid MSE: 14.4166 \t Valid RMSE: 3.7969]\n",
      "[Epoch: 205 \t Train MSE: 1.9746 \t Train RMSE: 1.4052]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 206 [48/22032] \t Train Loss(MSE): 0.5804 \t Train RMSE: 0.7619\n",
      "Train Epoch: 206 [9648/22032] \t Train Loss(MSE): 0.5986 \t Train RMSE: 0.7737\n",
      "Train Epoch: 206 [19248/22032] \t Train Loss(MSE): 0.8510 \t Train RMSE: 0.9225\n",
      "[Epoch: 206 \t Valid MSE: 14.5514 \t Valid RMSE: 3.8146]\n",
      "[Epoch: 206 \t Train MSE: 1.9626 \t Train RMSE: 1.4009]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 207 [48/22032] \t Train Loss(MSE): 1.0931 \t Train RMSE: 1.0455\n",
      "Train Epoch: 207 [9648/22032] \t Train Loss(MSE): 2.4350 \t Train RMSE: 1.5605\n",
      "Train Epoch: 207 [19248/22032] \t Train Loss(MSE): 0.6547 \t Train RMSE: 0.8091\n",
      "[Epoch: 207 \t Valid MSE: 14.9080 \t Valid RMSE: 3.8611]\n",
      "[Epoch: 207 \t Train MSE: 1.9431 \t Train RMSE: 1.3940]\n",
      "Validation loss decreased (1.953960 --> 1.943140).  Saving model ...\n",
      "Train Epoch: 208 [48/22032] \t Train Loss(MSE): 0.7966 \t Train RMSE: 0.8925\n",
      "Train Epoch: 208 [9648/22032] \t Train Loss(MSE): 5.6925 \t Train RMSE: 2.3859\n",
      "Train Epoch: 208 [19248/22032] \t Train Loss(MSE): 2.2872 \t Train RMSE: 1.5124\n",
      "[Epoch: 208 \t Valid MSE: 14.7480 \t Valid RMSE: 3.8403]\n",
      "[Epoch: 208 \t Train MSE: 1.9528 \t Train RMSE: 1.3974]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 209 [48/22032] \t Train Loss(MSE): 1.0195 \t Train RMSE: 1.0097\n",
      "Train Epoch: 209 [9648/22032] \t Train Loss(MSE): 3.1814 \t Train RMSE: 1.7836\n",
      "Train Epoch: 209 [19248/22032] \t Train Loss(MSE): 0.9431 \t Train RMSE: 0.9712\n",
      "[Epoch: 209 \t Valid MSE: 14.6360 \t Valid RMSE: 3.8257]\n",
      "[Epoch: 209 \t Train MSE: 1.9434 \t Train RMSE: 1.3941]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 210 [48/22032] \t Train Loss(MSE): 0.7376 \t Train RMSE: 0.8588\n",
      "Train Epoch: 210 [9648/22032] \t Train Loss(MSE): 0.6091 \t Train RMSE: 0.7805\n",
      "Train Epoch: 210 [19248/22032] \t Train Loss(MSE): 1.5044 \t Train RMSE: 1.2265\n",
      "[Epoch: 210 \t Valid MSE: 14.4826 \t Valid RMSE: 3.8056]\n",
      "[Epoch: 210 \t Train MSE: 1.9201 \t Train RMSE: 1.3857]\n",
      "Validation loss decreased (1.943140 --> 1.920076).  Saving model ...\n",
      "Train Epoch: 211 [48/22032] \t Train Loss(MSE): 0.5374 \t Train RMSE: 0.7331\n",
      "Train Epoch: 211 [9648/22032] \t Train Loss(MSE): 1.7425 \t Train RMSE: 1.3200\n",
      "Train Epoch: 211 [19248/22032] \t Train Loss(MSE): 0.4476 \t Train RMSE: 0.6690\n",
      "[Epoch: 211 \t Valid MSE: 14.4237 \t Valid RMSE: 3.7979]\n",
      "[Epoch: 211 \t Train MSE: 1.9289 \t Train RMSE: 1.3889]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 212 [48/22032] \t Train Loss(MSE): 4.0467 \t Train RMSE: 2.0116\n",
      "Train Epoch: 212 [9648/22032] \t Train Loss(MSE): 2.6723 \t Train RMSE: 1.6347\n",
      "Train Epoch: 212 [19248/22032] \t Train Loss(MSE): 21.1938 \t Train RMSE: 4.6037\n",
      "[Epoch: 212 \t Valid MSE: 15.0495 \t Valid RMSE: 3.8794]\n",
      "[Epoch: 212 \t Train MSE: 1.8739 \t Train RMSE: 1.3689]\n",
      "Validation loss decreased (1.920076 --> 1.873916).  Saving model ...\n",
      "Train Epoch: 213 [48/22032] \t Train Loss(MSE): 1.3706 \t Train RMSE: 1.1707\n",
      "Train Epoch: 213 [9648/22032] \t Train Loss(MSE): 0.5212 \t Train RMSE: 0.7219\n",
      "Train Epoch: 213 [19248/22032] \t Train Loss(MSE): 2.8400 \t Train RMSE: 1.6852\n",
      "[Epoch: 213 \t Valid MSE: 14.5274 \t Valid RMSE: 3.8115]\n",
      "[Epoch: 213 \t Train MSE: 1.8708 \t Train RMSE: 1.3678]\n",
      "Validation loss decreased (1.873916 --> 1.870769).  Saving model ...\n",
      "Train Epoch: 214 [48/22032] \t Train Loss(MSE): 0.9105 \t Train RMSE: 0.9542\n",
      "Train Epoch: 214 [9648/22032] \t Train Loss(MSE): 1.0490 \t Train RMSE: 1.0242\n",
      "Train Epoch: 214 [19248/22032] \t Train Loss(MSE): 0.5430 \t Train RMSE: 0.7369\n",
      "[Epoch: 214 \t Valid MSE: 14.6327 \t Valid RMSE: 3.8253]\n",
      "[Epoch: 214 \t Train MSE: 1.8700 \t Train RMSE: 1.3675]\n",
      "Validation loss decreased (1.870769 --> 1.870003).  Saving model ...\n",
      "Train Epoch: 215 [48/22032] \t Train Loss(MSE): 3.2842 \t Train RMSE: 1.8122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 215 [9648/22032] \t Train Loss(MSE): 1.5103 \t Train RMSE: 1.2289\n",
      "Train Epoch: 215 [19248/22032] \t Train Loss(MSE): 1.0090 \t Train RMSE: 1.0045\n",
      "[Epoch: 215 \t Valid MSE: 14.6972 \t Valid RMSE: 3.8337]\n",
      "[Epoch: 215 \t Train MSE: 1.8512 \t Train RMSE: 1.3606]\n",
      "Validation loss decreased (1.870003 --> 1.851206).  Saving model ...\n",
      "Train Epoch: 216 [48/22032] \t Train Loss(MSE): 1.0159 \t Train RMSE: 1.0079\n",
      "Train Epoch: 216 [9648/22032] \t Train Loss(MSE): 0.8757 \t Train RMSE: 0.9358\n",
      "Train Epoch: 216 [19248/22032] \t Train Loss(MSE): 9.1243 \t Train RMSE: 3.0206\n",
      "[Epoch: 216 \t Valid MSE: 14.8496 \t Valid RMSE: 3.8535]\n",
      "[Epoch: 216 \t Train MSE: 1.8326 \t Train RMSE: 1.3537]\n",
      "Validation loss decreased (1.851206 --> 1.832624).  Saving model ...\n",
      "Train Epoch: 217 [48/22032] \t Train Loss(MSE): 2.1174 \t Train RMSE: 1.4551\n",
      "Train Epoch: 217 [9648/22032] \t Train Loss(MSE): 1.1741 \t Train RMSE: 1.0836\n",
      "Train Epoch: 217 [19248/22032] \t Train Loss(MSE): 4.0797 \t Train RMSE: 2.0198\n",
      "[Epoch: 217 \t Valid MSE: 14.5814 \t Valid RMSE: 3.8186]\n",
      "[Epoch: 217 \t Train MSE: 1.8386 \t Train RMSE: 1.3560]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 218 [48/22032] \t Train Loss(MSE): 4.4376 \t Train RMSE: 2.1066\n",
      "Train Epoch: 218 [9648/22032] \t Train Loss(MSE): 0.4410 \t Train RMSE: 0.6641\n",
      "Train Epoch: 218 [19248/22032] \t Train Loss(MSE): 0.6319 \t Train RMSE: 0.7949\n",
      "[Epoch: 218 \t Valid MSE: 14.4324 \t Valid RMSE: 3.7990]\n",
      "[Epoch: 218 \t Train MSE: 1.8616 \t Train RMSE: 1.3644]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 219 [48/22032] \t Train Loss(MSE): 1.4205 \t Train RMSE: 1.1918\n",
      "Train Epoch: 219 [9648/22032] \t Train Loss(MSE): 0.6948 \t Train RMSE: 0.8335\n",
      "Train Epoch: 219 [19248/22032] \t Train Loss(MSE): 0.7850 \t Train RMSE: 0.8860\n",
      "[Epoch: 219 \t Valid MSE: 14.7281 \t Valid RMSE: 3.8377]\n",
      "[Epoch: 219 \t Train MSE: 1.7688 \t Train RMSE: 1.3300]\n",
      "Validation loss decreased (1.832624 --> 1.768831).  Saving model ...\n",
      "Train Epoch: 220 [48/22032] \t Train Loss(MSE): 0.7336 \t Train RMSE: 0.8565\n",
      "Train Epoch: 220 [9648/22032] \t Train Loss(MSE): 3.0262 \t Train RMSE: 1.7396\n",
      "Train Epoch: 220 [19248/22032] \t Train Loss(MSE): 0.4844 \t Train RMSE: 0.6960\n",
      "[Epoch: 220 \t Valid MSE: 14.8870 \t Valid RMSE: 3.8584]\n",
      "[Epoch: 220 \t Train MSE: 1.8032 \t Train RMSE: 1.3428]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 221 [48/22032] \t Train Loss(MSE): 4.2802 \t Train RMSE: 2.0689\n",
      "Train Epoch: 221 [9648/22032] \t Train Loss(MSE): 0.8560 \t Train RMSE: 0.9252\n",
      "Train Epoch: 221 [19248/22032] \t Train Loss(MSE): 1.0605 \t Train RMSE: 1.0298\n",
      "[Epoch: 221 \t Valid MSE: 14.3979 \t Valid RMSE: 3.7945]\n",
      "[Epoch: 221 \t Train MSE: 1.7487 \t Train RMSE: 1.3224]\n",
      "Validation loss decreased (1.768831 --> 1.748668).  Saving model ...\n",
      "Train Epoch: 222 [48/22032] \t Train Loss(MSE): 0.4777 \t Train RMSE: 0.6912\n",
      "Train Epoch: 222 [9648/22032] \t Train Loss(MSE): 0.6749 \t Train RMSE: 0.8215\n",
      "Train Epoch: 222 [19248/22032] \t Train Loss(MSE): 1.6666 \t Train RMSE: 1.2910\n",
      "[Epoch: 222 \t Valid MSE: 14.7729 \t Valid RMSE: 3.8436]\n",
      "[Epoch: 222 \t Train MSE: 1.7629 \t Train RMSE: 1.3277]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 223 [48/22032] \t Train Loss(MSE): 0.9959 \t Train RMSE: 0.9979\n",
      "Train Epoch: 223 [9648/22032] \t Train Loss(MSE): 0.9059 \t Train RMSE: 0.9518\n",
      "Train Epoch: 223 [19248/22032] \t Train Loss(MSE): 0.5604 \t Train RMSE: 0.7486\n",
      "[Epoch: 223 \t Valid MSE: 14.7138 \t Valid RMSE: 3.8359]\n",
      "[Epoch: 223 \t Train MSE: 1.7707 \t Train RMSE: 1.3307]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 224 [48/22032] \t Train Loss(MSE): 1.0822 \t Train RMSE: 1.0403\n",
      "Train Epoch: 224 [9648/22032] \t Train Loss(MSE): 1.2936 \t Train RMSE: 1.1374\n",
      "Train Epoch: 224 [19248/22032] \t Train Loss(MSE): 0.7144 \t Train RMSE: 0.8452\n",
      "[Epoch: 224 \t Valid MSE: 14.6011 \t Valid RMSE: 3.8211]\n",
      "[Epoch: 224 \t Train MSE: 1.7692 \t Train RMSE: 1.3301]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 225 [48/22032] \t Train Loss(MSE): 4.9933 \t Train RMSE: 2.2346\n",
      "Train Epoch: 225 [9648/22032] \t Train Loss(MSE): 0.6238 \t Train RMSE: 0.7898\n",
      "Train Epoch: 225 [19248/22032] \t Train Loss(MSE): 0.8265 \t Train RMSE: 0.9091\n",
      "[Epoch: 225 \t Valid MSE: 14.4366 \t Valid RMSE: 3.7995]\n",
      "[Epoch: 225 \t Train MSE: 1.7790 \t Train RMSE: 1.3338]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 226 [48/22032] \t Train Loss(MSE): 1.1794 \t Train RMSE: 1.0860\n",
      "Train Epoch: 226 [9648/22032] \t Train Loss(MSE): 0.2594 \t Train RMSE: 0.5093\n",
      "Train Epoch: 226 [19248/22032] \t Train Loss(MSE): 1.0984 \t Train RMSE: 1.0481\n",
      "[Epoch: 226 \t Valid MSE: 15.0565 \t Valid RMSE: 3.8803]\n",
      "[Epoch: 226 \t Train MSE: 1.7431 \t Train RMSE: 1.3203]\n",
      "Validation loss decreased (1.748668 --> 1.743122).  Saving model ...\n",
      "Train Epoch: 227 [48/22032] \t Train Loss(MSE): 0.8171 \t Train RMSE: 0.9040\n",
      "Train Epoch: 227 [9648/22032] \t Train Loss(MSE): 0.7275 \t Train RMSE: 0.8530\n",
      "Train Epoch: 227 [19248/22032] \t Train Loss(MSE): 0.8573 \t Train RMSE: 0.9259\n",
      "[Epoch: 227 \t Valid MSE: 14.6409 \t Valid RMSE: 3.8263]\n",
      "[Epoch: 227 \t Train MSE: 1.7194 \t Train RMSE: 1.3112]\n",
      "Validation loss decreased (1.743122 --> 1.719364).  Saving model ...\n",
      "Train Epoch: 228 [48/22032] \t Train Loss(MSE): 5.2717 \t Train RMSE: 2.2960\n",
      "Train Epoch: 228 [9648/22032] \t Train Loss(MSE): 3.6725 \t Train RMSE: 1.9164\n",
      "Train Epoch: 228 [19248/22032] \t Train Loss(MSE): 2.6672 \t Train RMSE: 1.6332\n",
      "[Epoch: 228 \t Valid MSE: 14.7196 \t Valid RMSE: 3.8366]\n",
      "[Epoch: 228 \t Train MSE: 1.8267 \t Train RMSE: 1.3516]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 229 [48/22032] \t Train Loss(MSE): 2.0562 \t Train RMSE: 1.4339\n",
      "Train Epoch: 229 [9648/22032] \t Train Loss(MSE): 2.0958 \t Train RMSE: 1.4477\n",
      "Train Epoch: 229 [19248/22032] \t Train Loss(MSE): 0.3130 \t Train RMSE: 0.5594\n",
      "[Epoch: 229 \t Valid MSE: 14.5968 \t Valid RMSE: 3.8206]\n",
      "[Epoch: 229 \t Train MSE: 1.7631 \t Train RMSE: 1.3278]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 230 [48/22032] \t Train Loss(MSE): 0.6882 \t Train RMSE: 0.8296\n",
      "Train Epoch: 230 [9648/22032] \t Train Loss(MSE): 8.4668 \t Train RMSE: 2.9098\n",
      "Train Epoch: 230 [19248/22032] \t Train Loss(MSE): 0.6641 \t Train RMSE: 0.8150\n",
      "[Epoch: 230 \t Valid MSE: 14.4545 \t Valid RMSE: 3.8019]\n",
      "[Epoch: 230 \t Train MSE: 1.7022 \t Train RMSE: 1.3047]\n",
      "Validation loss decreased (1.719364 --> 1.702236).  Saving model ...\n",
      "Train Epoch: 231 [48/22032] \t Train Loss(MSE): 1.2739 \t Train RMSE: 1.1287\n",
      "Train Epoch: 231 [9648/22032] \t Train Loss(MSE): 0.6285 \t Train RMSE: 0.7928\n",
      "Train Epoch: 231 [19248/22032] \t Train Loss(MSE): 0.6057 \t Train RMSE: 0.7783\n",
      "[Epoch: 231 \t Valid MSE: 14.6284 \t Valid RMSE: 3.8247]\n",
      "[Epoch: 231 \t Train MSE: 1.6603 \t Train RMSE: 1.2885]\n",
      "Validation loss decreased (1.702236 --> 1.660323).  Saving model ...\n",
      "Train Epoch: 232 [48/22032] \t Train Loss(MSE): 1.0308 \t Train RMSE: 1.0153\n",
      "Train Epoch: 232 [9648/22032] \t Train Loss(MSE): 4.6567 \t Train RMSE: 2.1579\n",
      "Train Epoch: 232 [19248/22032] \t Train Loss(MSE): 1.3722 \t Train RMSE: 1.1714\n",
      "[Epoch: 232 \t Valid MSE: 14.9264 \t Valid RMSE: 3.8635]\n",
      "[Epoch: 232 \t Train MSE: 1.6781 \t Train RMSE: 1.2954]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 233 [48/22032] \t Train Loss(MSE): 0.9740 \t Train RMSE: 0.9869\n",
      "Train Epoch: 233 [9648/22032] \t Train Loss(MSE): 1.3030 \t Train RMSE: 1.1415\n",
      "Train Epoch: 233 [19248/22032] \t Train Loss(MSE): 0.8018 \t Train RMSE: 0.8954\n",
      "[Epoch: 233 \t Valid MSE: 14.6398 \t Valid RMSE: 3.8262]\n",
      "[Epoch: 233 \t Train MSE: 1.7418 \t Train RMSE: 1.3198]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 234 [48/22032] \t Train Loss(MSE): 0.8120 \t Train RMSE: 0.9011\n",
      "Train Epoch: 234 [9648/22032] \t Train Loss(MSE): 1.2240 \t Train RMSE: 1.1063\n",
      "Train Epoch: 234 [19248/22032] \t Train Loss(MSE): 13.8581 \t Train RMSE: 3.7226\n",
      "[Epoch: 234 \t Valid MSE: 14.5642 \t Valid RMSE: 3.8163]\n",
      "[Epoch: 234 \t Train MSE: 1.7265 \t Train RMSE: 1.3140]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 235 [48/22032] \t Train Loss(MSE): 0.3545 \t Train RMSE: 0.5954\n",
      "Train Epoch: 235 [9648/22032] \t Train Loss(MSE): 0.5939 \t Train RMSE: 0.7706\n",
      "Train Epoch: 235 [19248/22032] \t Train Loss(MSE): 0.5431 \t Train RMSE: 0.7370\n",
      "[Epoch: 235 \t Valid MSE: 14.9880 \t Valid RMSE: 3.8714]\n",
      "[Epoch: 235 \t Train MSE: 1.6565 \t Train RMSE: 1.2871]\n",
      "Validation loss decreased (1.660323 --> 1.656534).  Saving model ...\n",
      "Train Epoch: 236 [48/22032] \t Train Loss(MSE): 0.3160 \t Train RMSE: 0.5621\n",
      "Train Epoch: 236 [9648/22032] \t Train Loss(MSE): 0.6322 \t Train RMSE: 0.7951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 236 [19248/22032] \t Train Loss(MSE): 1.1649 \t Train RMSE: 1.0793\n",
      "[Epoch: 236 \t Valid MSE: 14.8014 \t Valid RMSE: 3.8473]\n",
      "[Epoch: 236 \t Train MSE: 1.6342 \t Train RMSE: 1.2783]\n",
      "Validation loss decreased (1.656534 --> 1.634166).  Saving model ...\n",
      "Train Epoch: 237 [48/22032] \t Train Loss(MSE): 1.1514 \t Train RMSE: 1.0730\n",
      "Train Epoch: 237 [9648/22032] \t Train Loss(MSE): 0.3576 \t Train RMSE: 0.5980\n",
      "Train Epoch: 237 [19248/22032] \t Train Loss(MSE): 0.5309 \t Train RMSE: 0.7286\n",
      "[Epoch: 237 \t Valid MSE: 14.7463 \t Valid RMSE: 3.8401]\n",
      "[Epoch: 237 \t Train MSE: 1.6584 \t Train RMSE: 1.2878]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 238 [48/22032] \t Train Loss(MSE): 0.3172 \t Train RMSE: 0.5632\n",
      "Train Epoch: 238 [9648/22032] \t Train Loss(MSE): 1.7577 \t Train RMSE: 1.3258\n",
      "Train Epoch: 238 [19248/22032] \t Train Loss(MSE): 1.2780 \t Train RMSE: 1.1305\n",
      "[Epoch: 238 \t Valid MSE: 14.6869 \t Valid RMSE: 3.8324]\n",
      "[Epoch: 238 \t Train MSE: 1.6249 \t Train RMSE: 1.2747]\n",
      "Validation loss decreased (1.634166 --> 1.624866).  Saving model ...\n",
      "Train Epoch: 239 [48/22032] \t Train Loss(MSE): 3.2314 \t Train RMSE: 1.7976\n",
      "Train Epoch: 239 [9648/22032] \t Train Loss(MSE): 0.4156 \t Train RMSE: 0.6447\n",
      "Train Epoch: 239 [19248/22032] \t Train Loss(MSE): 0.4749 \t Train RMSE: 0.6892\n",
      "[Epoch: 239 \t Valid MSE: 14.7994 \t Valid RMSE: 3.8470]\n",
      "[Epoch: 239 \t Train MSE: 1.6213 \t Train RMSE: 1.2733]\n",
      "Validation loss decreased (1.624866 --> 1.621325).  Saving model ...\n",
      "Train Epoch: 240 [48/22032] \t Train Loss(MSE): 2.6917 \t Train RMSE: 1.6406\n",
      "Train Epoch: 240 [9648/22032] \t Train Loss(MSE): 0.3746 \t Train RMSE: 0.6121\n",
      "Train Epoch: 240 [19248/22032] \t Train Loss(MSE): 1.1102 \t Train RMSE: 1.0537\n",
      "[Epoch: 240 \t Valid MSE: 14.7682 \t Valid RMSE: 3.8429]\n",
      "[Epoch: 240 \t Train MSE: 1.6279 \t Train RMSE: 1.2759]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 241 [48/22032] \t Train Loss(MSE): 0.7489 \t Train RMSE: 0.8654\n",
      "Train Epoch: 241 [9648/22032] \t Train Loss(MSE): 0.4167 \t Train RMSE: 0.6455\n",
      "Train Epoch: 241 [19248/22032] \t Train Loss(MSE): 4.4459 \t Train RMSE: 2.1085\n",
      "[Epoch: 241 \t Valid MSE: 14.9046 \t Valid RMSE: 3.8607]\n",
      "[Epoch: 241 \t Train MSE: 1.6732 \t Train RMSE: 1.2935]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 242 [48/22032] \t Train Loss(MSE): 0.5732 \t Train RMSE: 0.7571\n",
      "Train Epoch: 242 [9648/22032] \t Train Loss(MSE): 1.9900 \t Train RMSE: 1.4107\n",
      "Train Epoch: 242 [19248/22032] \t Train Loss(MSE): 4.7060 \t Train RMSE: 2.1693\n",
      "[Epoch: 242 \t Valid MSE: 14.9494 \t Valid RMSE: 3.8664]\n",
      "[Epoch: 242 \t Train MSE: 1.6171 \t Train RMSE: 1.2717]\n",
      "Validation loss decreased (1.621325 --> 1.617123).  Saving model ...\n",
      "Train Epoch: 243 [48/22032] \t Train Loss(MSE): 8.4071 \t Train RMSE: 2.8995\n",
      "Train Epoch: 243 [9648/22032] \t Train Loss(MSE): 0.5034 \t Train RMSE: 0.7095\n",
      "Train Epoch: 243 [19248/22032] \t Train Loss(MSE): 1.0781 \t Train RMSE: 1.0383\n",
      "[Epoch: 243 \t Valid MSE: 14.7061 \t Valid RMSE: 3.8349]\n",
      "[Epoch: 243 \t Train MSE: 1.6280 \t Train RMSE: 1.2759]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 244 [48/22032] \t Train Loss(MSE): 0.6337 \t Train RMSE: 0.7961\n",
      "Train Epoch: 244 [9648/22032] \t Train Loss(MSE): 0.4658 \t Train RMSE: 0.6825\n",
      "Train Epoch: 244 [19248/22032] \t Train Loss(MSE): 0.9518 \t Train RMSE: 0.9756\n",
      "[Epoch: 244 \t Valid MSE: 14.9590 \t Valid RMSE: 3.8677]\n",
      "[Epoch: 244 \t Train MSE: 1.6243 \t Train RMSE: 1.2745]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 245 [48/22032] \t Train Loss(MSE): 0.5214 \t Train RMSE: 0.7221\n",
      "Train Epoch: 245 [9648/22032] \t Train Loss(MSE): 0.3247 \t Train RMSE: 0.5698\n",
      "Train Epoch: 245 [19248/22032] \t Train Loss(MSE): 0.7658 \t Train RMSE: 0.8751\n",
      "[Epoch: 245 \t Valid MSE: 14.9088 \t Valid RMSE: 3.8612]\n",
      "[Epoch: 245 \t Train MSE: 1.6413 \t Train RMSE: 1.2811]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 246 [48/22032] \t Train Loss(MSE): 0.3816 \t Train RMSE: 0.6177\n",
      "Train Epoch: 246 [9648/22032] \t Train Loss(MSE): 0.8471 \t Train RMSE: 0.9204\n",
      "Train Epoch: 246 [19248/22032] \t Train Loss(MSE): 4.3249 \t Train RMSE: 2.0796\n",
      "[Epoch: 246 \t Valid MSE: 15.0758 \t Valid RMSE: 3.8828]\n",
      "[Epoch: 246 \t Train MSE: 1.5817 \t Train RMSE: 1.2577]\n",
      "Validation loss decreased (1.617123 --> 1.581709).  Saving model ...\n",
      "Train Epoch: 247 [48/22032] \t Train Loss(MSE): 0.3812 \t Train RMSE: 0.6174\n",
      "Train Epoch: 247 [9648/22032] \t Train Loss(MSE): 5.3448 \t Train RMSE: 2.3119\n",
      "Train Epoch: 247 [19248/22032] \t Train Loss(MSE): 1.1013 \t Train RMSE: 1.0494\n",
      "[Epoch: 247 \t Valid MSE: 14.9410 \t Valid RMSE: 3.8654]\n",
      "[Epoch: 247 \t Train MSE: 1.6920 \t Train RMSE: 1.3008]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 248 [48/22032] \t Train Loss(MSE): 1.0114 \t Train RMSE: 1.0057\n",
      "Train Epoch: 248 [9648/22032] \t Train Loss(MSE): 0.7161 \t Train RMSE: 0.8463\n",
      "Train Epoch: 248 [19248/22032] \t Train Loss(MSE): 0.7034 \t Train RMSE: 0.8387\n",
      "[Epoch: 248 \t Valid MSE: 14.7876 \t Valid RMSE: 3.8455]\n",
      "[Epoch: 248 \t Train MSE: 1.6451 \t Train RMSE: 1.2826]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 249 [48/22032] \t Train Loss(MSE): 0.7269 \t Train RMSE: 0.8526\n",
      "Train Epoch: 249 [9648/22032] \t Train Loss(MSE): 0.6702 \t Train RMSE: 0.8187\n",
      "Train Epoch: 249 [19248/22032] \t Train Loss(MSE): 0.4282 \t Train RMSE: 0.6544\n",
      "[Epoch: 249 \t Valid MSE: 14.9853 \t Valid RMSE: 3.8711]\n",
      "[Epoch: 249 \t Train MSE: 1.6024 \t Train RMSE: 1.2659]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 250 [48/22032] \t Train Loss(MSE): 0.4329 \t Train RMSE: 0.6580\n",
      "Train Epoch: 250 [9648/22032] \t Train Loss(MSE): 12.6063 \t Train RMSE: 3.5505\n",
      "Train Epoch: 250 [19248/22032] \t Train Loss(MSE): 0.7360 \t Train RMSE: 0.8579\n",
      "[Epoch: 250 \t Valid MSE: 15.9481 \t Valid RMSE: 3.9935]\n",
      "[Epoch: 250 \t Train MSE: 1.5422 \t Train RMSE: 1.2419]\n",
      "Validation loss decreased (1.581709 --> 1.542234).  Saving model ...\n",
      "Train Epoch: 251 [48/22032] \t Train Loss(MSE): 0.3270 \t Train RMSE: 0.5719\n",
      "Train Epoch: 251 [9648/22032] \t Train Loss(MSE): 0.5333 \t Train RMSE: 0.7303\n",
      "Train Epoch: 251 [19248/22032] \t Train Loss(MSE): 0.9883 \t Train RMSE: 0.9941\n",
      "[Epoch: 251 \t Valid MSE: 14.5621 \t Valid RMSE: 3.8160]\n",
      "[Epoch: 251 \t Train MSE: 1.5603 \t Train RMSE: 1.2491]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 252 [48/22032] \t Train Loss(MSE): 0.4602 \t Train RMSE: 0.6783\n",
      "Train Epoch: 252 [9648/22032] \t Train Loss(MSE): 0.6345 \t Train RMSE: 0.7966\n",
      "Train Epoch: 252 [19248/22032] \t Train Loss(MSE): 0.4755 \t Train RMSE: 0.6896\n",
      "[Epoch: 252 \t Valid MSE: 14.9769 \t Valid RMSE: 3.8700]\n",
      "[Epoch: 252 \t Train MSE: 1.5316 \t Train RMSE: 1.2376]\n",
      "Validation loss decreased (1.542234 --> 1.531629).  Saving model ...\n",
      "Train Epoch: 253 [48/22032] \t Train Loss(MSE): 0.6121 \t Train RMSE: 0.7824\n",
      "Train Epoch: 253 [9648/22032] \t Train Loss(MSE): 3.5399 \t Train RMSE: 1.8815\n",
      "Train Epoch: 253 [19248/22032] \t Train Loss(MSE): 10.1397 \t Train RMSE: 3.1843\n",
      "[Epoch: 253 \t Valid MSE: 14.7448 \t Valid RMSE: 3.8399]\n",
      "[Epoch: 253 \t Train MSE: 1.6211 \t Train RMSE: 1.2732]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 254 [48/22032] \t Train Loss(MSE): 0.4930 \t Train RMSE: 0.7022\n",
      "Train Epoch: 254 [9648/22032] \t Train Loss(MSE): 0.2765 \t Train RMSE: 0.5259\n",
      "Train Epoch: 254 [19248/22032] \t Train Loss(MSE): 1.2311 \t Train RMSE: 1.1095\n",
      "[Epoch: 254 \t Valid MSE: 14.8276 \t Valid RMSE: 3.8507]\n",
      "[Epoch: 254 \t Train MSE: 1.5355 \t Train RMSE: 1.2391]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 255 [48/22032] \t Train Loss(MSE): 0.3280 \t Train RMSE: 0.5727\n",
      "Train Epoch: 255 [9648/22032] \t Train Loss(MSE): 0.5482 \t Train RMSE: 0.7404\n",
      "Train Epoch: 255 [19248/22032] \t Train Loss(MSE): 0.6272 \t Train RMSE: 0.7919\n",
      "[Epoch: 255 \t Valid MSE: 15.0032 \t Valid RMSE: 3.8734]\n",
      "[Epoch: 255 \t Train MSE: 1.5540 \t Train RMSE: 1.2466]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 256 [48/22032] \t Train Loss(MSE): 0.5649 \t Train RMSE: 0.7516\n",
      "Train Epoch: 256 [9648/22032] \t Train Loss(MSE): 1.4547 \t Train RMSE: 1.2061\n",
      "Train Epoch: 256 [19248/22032] \t Train Loss(MSE): 0.4458 \t Train RMSE: 0.6677\n",
      "[Epoch: 256 \t Valid MSE: 14.7756 \t Valid RMSE: 3.8439]\n",
      "[Epoch: 256 \t Train MSE: 1.5189 \t Train RMSE: 1.2324]\n",
      "Validation loss decreased (1.531629 --> 1.518919).  Saving model ...\n",
      "Train Epoch: 257 [48/22032] \t Train Loss(MSE): 0.7849 \t Train RMSE: 0.8860\n",
      "Train Epoch: 257 [9648/22032] \t Train Loss(MSE): 0.9038 \t Train RMSE: 0.9507\n",
      "Train Epoch: 257 [19248/22032] \t Train Loss(MSE): 0.7747 \t Train RMSE: 0.8802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 257 \t Valid MSE: 14.9375 \t Valid RMSE: 3.8649]\n",
      "[Epoch: 257 \t Train MSE: 1.5603 \t Train RMSE: 1.2491]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 258 [48/22032] \t Train Loss(MSE): 0.2832 \t Train RMSE: 0.5322\n",
      "Train Epoch: 258 [9648/22032] \t Train Loss(MSE): 0.7927 \t Train RMSE: 0.8904\n",
      "Train Epoch: 258 [19248/22032] \t Train Loss(MSE): 1.1766 \t Train RMSE: 1.0847\n",
      "[Epoch: 258 \t Valid MSE: 14.7004 \t Valid RMSE: 3.8341]\n",
      "[Epoch: 258 \t Train MSE: 1.6475 \t Train RMSE: 1.2836]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 259 [48/22032] \t Train Loss(MSE): 0.3657 \t Train RMSE: 0.6048\n",
      "Train Epoch: 259 [9648/22032] \t Train Loss(MSE): 0.4566 \t Train RMSE: 0.6757\n",
      "Train Epoch: 259 [19248/22032] \t Train Loss(MSE): 0.7839 \t Train RMSE: 0.8854\n",
      "[Epoch: 259 \t Valid MSE: 14.8953 \t Valid RMSE: 3.8594]\n",
      "[Epoch: 259 \t Train MSE: 1.6010 \t Train RMSE: 1.2653]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 260 [48/22032] \t Train Loss(MSE): 0.3992 \t Train RMSE: 0.6318\n",
      "Train Epoch: 260 [9648/22032] \t Train Loss(MSE): 4.3933 \t Train RMSE: 2.0960\n",
      "Train Epoch: 260 [19248/22032] \t Train Loss(MSE): 0.9896 \t Train RMSE: 0.9948\n",
      "[Epoch: 260 \t Valid MSE: 14.8776 \t Valid RMSE: 3.8572]\n",
      "[Epoch: 260 \t Train MSE: 1.5182 \t Train RMSE: 1.2322]\n",
      "Validation loss decreased (1.518919 --> 1.518244).  Saving model ...\n",
      "Train Epoch: 261 [48/22032] \t Train Loss(MSE): 10.3844 \t Train RMSE: 3.2225\n",
      "Train Epoch: 261 [9648/22032] \t Train Loss(MSE): 1.2328 \t Train RMSE: 1.1103\n",
      "Train Epoch: 261 [19248/22032] \t Train Loss(MSE): 0.4921 \t Train RMSE: 0.7015\n",
      "[Epoch: 261 \t Valid MSE: 14.9207 \t Valid RMSE: 3.8627]\n",
      "[Epoch: 261 \t Train MSE: 1.5657 \t Train RMSE: 1.2513]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 262 [48/22032] \t Train Loss(MSE): 0.3681 \t Train RMSE: 0.6068\n",
      "Train Epoch: 262 [9648/22032] \t Train Loss(MSE): 0.4455 \t Train RMSE: 0.6675\n",
      "Train Epoch: 262 [19248/22032] \t Train Loss(MSE): 0.4097 \t Train RMSE: 0.6401\n",
      "[Epoch: 262 \t Valid MSE: 15.4714 \t Valid RMSE: 3.9334]\n",
      "[Epoch: 262 \t Train MSE: 1.6464 \t Train RMSE: 1.2831]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 263 [48/22032] \t Train Loss(MSE): 0.6971 \t Train RMSE: 0.8349\n",
      "Train Epoch: 263 [9648/22032] \t Train Loss(MSE): 0.8610 \t Train RMSE: 0.9279\n",
      "Train Epoch: 263 [19248/22032] \t Train Loss(MSE): 1.4105 \t Train RMSE: 1.1877\n",
      "[Epoch: 263 \t Valid MSE: 15.2143 \t Valid RMSE: 3.9006]\n",
      "[Epoch: 263 \t Train MSE: 1.5479 \t Train RMSE: 1.2442]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 264 [48/22032] \t Train Loss(MSE): 0.8067 \t Train RMSE: 0.8982\n",
      "Train Epoch: 264 [9648/22032] \t Train Loss(MSE): 0.2922 \t Train RMSE: 0.5406\n",
      "Train Epoch: 264 [19248/22032] \t Train Loss(MSE): 1.5771 \t Train RMSE: 1.2558\n",
      "[Epoch: 264 \t Valid MSE: 14.6236 \t Valid RMSE: 3.8241]\n",
      "[Epoch: 264 \t Train MSE: 1.5194 \t Train RMSE: 1.2327]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 265 [48/22032] \t Train Loss(MSE): 5.2038 \t Train RMSE: 2.2812\n",
      "Train Epoch: 265 [9648/22032] \t Train Loss(MSE): 0.2549 \t Train RMSE: 0.5049\n",
      "Train Epoch: 265 [19248/22032] \t Train Loss(MSE): 0.3414 \t Train RMSE: 0.5843\n",
      "[Epoch: 265 \t Valid MSE: 14.9412 \t Valid RMSE: 3.8654]\n",
      "[Epoch: 265 \t Train MSE: 1.4889 \t Train RMSE: 1.2202]\n",
      "Validation loss decreased (1.518244 --> 1.488946).  Saving model ...\n",
      "Train Epoch: 266 [48/22032] \t Train Loss(MSE): 0.5903 \t Train RMSE: 0.7683\n",
      "Train Epoch: 266 [9648/22032] \t Train Loss(MSE): 0.4787 \t Train RMSE: 0.6919\n",
      "Train Epoch: 266 [19248/22032] \t Train Loss(MSE): 0.4530 \t Train RMSE: 0.6731\n",
      "[Epoch: 266 \t Valid MSE: 14.8741 \t Valid RMSE: 3.8567]\n",
      "[Epoch: 266 \t Train MSE: 1.6918 \t Train RMSE: 1.3007]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 267 [48/22032] \t Train Loss(MSE): 0.6631 \t Train RMSE: 0.8143\n",
      "Train Epoch: 267 [9648/22032] \t Train Loss(MSE): 1.1891 \t Train RMSE: 1.0905\n",
      "Train Epoch: 267 [19248/22032] \t Train Loss(MSE): 0.4980 \t Train RMSE: 0.7057\n",
      "[Epoch: 267 \t Valid MSE: 15.0659 \t Valid RMSE: 3.8815]\n",
      "[Epoch: 267 \t Train MSE: 1.5722 \t Train RMSE: 1.2539]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 268 [48/22032] \t Train Loss(MSE): 0.4809 \t Train RMSE: 0.6935\n",
      "Train Epoch: 268 [9648/22032] \t Train Loss(MSE): 0.5139 \t Train RMSE: 0.7169\n",
      "Train Epoch: 268 [19248/22032] \t Train Loss(MSE): 0.4136 \t Train RMSE: 0.6431\n",
      "[Epoch: 268 \t Valid MSE: 15.6308 \t Valid RMSE: 3.9536]\n",
      "[Epoch: 268 \t Train MSE: 1.5028 \t Train RMSE: 1.2259]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 269 [48/22032] \t Train Loss(MSE): 0.8561 \t Train RMSE: 0.9253\n",
      "Train Epoch: 269 [9648/22032] \t Train Loss(MSE): 0.4996 \t Train RMSE: 0.7068\n",
      "Train Epoch: 269 [19248/22032] \t Train Loss(MSE): 0.3033 \t Train RMSE: 0.5508\n",
      "[Epoch: 269 \t Valid MSE: 14.9148 \t Valid RMSE: 3.8620]\n",
      "[Epoch: 269 \t Train MSE: 1.4855 \t Train RMSE: 1.2188]\n",
      "Validation loss decreased (1.488946 --> 1.485520).  Saving model ...\n",
      "Train Epoch: 270 [48/22032] \t Train Loss(MSE): 0.3746 \t Train RMSE: 0.6121\n",
      "Train Epoch: 270 [9648/22032] \t Train Loss(MSE): 11.2631 \t Train RMSE: 3.3560\n",
      "Train Epoch: 270 [19248/22032] \t Train Loss(MSE): 0.2463 \t Train RMSE: 0.4963\n",
      "[Epoch: 270 \t Valid MSE: 15.2088 \t Valid RMSE: 3.8998]\n",
      "[Epoch: 270 \t Train MSE: 1.4764 \t Train RMSE: 1.2151]\n",
      "Validation loss decreased (1.485520 --> 1.476384).  Saving model ...\n",
      "Train Epoch: 271 [48/22032] \t Train Loss(MSE): 3.9785 \t Train RMSE: 1.9946\n",
      "Train Epoch: 271 [9648/22032] \t Train Loss(MSE): 0.3563 \t Train RMSE: 0.5969\n",
      "Train Epoch: 271 [19248/22032] \t Train Loss(MSE): 0.6189 \t Train RMSE: 0.7867\n",
      "[Epoch: 271 \t Valid MSE: 15.1169 \t Valid RMSE: 3.8880]\n",
      "[Epoch: 271 \t Train MSE: 1.5708 \t Train RMSE: 1.2533]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 272 [48/22032] \t Train Loss(MSE): 0.5156 \t Train RMSE: 0.7181\n",
      "Train Epoch: 272 [9648/22032] \t Train Loss(MSE): 1.9527 \t Train RMSE: 1.3974\n",
      "Train Epoch: 272 [19248/22032] \t Train Loss(MSE): 0.5712 \t Train RMSE: 0.7558\n",
      "[Epoch: 272 \t Valid MSE: 15.0125 \t Valid RMSE: 3.8746]\n",
      "[Epoch: 272 \t Train MSE: 1.4367 \t Train RMSE: 1.1986]\n",
      "Validation loss decreased (1.476384 --> 1.436747).  Saving model ...\n",
      "Train Epoch: 273 [48/22032] \t Train Loss(MSE): 0.3547 \t Train RMSE: 0.5955\n",
      "Train Epoch: 273 [9648/22032] \t Train Loss(MSE): 0.6229 \t Train RMSE: 0.7892\n",
      "Train Epoch: 273 [19248/22032] \t Train Loss(MSE): 1.9069 \t Train RMSE: 1.3809\n",
      "[Epoch: 273 \t Valid MSE: 14.7505 \t Valid RMSE: 3.8406]\n",
      "[Epoch: 273 \t Train MSE: 1.4158 \t Train RMSE: 1.1899]\n",
      "Validation loss decreased (1.436747 --> 1.415794).  Saving model ...\n",
      "Train Epoch: 274 [48/22032] \t Train Loss(MSE): 0.5075 \t Train RMSE: 0.7124\n",
      "Train Epoch: 274 [9648/22032] \t Train Loss(MSE): 14.4545 \t Train RMSE: 3.8019\n",
      "Train Epoch: 274 [19248/22032] \t Train Loss(MSE): 0.5257 \t Train RMSE: 0.7250\n",
      "[Epoch: 274 \t Valid MSE: 14.8941 \t Valid RMSE: 3.8593]\n",
      "[Epoch: 274 \t Train MSE: 1.4881 \t Train RMSE: 1.2199]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 275 [48/22032] \t Train Loss(MSE): 0.5458 \t Train RMSE: 0.7388\n",
      "Train Epoch: 275 [9648/22032] \t Train Loss(MSE): 0.3154 \t Train RMSE: 0.5616\n",
      "Train Epoch: 275 [19248/22032] \t Train Loss(MSE): 3.5891 \t Train RMSE: 1.8945\n",
      "[Epoch: 275 \t Valid MSE: 15.2941 \t Valid RMSE: 3.9108]\n",
      "[Epoch: 275 \t Train MSE: 1.4765 \t Train RMSE: 1.2151]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 276 [48/22032] \t Train Loss(MSE): 2.5606 \t Train RMSE: 1.6002\n",
      "Train Epoch: 276 [9648/22032] \t Train Loss(MSE): 3.0599 \t Train RMSE: 1.7493\n",
      "Train Epoch: 276 [19248/22032] \t Train Loss(MSE): 0.5230 \t Train RMSE: 0.7232\n",
      "[Epoch: 276 \t Valid MSE: 14.9832 \t Valid RMSE: 3.8708]\n",
      "[Epoch: 276 \t Train MSE: 1.5130 \t Train RMSE: 1.2301]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 277 [48/22032] \t Train Loss(MSE): 0.4633 \t Train RMSE: 0.6807\n",
      "Train Epoch: 277 [9648/22032] \t Train Loss(MSE): 0.9027 \t Train RMSE: 0.9501\n",
      "Train Epoch: 277 [19248/22032] \t Train Loss(MSE): 0.4164 \t Train RMSE: 0.6453\n",
      "[Epoch: 277 \t Valid MSE: 15.2699 \t Valid RMSE: 3.9077]\n",
      "[Epoch: 277 \t Train MSE: 1.4603 \t Train RMSE: 1.2084]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 278 [48/22032] \t Train Loss(MSE): 0.8560 \t Train RMSE: 0.9252\n",
      "Train Epoch: 278 [9648/22032] \t Train Loss(MSE): 0.3021 \t Train RMSE: 0.5496\n",
      "Train Epoch: 278 [19248/22032] \t Train Loss(MSE): 3.9038 \t Train RMSE: 1.9758\n",
      "[Epoch: 278 \t Valid MSE: 14.8359 \t Valid RMSE: 3.8517]\n",
      "[Epoch: 278 \t Train MSE: 1.5469 \t Train RMSE: 1.2437]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 279 [48/22032] \t Train Loss(MSE): 0.6748 \t Train RMSE: 0.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 279 [9648/22032] \t Train Loss(MSE): 0.3577 \t Train RMSE: 0.5981\n",
      "Train Epoch: 279 [19248/22032] \t Train Loss(MSE): 2.3836 \t Train RMSE: 1.5439\n",
      "[Epoch: 279 \t Valid MSE: 15.0284 \t Valid RMSE: 3.8767]\n",
      "[Epoch: 279 \t Train MSE: 1.6863 \t Train RMSE: 1.2986]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 280 [48/22032] \t Train Loss(MSE): 0.3567 \t Train RMSE: 0.5973\n",
      "Train Epoch: 280 [9648/22032] \t Train Loss(MSE): 0.5775 \t Train RMSE: 0.7599\n",
      "Train Epoch: 280 [19248/22032] \t Train Loss(MSE): 0.3753 \t Train RMSE: 0.6127\n",
      "[Epoch: 280 \t Valid MSE: 14.8480 \t Valid RMSE: 3.8533]\n",
      "[Epoch: 280 \t Train MSE: 1.5291 \t Train RMSE: 1.2365]\n",
      "EarlyStopping counter: 7 out of 40\n",
      "Train Epoch: 281 [48/22032] \t Train Loss(MSE): 3.0488 \t Train RMSE: 1.7461\n",
      "Train Epoch: 281 [9648/22032] \t Train Loss(MSE): 0.2972 \t Train RMSE: 0.5451\n",
      "Train Epoch: 281 [19248/22032] \t Train Loss(MSE): 0.2989 \t Train RMSE: 0.5467\n",
      "[Epoch: 281 \t Valid MSE: 14.9373 \t Valid RMSE: 3.8649]\n",
      "[Epoch: 281 \t Train MSE: 1.4039 \t Train RMSE: 1.1849]\n",
      "Validation loss decreased (1.415794 --> 1.403918).  Saving model ...\n",
      "Train Epoch: 282 [48/22032] \t Train Loss(MSE): 11.0380 \t Train RMSE: 3.3224\n",
      "Train Epoch: 282 [9648/22032] \t Train Loss(MSE): 10.0589 \t Train RMSE: 3.1716\n",
      "Train Epoch: 282 [19248/22032] \t Train Loss(MSE): 0.5178 \t Train RMSE: 0.7196\n",
      "[Epoch: 282 \t Valid MSE: 15.0455 \t Valid RMSE: 3.8789]\n",
      "[Epoch: 282 \t Train MSE: 1.4470 \t Train RMSE: 1.2029]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 283 [48/22032] \t Train Loss(MSE): 0.7594 \t Train RMSE: 0.8715\n",
      "Train Epoch: 283 [9648/22032] \t Train Loss(MSE): 0.2357 \t Train RMSE: 0.4855\n",
      "Train Epoch: 283 [19248/22032] \t Train Loss(MSE): 0.6323 \t Train RMSE: 0.7952\n",
      "[Epoch: 283 \t Valid MSE: 14.9934 \t Valid RMSE: 3.8721]\n",
      "[Epoch: 283 \t Train MSE: 1.4695 \t Train RMSE: 1.2122]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 284 [48/22032] \t Train Loss(MSE): 0.7481 \t Train RMSE: 0.8649\n",
      "Train Epoch: 284 [9648/22032] \t Train Loss(MSE): 0.9642 \t Train RMSE: 0.9819\n",
      "Train Epoch: 284 [19248/22032] \t Train Loss(MSE): 0.4899 \t Train RMSE: 0.6999\n",
      "[Epoch: 284 \t Valid MSE: 14.7964 \t Valid RMSE: 3.8466]\n",
      "[Epoch: 284 \t Train MSE: 1.4521 \t Train RMSE: 1.2050]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 285 [48/22032] \t Train Loss(MSE): 0.2536 \t Train RMSE: 0.5035\n",
      "Train Epoch: 285 [9648/22032] \t Train Loss(MSE): 1.0577 \t Train RMSE: 1.0285\n",
      "Train Epoch: 285 [19248/22032] \t Train Loss(MSE): 0.4563 \t Train RMSE: 0.6755\n",
      "[Epoch: 285 \t Valid MSE: 14.9712 \t Valid RMSE: 3.8693]\n",
      "[Epoch: 285 \t Train MSE: 1.4562 \t Train RMSE: 1.2067]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 286 [48/22032] \t Train Loss(MSE): 0.4588 \t Train RMSE: 0.6773\n",
      "Train Epoch: 286 [9648/22032] \t Train Loss(MSE): 0.5230 \t Train RMSE: 0.7232\n",
      "Train Epoch: 286 [19248/22032] \t Train Loss(MSE): 0.4560 \t Train RMSE: 0.6753\n",
      "[Epoch: 286 \t Valid MSE: 15.0245 \t Valid RMSE: 3.8761]\n",
      "[Epoch: 286 \t Train MSE: 1.3877 \t Train RMSE: 1.1780]\n",
      "Validation loss decreased (1.403918 --> 1.387667).  Saving model ...\n",
      "Train Epoch: 287 [48/22032] \t Train Loss(MSE): 0.3909 \t Train RMSE: 0.6252\n",
      "Train Epoch: 287 [9648/22032] \t Train Loss(MSE): 0.2985 \t Train RMSE: 0.5463\n",
      "Train Epoch: 287 [19248/22032] \t Train Loss(MSE): 0.2810 \t Train RMSE: 0.5301\n",
      "[Epoch: 287 \t Valid MSE: 15.2906 \t Valid RMSE: 3.9103]\n",
      "[Epoch: 287 \t Train MSE: 1.3756 \t Train RMSE: 1.1728]\n",
      "Validation loss decreased (1.387667 --> 1.375556).  Saving model ...\n",
      "Train Epoch: 288 [48/22032] \t Train Loss(MSE): 1.1253 \t Train RMSE: 1.0608\n",
      "Train Epoch: 288 [9648/22032] \t Train Loss(MSE): 0.3823 \t Train RMSE: 0.6183\n",
      "Train Epoch: 288 [19248/22032] \t Train Loss(MSE): 0.4694 \t Train RMSE: 0.6851\n",
      "[Epoch: 288 \t Valid MSE: 14.9515 \t Valid RMSE: 3.8667]\n",
      "[Epoch: 288 \t Train MSE: 1.4426 \t Train RMSE: 1.2011]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 289 [48/22032] \t Train Loss(MSE): 2.2948 \t Train RMSE: 1.5148\n",
      "Train Epoch: 289 [9648/22032] \t Train Loss(MSE): 0.4975 \t Train RMSE: 0.7053\n",
      "Train Epoch: 289 [19248/22032] \t Train Loss(MSE): 0.5889 \t Train RMSE: 0.7674\n",
      "[Epoch: 289 \t Valid MSE: 15.1246 \t Valid RMSE: 3.8890]\n",
      "[Epoch: 289 \t Train MSE: 1.4673 \t Train RMSE: 1.2113]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 290 [48/22032] \t Train Loss(MSE): 0.5064 \t Train RMSE: 0.7116\n",
      "Train Epoch: 290 [9648/22032] \t Train Loss(MSE): 0.5148 \t Train RMSE: 0.7175\n",
      "Train Epoch: 290 [19248/22032] \t Train Loss(MSE): 1.0610 \t Train RMSE: 1.0301\n",
      "[Epoch: 290 \t Valid MSE: 15.1162 \t Valid RMSE: 3.8880]\n",
      "[Epoch: 290 \t Train MSE: 1.4375 \t Train RMSE: 1.1990]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 291 [48/22032] \t Train Loss(MSE): 2.0622 \t Train RMSE: 1.4360\n",
      "Train Epoch: 291 [9648/22032] \t Train Loss(MSE): 1.1758 \t Train RMSE: 1.0843\n",
      "Train Epoch: 291 [19248/22032] \t Train Loss(MSE): 0.4252 \t Train RMSE: 0.6520\n",
      "[Epoch: 291 \t Valid MSE: 15.2727 \t Valid RMSE: 3.9080]\n",
      "[Epoch: 291 \t Train MSE: 1.6236 \t Train RMSE: 1.2742]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 292 [48/22032] \t Train Loss(MSE): 1.1956 \t Train RMSE: 1.0934\n",
      "Train Epoch: 292 [9648/22032] \t Train Loss(MSE): 0.4752 \t Train RMSE: 0.6894\n",
      "Train Epoch: 292 [19248/22032] \t Train Loss(MSE): 0.5413 \t Train RMSE: 0.7358\n",
      "[Epoch: 292 \t Valid MSE: 14.8857 \t Valid RMSE: 3.8582]\n",
      "[Epoch: 292 \t Train MSE: 1.4930 \t Train RMSE: 1.2219]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 293 [48/22032] \t Train Loss(MSE): 2.9154 \t Train RMSE: 1.7075\n",
      "Train Epoch: 293 [9648/22032] \t Train Loss(MSE): 0.4913 \t Train RMSE: 0.7009\n",
      "Train Epoch: 293 [19248/22032] \t Train Loss(MSE): 0.2688 \t Train RMSE: 0.5184\n",
      "[Epoch: 293 \t Valid MSE: 14.9957 \t Valid RMSE: 3.8724]\n",
      "[Epoch: 293 \t Train MSE: 1.4092 \t Train RMSE: 1.1871]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 294 [48/22032] \t Train Loss(MSE): 0.3311 \t Train RMSE: 0.5754\n",
      "Train Epoch: 294 [9648/22032] \t Train Loss(MSE): 0.6489 \t Train RMSE: 0.8055\n",
      "Train Epoch: 294 [19248/22032] \t Train Loss(MSE): 0.4948 \t Train RMSE: 0.7034\n",
      "[Epoch: 294 \t Valid MSE: 14.8401 \t Valid RMSE: 3.8523]\n",
      "[Epoch: 294 \t Train MSE: 1.4248 \t Train RMSE: 1.1936]\n",
      "EarlyStopping counter: 7 out of 40\n",
      "Train Epoch: 295 [48/22032] \t Train Loss(MSE): 0.5512 \t Train RMSE: 0.7424\n",
      "Train Epoch: 295 [9648/22032] \t Train Loss(MSE): 0.8278 \t Train RMSE: 0.9098\n",
      "Train Epoch: 295 [19248/22032] \t Train Loss(MSE): 20.5219 \t Train RMSE: 4.5301\n",
      "[Epoch: 295 \t Valid MSE: 14.8749 \t Valid RMSE: 3.8568]\n",
      "[Epoch: 295 \t Train MSE: 1.5180 \t Train RMSE: 1.2321]\n",
      "EarlyStopping counter: 8 out of 40\n",
      "Train Epoch: 296 [48/22032] \t Train Loss(MSE): 4.3307 \t Train RMSE: 2.0810\n",
      "Train Epoch: 296 [9648/22032] \t Train Loss(MSE): 0.2931 \t Train RMSE: 0.5414\n",
      "Train Epoch: 296 [19248/22032] \t Train Loss(MSE): 0.7622 \t Train RMSE: 0.8730\n",
      "[Epoch: 296 \t Valid MSE: 15.2751 \t Valid RMSE: 3.9083]\n",
      "[Epoch: 296 \t Train MSE: 1.5474 \t Train RMSE: 1.2439]\n",
      "EarlyStopping counter: 9 out of 40\n",
      "Train Epoch: 297 [48/22032] \t Train Loss(MSE): 4.8478 \t Train RMSE: 2.2018\n",
      "Train Epoch: 297 [9648/22032] \t Train Loss(MSE): 0.4795 \t Train RMSE: 0.6925\n",
      "Train Epoch: 297 [19248/22032] \t Train Loss(MSE): 0.3919 \t Train RMSE: 0.6260\n",
      "[Epoch: 297 \t Valid MSE: 14.9928 \t Valid RMSE: 3.8721]\n",
      "[Epoch: 297 \t Train MSE: 1.3770 \t Train RMSE: 1.1734]\n",
      "EarlyStopping counter: 10 out of 40\n",
      "Train Epoch: 298 [48/22032] \t Train Loss(MSE): 1.0542 \t Train RMSE: 1.0267\n",
      "Train Epoch: 298 [9648/22032] \t Train Loss(MSE): 0.6340 \t Train RMSE: 0.7962\n",
      "Train Epoch: 298 [19248/22032] \t Train Loss(MSE): 0.3135 \t Train RMSE: 0.5599\n",
      "[Epoch: 298 \t Valid MSE: 15.1380 \t Valid RMSE: 3.8908]\n",
      "[Epoch: 298 \t Train MSE: 1.3477 \t Train RMSE: 1.1609]\n",
      "Validation loss decreased (1.375556 --> 1.347750).  Saving model ...\n",
      "Train Epoch: 299 [48/22032] \t Train Loss(MSE): 0.3160 \t Train RMSE: 0.5622\n",
      "Train Epoch: 299 [9648/22032] \t Train Loss(MSE): 0.5395 \t Train RMSE: 0.7345\n",
      "Train Epoch: 299 [19248/22032] \t Train Loss(MSE): 0.3515 \t Train RMSE: 0.5929\n",
      "[Epoch: 299 \t Valid MSE: 15.0232 \t Valid RMSE: 3.8760]\n",
      "[Epoch: 299 \t Train MSE: 1.3791 \t Train RMSE: 1.1744]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 300 [48/22032] \t Train Loss(MSE): 5.3401 \t Train RMSE: 2.3109\n",
      "Train Epoch: 300 [9648/22032] \t Train Loss(MSE): 0.6448 \t Train RMSE: 0.8030\n",
      "Train Epoch: 300 [19248/22032] \t Train Loss(MSE): 0.5608 \t Train RMSE: 0.7489\n",
      "[Epoch: 300 \t Valid MSE: 15.0907 \t Valid RMSE: 3.8847]\n",
      "[Epoch: 300 \t Train MSE: 1.4739 \t Train RMSE: 1.2141]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 301 [48/22032] \t Train Loss(MSE): 0.4565 \t Train RMSE: 0.6756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 301 [9648/22032] \t Train Loss(MSE): 0.8122 \t Train RMSE: 0.9012\n",
      "Train Epoch: 301 [19248/22032] \t Train Loss(MSE): 4.0596 \t Train RMSE: 2.0148\n",
      "[Epoch: 301 \t Valid MSE: 15.0735 \t Valid RMSE: 3.8825]\n",
      "[Epoch: 301 \t Train MSE: 1.4833 \t Train RMSE: 1.2179]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 302 [48/22032] \t Train Loss(MSE): 0.2148 \t Train RMSE: 0.4635\n",
      "Train Epoch: 302 [9648/22032] \t Train Loss(MSE): 0.4811 \t Train RMSE: 0.6936\n",
      "Train Epoch: 302 [19248/22032] \t Train Loss(MSE): 0.4763 \t Train RMSE: 0.6901\n",
      "[Epoch: 302 \t Valid MSE: 15.0970 \t Valid RMSE: 3.8855]\n",
      "[Epoch: 302 \t Train MSE: 1.4402 \t Train RMSE: 1.2001]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 303 [48/22032] \t Train Loss(MSE): 0.2139 \t Train RMSE: 0.4625\n",
      "Train Epoch: 303 [9648/22032] \t Train Loss(MSE): 0.3242 \t Train RMSE: 0.5694\n",
      "Train Epoch: 303 [19248/22032] \t Train Loss(MSE): 0.8875 \t Train RMSE: 0.9421\n",
      "[Epoch: 303 \t Valid MSE: 14.9950 \t Valid RMSE: 3.8723]\n",
      "[Epoch: 303 \t Train MSE: 1.5902 \t Train RMSE: 1.2610]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 304 [48/22032] \t Train Loss(MSE): 0.3594 \t Train RMSE: 0.5995\n",
      "Train Epoch: 304 [9648/22032] \t Train Loss(MSE): 0.3540 \t Train RMSE: 0.5949\n",
      "Train Epoch: 304 [19248/22032] \t Train Loss(MSE): 0.3176 \t Train RMSE: 0.5636\n",
      "[Epoch: 304 \t Valid MSE: 14.7199 \t Valid RMSE: 3.8367]\n",
      "[Epoch: 304 \t Train MSE: 1.4336 \t Train RMSE: 1.1973]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 305 [48/22032] \t Train Loss(MSE): 0.4070 \t Train RMSE: 0.6379\n",
      "Train Epoch: 305 [9648/22032] \t Train Loss(MSE): 0.6360 \t Train RMSE: 0.7975\n",
      "Train Epoch: 305 [19248/22032] \t Train Loss(MSE): 0.3458 \t Train RMSE: 0.5880\n",
      "[Epoch: 305 \t Valid MSE: 14.8991 \t Valid RMSE: 3.8599]\n",
      "[Epoch: 305 \t Train MSE: 1.4435 \t Train RMSE: 1.2014]\n",
      "EarlyStopping counter: 7 out of 40\n",
      "Train Epoch: 306 [48/22032] \t Train Loss(MSE): 0.3535 \t Train RMSE: 0.5946\n",
      "Train Epoch: 306 [9648/22032] \t Train Loss(MSE): 1.2627 \t Train RMSE: 1.1237\n",
      "Train Epoch: 306 [19248/22032] \t Train Loss(MSE): 6.6429 \t Train RMSE: 2.5774\n",
      "[Epoch: 306 \t Valid MSE: 14.8819 \t Valid RMSE: 3.8577]\n",
      "[Epoch: 306 \t Train MSE: 1.3766 \t Train RMSE: 1.1733]\n",
      "EarlyStopping counter: 8 out of 40\n",
      "Train Epoch: 307 [48/22032] \t Train Loss(MSE): 0.3503 \t Train RMSE: 0.5918\n",
      "Train Epoch: 307 [9648/22032] \t Train Loss(MSE): 0.4610 \t Train RMSE: 0.6790\n",
      "Train Epoch: 307 [19248/22032] \t Train Loss(MSE): 0.2557 \t Train RMSE: 0.5057\n",
      "[Epoch: 307 \t Valid MSE: 14.8698 \t Valid RMSE: 3.8561]\n",
      "[Epoch: 307 \t Train MSE: 1.3193 \t Train RMSE: 1.1486]\n",
      "Validation loss decreased (1.347750 --> 1.319299).  Saving model ...\n",
      "Train Epoch: 308 [48/22032] \t Train Loss(MSE): 1.8765 \t Train RMSE: 1.3699\n",
      "Train Epoch: 308 [9648/22032] \t Train Loss(MSE): 0.4204 \t Train RMSE: 0.6484\n",
      "Train Epoch: 308 [19248/22032] \t Train Loss(MSE): 0.3225 \t Train RMSE: 0.5679\n",
      "[Epoch: 308 \t Valid MSE: 15.1560 \t Valid RMSE: 3.8931]\n",
      "[Epoch: 308 \t Train MSE: 1.3540 \t Train RMSE: 1.1636]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 309 [48/22032] \t Train Loss(MSE): 0.2123 \t Train RMSE: 0.4608\n",
      "Train Epoch: 309 [9648/22032] \t Train Loss(MSE): 0.5697 \t Train RMSE: 0.7548\n",
      "Train Epoch: 309 [19248/22032] \t Train Loss(MSE): 0.3761 \t Train RMSE: 0.6133\n",
      "[Epoch: 309 \t Valid MSE: 15.0913 \t Valid RMSE: 3.8848]\n",
      "[Epoch: 309 \t Train MSE: 1.4093 \t Train RMSE: 1.1871]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 310 [48/22032] \t Train Loss(MSE): 0.2947 \t Train RMSE: 0.5428\n",
      "Train Epoch: 310 [9648/22032] \t Train Loss(MSE): 0.5453 \t Train RMSE: 0.7385\n",
      "Train Epoch: 310 [19248/22032] \t Train Loss(MSE): 1.7234 \t Train RMSE: 1.3128\n",
      "[Epoch: 310 \t Valid MSE: 15.3682 \t Valid RMSE: 3.9202]\n",
      "[Epoch: 310 \t Train MSE: 1.4113 \t Train RMSE: 1.1880]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 311 [48/22032] \t Train Loss(MSE): 12.3983 \t Train RMSE: 3.5211\n",
      "Train Epoch: 311 [9648/22032] \t Train Loss(MSE): 0.6489 \t Train RMSE: 0.8055\n",
      "Train Epoch: 311 [19248/22032] \t Train Loss(MSE): 0.4979 \t Train RMSE: 0.7056\n",
      "[Epoch: 311 \t Valid MSE: 15.0572 \t Valid RMSE: 3.8804]\n",
      "[Epoch: 311 \t Train MSE: 1.3697 \t Train RMSE: 1.1703]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 312 [48/22032] \t Train Loss(MSE): 0.1724 \t Train RMSE: 0.4152\n",
      "Train Epoch: 312 [9648/22032] \t Train Loss(MSE): 0.3284 \t Train RMSE: 0.5730\n",
      "Train Epoch: 312 [19248/22032] \t Train Loss(MSE): 0.6666 \t Train RMSE: 0.8165\n",
      "[Epoch: 312 \t Valid MSE: 15.1551 \t Valid RMSE: 3.8930]\n",
      "[Epoch: 312 \t Train MSE: 1.3714 \t Train RMSE: 1.1711]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 313 [48/22032] \t Train Loss(MSE): 0.3811 \t Train RMSE: 0.6173\n",
      "Train Epoch: 313 [9648/22032] \t Train Loss(MSE): 0.4608 \t Train RMSE: 0.6789\n",
      "Train Epoch: 313 [19248/22032] \t Train Loss(MSE): 0.2984 \t Train RMSE: 0.5462\n",
      "[Epoch: 313 \t Valid MSE: 15.2143 \t Valid RMSE: 3.9005]\n",
      "[Epoch: 313 \t Train MSE: 1.3680 \t Train RMSE: 1.1696]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 314 [48/22032] \t Train Loss(MSE): 0.3619 \t Train RMSE: 0.6016\n",
      "Train Epoch: 314 [9648/22032] \t Train Loss(MSE): 0.3463 \t Train RMSE: 0.5884\n",
      "Train Epoch: 314 [19248/22032] \t Train Loss(MSE): 0.2375 \t Train RMSE: 0.4873\n",
      "[Epoch: 314 \t Valid MSE: 15.0647 \t Valid RMSE: 3.8813]\n",
      "[Epoch: 314 \t Train MSE: 1.3595 \t Train RMSE: 1.1660]\n",
      "EarlyStopping counter: 7 out of 40\n",
      "Train Epoch: 315 [48/22032] \t Train Loss(MSE): 0.3259 \t Train RMSE: 0.5709\n",
      "Train Epoch: 315 [9648/22032] \t Train Loss(MSE): 0.3825 \t Train RMSE: 0.6184\n",
      "Train Epoch: 315 [19248/22032] \t Train Loss(MSE): 1.0574 \t Train RMSE: 1.0283\n",
      "[Epoch: 315 \t Valid MSE: 15.2378 \t Valid RMSE: 3.9036]\n",
      "[Epoch: 315 \t Train MSE: 1.3290 \t Train RMSE: 1.1528]\n",
      "EarlyStopping counter: 8 out of 40\n",
      "Train Epoch: 316 [48/22032] \t Train Loss(MSE): 0.4909 \t Train RMSE: 0.7007\n",
      "Train Epoch: 316 [9648/22032] \t Train Loss(MSE): 2.5248 \t Train RMSE: 1.5890\n",
      "Train Epoch: 316 [19248/22032] \t Train Loss(MSE): 0.5008 \t Train RMSE: 0.7077\n",
      "[Epoch: 316 \t Valid MSE: 15.1138 \t Valid RMSE: 3.8876]\n",
      "[Epoch: 316 \t Train MSE: 1.4511 \t Train RMSE: 1.2046]\n",
      "EarlyStopping counter: 9 out of 40\n",
      "Train Epoch: 317 [48/22032] \t Train Loss(MSE): 0.7112 \t Train RMSE: 0.8434\n",
      "Train Epoch: 317 [9648/22032] \t Train Loss(MSE): 0.5467 \t Train RMSE: 0.7394\n",
      "Train Epoch: 317 [19248/22032] \t Train Loss(MSE): 0.2682 \t Train RMSE: 0.5178\n",
      "[Epoch: 317 \t Valid MSE: 15.1830 \t Valid RMSE: 3.8965]\n",
      "[Epoch: 317 \t Train MSE: 1.5084 \t Train RMSE: 1.2282]\n",
      "EarlyStopping counter: 10 out of 40\n",
      "Train Epoch: 318 [48/22032] \t Train Loss(MSE): 0.6050 \t Train RMSE: 0.7778\n",
      "Train Epoch: 318 [9648/22032] \t Train Loss(MSE): 0.8362 \t Train RMSE: 0.9144\n",
      "Train Epoch: 318 [19248/22032] \t Train Loss(MSE): 0.3988 \t Train RMSE: 0.6315\n",
      "[Epoch: 318 \t Valid MSE: 14.8228 \t Valid RMSE: 3.8500]\n",
      "[Epoch: 318 \t Train MSE: 1.5007 \t Train RMSE: 1.2251]\n",
      "Epoch   318: reducing learning rate of group 0 to 1.2500e-03.\n",
      "EarlyStopping counter: 11 out of 40\n",
      "Train Epoch: 319 [48/22032] \t Train Loss(MSE): 0.2136 \t Train RMSE: 0.4622\n",
      "Train Epoch: 319 [9648/22032] \t Train Loss(MSE): 2.8828 \t Train RMSE: 1.6979\n",
      "Train Epoch: 319 [19248/22032] \t Train Loss(MSE): 0.2860 \t Train RMSE: 0.5348\n",
      "[Epoch: 319 \t Valid MSE: 14.7882 \t Valid RMSE: 3.8455]\n",
      "[Epoch: 319 \t Train MSE: 1.2946 \t Train RMSE: 1.1378]\n",
      "Validation loss decreased (1.319299 --> 1.294603).  Saving model ...\n",
      "Train Epoch: 320 [48/22032] \t Train Loss(MSE): 0.1571 \t Train RMSE: 0.3964\n",
      "Train Epoch: 320 [9648/22032] \t Train Loss(MSE): 0.2575 \t Train RMSE: 0.5074\n",
      "Train Epoch: 320 [19248/22032] \t Train Loss(MSE): 0.3402 \t Train RMSE: 0.5833\n",
      "[Epoch: 320 \t Valid MSE: 14.8296 \t Valid RMSE: 3.8509]\n",
      "[Epoch: 320 \t Train MSE: 1.2178 \t Train RMSE: 1.1035]\n",
      "Validation loss decreased (1.294603 --> 1.217752).  Saving model ...\n",
      "Train Epoch: 321 [48/22032] \t Train Loss(MSE): 0.0724 \t Train RMSE: 0.2690\n",
      "Train Epoch: 321 [9648/22032] \t Train Loss(MSE): 0.1918 \t Train RMSE: 0.4380\n",
      "Train Epoch: 321 [19248/22032] \t Train Loss(MSE): 1.7046 \t Train RMSE: 1.3056\n",
      "[Epoch: 321 \t Valid MSE: 14.8379 \t Valid RMSE: 3.8520]\n",
      "[Epoch: 321 \t Train MSE: 1.2003 \t Train RMSE: 1.0956]\n",
      "Validation loss decreased (1.217752 --> 1.200331).  Saving model ...\n",
      "Train Epoch: 322 [48/22032] \t Train Loss(MSE): 0.2543 \t Train RMSE: 0.5043\n",
      "Train Epoch: 322 [9648/22032] \t Train Loss(MSE): 0.2703 \t Train RMSE: 0.5199\n",
      "Train Epoch: 322 [19248/22032] \t Train Loss(MSE): 0.5950 \t Train RMSE: 0.7713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 322 \t Valid MSE: 14.7866 \t Valid RMSE: 3.8453]\n",
      "[Epoch: 322 \t Train MSE: 1.1939 \t Train RMSE: 1.0926]\n",
      "Validation loss decreased (1.200331 --> 1.193873).  Saving model ...\n",
      "Train Epoch: 323 [48/22032] \t Train Loss(MSE): 0.2277 \t Train RMSE: 0.4772\n",
      "Train Epoch: 323 [9648/22032] \t Train Loss(MSE): 0.3102 \t Train RMSE: 0.5570\n",
      "Train Epoch: 323 [19248/22032] \t Train Loss(MSE): 0.2268 \t Train RMSE: 0.4762\n",
      "[Epoch: 323 \t Valid MSE: 15.4156 \t Valid RMSE: 3.9263]\n",
      "[Epoch: 323 \t Train MSE: 1.1768 \t Train RMSE: 1.0848]\n",
      "Validation loss decreased (1.193873 --> 1.176752).  Saving model ...\n",
      "Train Epoch: 324 [48/22032] \t Train Loss(MSE): 0.5908 \t Train RMSE: 0.7686\n",
      "Train Epoch: 324 [9648/22032] \t Train Loss(MSE): 0.2191 \t Train RMSE: 0.4681\n",
      "Train Epoch: 324 [19248/22032] \t Train Loss(MSE): 0.8778 \t Train RMSE: 0.9369\n",
      "[Epoch: 324 \t Valid MSE: 15.0278 \t Valid RMSE: 3.8766]\n",
      "[Epoch: 324 \t Train MSE: 1.1680 \t Train RMSE: 1.0807]\n",
      "Validation loss decreased (1.176752 --> 1.167966).  Saving model ...\n",
      "Train Epoch: 325 [48/22032] \t Train Loss(MSE): 0.3108 \t Train RMSE: 0.5575\n",
      "Train Epoch: 325 [9648/22032] \t Train Loss(MSE): 0.1616 \t Train RMSE: 0.4019\n",
      "Train Epoch: 325 [19248/22032] \t Train Loss(MSE): 0.3974 \t Train RMSE: 0.6304\n",
      "[Epoch: 325 \t Valid MSE: 14.9313 \t Valid RMSE: 3.8641]\n",
      "[Epoch: 325 \t Train MSE: 1.1688 \t Train RMSE: 1.0811]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 326 [48/22032] \t Train Loss(MSE): 2.8158 \t Train RMSE: 1.6780\n",
      "Train Epoch: 326 [9648/22032] \t Train Loss(MSE): 0.2964 \t Train RMSE: 0.5445\n",
      "Train Epoch: 326 [19248/22032] \t Train Loss(MSE): 0.5255 \t Train RMSE: 0.7249\n",
      "[Epoch: 326 \t Valid MSE: 15.2188 \t Valid RMSE: 3.9011]\n",
      "[Epoch: 326 \t Train MSE: 1.1730 \t Train RMSE: 1.0831]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 327 [48/22032] \t Train Loss(MSE): 0.1995 \t Train RMSE: 0.4467\n",
      "Train Epoch: 327 [9648/22032] \t Train Loss(MSE): 0.1552 \t Train RMSE: 0.3939\n",
      "Train Epoch: 327 [19248/22032] \t Train Loss(MSE): 2.4465 \t Train RMSE: 1.5641\n",
      "[Epoch: 327 \t Valid MSE: 15.1200 \t Valid RMSE: 3.8884]\n",
      "[Epoch: 327 \t Train MSE: 1.1707 \t Train RMSE: 1.0820]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 328 [48/22032] \t Train Loss(MSE): 0.1577 \t Train RMSE: 0.3971\n",
      "Train Epoch: 328 [9648/22032] \t Train Loss(MSE): 0.2404 \t Train RMSE: 0.4903\n",
      "Train Epoch: 328 [19248/22032] \t Train Loss(MSE): 0.1673 \t Train RMSE: 0.4090\n",
      "[Epoch: 328 \t Valid MSE: 15.1004 \t Valid RMSE: 3.8859]\n",
      "[Epoch: 328 \t Train MSE: 1.1655 \t Train RMSE: 1.0796]\n",
      "Validation loss decreased (1.167966 --> 1.165531).  Saving model ...\n",
      "Train Epoch: 329 [48/22032] \t Train Loss(MSE): 0.2250 \t Train RMSE: 0.4743\n",
      "Train Epoch: 329 [9648/22032] \t Train Loss(MSE): 0.2161 \t Train RMSE: 0.4649\n",
      "Train Epoch: 329 [19248/22032] \t Train Loss(MSE): 3.4189 \t Train RMSE: 1.8490\n",
      "[Epoch: 329 \t Valid MSE: 15.1910 \t Valid RMSE: 3.8976]\n",
      "[Epoch: 329 \t Train MSE: 1.1690 \t Train RMSE: 1.0812]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 330 [48/22032] \t Train Loss(MSE): 5.5563 \t Train RMSE: 2.3572\n",
      "Train Epoch: 330 [9648/22032] \t Train Loss(MSE): 2.9175 \t Train RMSE: 1.7081\n",
      "Train Epoch: 330 [19248/22032] \t Train Loss(MSE): 0.3925 \t Train RMSE: 0.6265\n",
      "[Epoch: 330 \t Valid MSE: 15.0792 \t Valid RMSE: 3.8832]\n",
      "[Epoch: 330 \t Train MSE: 1.1621 \t Train RMSE: 1.0780]\n",
      "Validation loss decreased (1.165531 --> 1.162067).  Saving model ...\n",
      "Train Epoch: 331 [48/22032] \t Train Loss(MSE): 0.1580 \t Train RMSE: 0.3975\n",
      "Train Epoch: 331 [9648/22032] \t Train Loss(MSE): 2.7512 \t Train RMSE: 1.6587\n",
      "Train Epoch: 331 [19248/22032] \t Train Loss(MSE): 0.1805 \t Train RMSE: 0.4248\n",
      "[Epoch: 331 \t Valid MSE: 15.0209 \t Valid RMSE: 3.8757]\n",
      "[Epoch: 331 \t Train MSE: 1.1593 \t Train RMSE: 1.0767]\n",
      "Validation loss decreased (1.162067 --> 1.159324).  Saving model ...\n",
      "Train Epoch: 332 [48/22032] \t Train Loss(MSE): 0.1486 \t Train RMSE: 0.3855\n",
      "Train Epoch: 332 [9648/22032] \t Train Loss(MSE): 0.2236 \t Train RMSE: 0.4728\n",
      "Train Epoch: 332 [19248/22032] \t Train Loss(MSE): 1.6441 \t Train RMSE: 1.2822\n",
      "[Epoch: 332 \t Valid MSE: 15.0994 \t Valid RMSE: 3.8858]\n",
      "[Epoch: 332 \t Train MSE: 1.1668 \t Train RMSE: 1.0802]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 333 [48/22032] \t Train Loss(MSE): 1.6968 \t Train RMSE: 1.3026\n",
      "Train Epoch: 333 [9648/22032] \t Train Loss(MSE): 0.1615 \t Train RMSE: 0.4019\n",
      "Train Epoch: 333 [19248/22032] \t Train Loss(MSE): 0.1627 \t Train RMSE: 0.4034\n",
      "[Epoch: 333 \t Valid MSE: 15.0348 \t Valid RMSE: 3.8775]\n",
      "[Epoch: 333 \t Train MSE: 1.1531 \t Train RMSE: 1.0738]\n",
      "Validation loss decreased (1.159324 --> 1.153134).  Saving model ...\n",
      "Train Epoch: 334 [48/22032] \t Train Loss(MSE): 0.3782 \t Train RMSE: 0.6150\n",
      "Train Epoch: 334 [9648/22032] \t Train Loss(MSE): 0.1498 \t Train RMSE: 0.3871\n",
      "Train Epoch: 334 [19248/22032] \t Train Loss(MSE): 14.6048 \t Train RMSE: 3.8216\n",
      "[Epoch: 334 \t Valid MSE: 15.1119 \t Valid RMSE: 3.8874]\n",
      "[Epoch: 334 \t Train MSE: 1.1501 \t Train RMSE: 1.0724]\n",
      "Validation loss decreased (1.153134 --> 1.150132).  Saving model ...\n",
      "Train Epoch: 335 [48/22032] \t Train Loss(MSE): 4.1007 \t Train RMSE: 2.0250\n",
      "Train Epoch: 335 [9648/22032] \t Train Loss(MSE): 0.2343 \t Train RMSE: 0.4841\n",
      "Train Epoch: 335 [19248/22032] \t Train Loss(MSE): 0.9140 \t Train RMSE: 0.9560\n",
      "[Epoch: 335 \t Valid MSE: 16.4407 \t Valid RMSE: 4.0547]\n",
      "[Epoch: 335 \t Train MSE: 1.1508 \t Train RMSE: 1.0727]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 336 [48/22032] \t Train Loss(MSE): 1.0015 \t Train RMSE: 1.0008\n",
      "Train Epoch: 336 [9648/22032] \t Train Loss(MSE): 0.1702 \t Train RMSE: 0.4126\n",
      "Train Epoch: 336 [19248/22032] \t Train Loss(MSE): 8.8446 \t Train RMSE: 2.9740\n",
      "[Epoch: 336 \t Valid MSE: 15.1325 \t Valid RMSE: 3.8901]\n",
      "[Epoch: 336 \t Train MSE: 1.1462 \t Train RMSE: 1.0706]\n",
      "Validation loss decreased (1.150132 --> 1.146223).  Saving model ...\n",
      "Train Epoch: 337 [48/22032] \t Train Loss(MSE): 1.9597 \t Train RMSE: 1.3999\n",
      "Train Epoch: 337 [9648/22032] \t Train Loss(MSE): 0.1574 \t Train RMSE: 0.3967\n",
      "Train Epoch: 337 [19248/22032] \t Train Loss(MSE): 0.2120 \t Train RMSE: 0.4604\n",
      "[Epoch: 337 \t Valid MSE: 15.1744 \t Valid RMSE: 3.8954]\n",
      "[Epoch: 337 \t Train MSE: 1.1440 \t Train RMSE: 1.0696]\n",
      "Validation loss decreased (1.146223 --> 1.143952).  Saving model ...\n",
      "Train Epoch: 338 [48/22032] \t Train Loss(MSE): 0.1670 \t Train RMSE: 0.4087\n",
      "Train Epoch: 338 [9648/22032] \t Train Loss(MSE): 0.1520 \t Train RMSE: 0.3898\n",
      "Train Epoch: 338 [19248/22032] \t Train Loss(MSE): 3.7158 \t Train RMSE: 1.9276\n",
      "[Epoch: 338 \t Valid MSE: 15.5754 \t Valid RMSE: 3.9466]\n",
      "[Epoch: 338 \t Train MSE: 1.1444 \t Train RMSE: 1.0698]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 339 [48/22032] \t Train Loss(MSE): 0.2226 \t Train RMSE: 0.4718\n",
      "Train Epoch: 339 [9648/22032] \t Train Loss(MSE): 1.8000 \t Train RMSE: 1.3416\n",
      "Train Epoch: 339 [19248/22032] \t Train Loss(MSE): 0.3906 \t Train RMSE: 0.6250\n",
      "[Epoch: 339 \t Valid MSE: 15.0084 \t Valid RMSE: 3.8741]\n",
      "[Epoch: 339 \t Train MSE: 1.1360 \t Train RMSE: 1.0658]\n",
      "Validation loss decreased (1.143952 --> 1.136023).  Saving model ...\n",
      "Train Epoch: 340 [48/22032] \t Train Loss(MSE): 2.8068 \t Train RMSE: 1.6754\n",
      "Train Epoch: 340 [9648/22032] \t Train Loss(MSE): 0.1275 \t Train RMSE: 0.3571\n",
      "Train Epoch: 340 [19248/22032] \t Train Loss(MSE): 1.6136 \t Train RMSE: 1.2703\n",
      "[Epoch: 340 \t Valid MSE: 15.0146 \t Valid RMSE: 3.8749]\n",
      "[Epoch: 340 \t Train MSE: 1.1481 \t Train RMSE: 1.0715]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 341 [48/22032] \t Train Loss(MSE): 0.3633 \t Train RMSE: 0.6027\n",
      "Train Epoch: 341 [9648/22032] \t Train Loss(MSE): 0.9007 \t Train RMSE: 0.9490\n",
      "Train Epoch: 341 [19248/22032] \t Train Loss(MSE): 0.2570 \t Train RMSE: 0.5069\n",
      "[Epoch: 341 \t Valid MSE: 15.1446 \t Valid RMSE: 3.8916]\n",
      "[Epoch: 341 \t Train MSE: 1.1430 \t Train RMSE: 1.0691]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 342 [48/22032] \t Train Loss(MSE): 0.2468 \t Train RMSE: 0.4968\n",
      "Train Epoch: 342 [9648/22032] \t Train Loss(MSE): 0.3459 \t Train RMSE: 0.5881\n",
      "Train Epoch: 342 [19248/22032] \t Train Loss(MSE): 2.8574 \t Train RMSE: 1.6904\n",
      "[Epoch: 342 \t Valid MSE: 15.1168 \t Valid RMSE: 3.8880]\n",
      "[Epoch: 342 \t Train MSE: 1.1385 \t Train RMSE: 1.0670]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 343 [48/22032] \t Train Loss(MSE): 2.5629 \t Train RMSE: 1.6009\n",
      "Train Epoch: 343 [9648/22032] \t Train Loss(MSE): 0.2463 \t Train RMSE: 0.4963\n",
      "Train Epoch: 343 [19248/22032] \t Train Loss(MSE): 0.2148 \t Train RMSE: 0.4634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 343 \t Valid MSE: 15.1702 \t Valid RMSE: 3.8949]\n",
      "[Epoch: 343 \t Train MSE: 1.1339 \t Train RMSE: 1.0648]\n",
      "Validation loss decreased (1.136023 --> 1.133872).  Saving model ...\n",
      "Train Epoch: 344 [48/22032] \t Train Loss(MSE): 0.6998 \t Train RMSE: 0.8366\n",
      "Train Epoch: 344 [9648/22032] \t Train Loss(MSE): 0.4538 \t Train RMSE: 0.6736\n",
      "Train Epoch: 344 [19248/22032] \t Train Loss(MSE): 0.2089 \t Train RMSE: 0.4570\n",
      "[Epoch: 344 \t Valid MSE: 15.2678 \t Valid RMSE: 3.9074]\n",
      "[Epoch: 344 \t Train MSE: 1.1341 \t Train RMSE: 1.0649]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 345 [48/22032] \t Train Loss(MSE): 0.2939 \t Train RMSE: 0.5422\n",
      "Train Epoch: 345 [9648/22032] \t Train Loss(MSE): 0.9448 \t Train RMSE: 0.9720\n",
      "Train Epoch: 345 [19248/22032] \t Train Loss(MSE): 2.9818 \t Train RMSE: 1.7268\n",
      "[Epoch: 345 \t Valid MSE: 15.2766 \t Valid RMSE: 3.9085]\n",
      "[Epoch: 345 \t Train MSE: 1.1281 \t Train RMSE: 1.0621]\n",
      "Validation loss decreased (1.133872 --> 1.128084).  Saving model ...\n",
      "Train Epoch: 346 [48/22032] \t Train Loss(MSE): 0.1749 \t Train RMSE: 0.4182\n",
      "Train Epoch: 346 [9648/22032] \t Train Loss(MSE): 3.5964 \t Train RMSE: 1.8964\n",
      "Train Epoch: 346 [19248/22032] \t Train Loss(MSE): 0.1996 \t Train RMSE: 0.4467\n",
      "[Epoch: 346 \t Valid MSE: 15.6717 \t Valid RMSE: 3.9588]\n",
      "[Epoch: 346 \t Train MSE: 1.1317 \t Train RMSE: 1.0638]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 347 [48/22032] \t Train Loss(MSE): 0.5335 \t Train RMSE: 0.7304\n",
      "Train Epoch: 347 [9648/22032] \t Train Loss(MSE): 1.4434 \t Train RMSE: 1.2014\n",
      "Train Epoch: 347 [19248/22032] \t Train Loss(MSE): 2.1785 \t Train RMSE: 1.4760\n",
      "[Epoch: 347 \t Valid MSE: 15.2594 \t Valid RMSE: 3.9063]\n",
      "[Epoch: 347 \t Train MSE: 1.1225 \t Train RMSE: 1.0595]\n",
      "Validation loss decreased (1.128084 --> 1.122509).  Saving model ...\n",
      "Train Epoch: 348 [48/22032] \t Train Loss(MSE): 3.1305 \t Train RMSE: 1.7693\n",
      "Train Epoch: 348 [9648/22032] \t Train Loss(MSE): 0.3312 \t Train RMSE: 0.5755\n",
      "Train Epoch: 348 [19248/22032] \t Train Loss(MSE): 0.1640 \t Train RMSE: 0.4049\n",
      "[Epoch: 348 \t Valid MSE: 17.3175 \t Valid RMSE: 4.1614]\n",
      "[Epoch: 348 \t Train MSE: 1.1320 \t Train RMSE: 1.0640]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 349 [48/22032] \t Train Loss(MSE): 0.6935 \t Train RMSE: 0.8328\n",
      "Train Epoch: 349 [9648/22032] \t Train Loss(MSE): 0.1778 \t Train RMSE: 0.4216\n",
      "Train Epoch: 349 [19248/22032] \t Train Loss(MSE): 0.3205 \t Train RMSE: 0.5661\n",
      "[Epoch: 349 \t Valid MSE: 15.1718 \t Valid RMSE: 3.8951]\n",
      "[Epoch: 349 \t Train MSE: 1.1355 \t Train RMSE: 1.0656]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 350 [48/22032] \t Train Loss(MSE): 0.2901 \t Train RMSE: 0.5386\n",
      "Train Epoch: 350 [9648/22032] \t Train Loss(MSE): 0.2050 \t Train RMSE: 0.4527\n",
      "Train Epoch: 350 [19248/22032] \t Train Loss(MSE): 0.2103 \t Train RMSE: 0.4586\n",
      "[Epoch: 350 \t Valid MSE: 15.4222 \t Valid RMSE: 3.9271]\n",
      "[Epoch: 350 \t Train MSE: 1.1248 \t Train RMSE: 1.0606]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 351 [48/22032] \t Train Loss(MSE): 0.1347 \t Train RMSE: 0.3670\n",
      "Train Epoch: 351 [9648/22032] \t Train Loss(MSE): 0.2833 \t Train RMSE: 0.5322\n",
      "Train Epoch: 351 [19248/22032] \t Train Loss(MSE): 0.3151 \t Train RMSE: 0.5613\n",
      "[Epoch: 351 \t Valid MSE: 15.5008 \t Valid RMSE: 3.9371]\n",
      "[Epoch: 351 \t Train MSE: 1.1169 \t Train RMSE: 1.0569]\n",
      "Validation loss decreased (1.122509 --> 1.116948).  Saving model ...\n",
      "Train Epoch: 352 [48/22032] \t Train Loss(MSE): 0.1856 \t Train RMSE: 0.4308\n",
      "Train Epoch: 352 [9648/22032] \t Train Loss(MSE): 0.1763 \t Train RMSE: 0.4199\n",
      "Train Epoch: 352 [19248/22032] \t Train Loss(MSE): 0.3061 \t Train RMSE: 0.5533\n",
      "[Epoch: 352 \t Valid MSE: 15.3512 \t Valid RMSE: 3.9181]\n",
      "[Epoch: 352 \t Train MSE: 1.1279 \t Train RMSE: 1.0620]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 353 [48/22032] \t Train Loss(MSE): 0.2073 \t Train RMSE: 0.4553\n",
      "Train Epoch: 353 [9648/22032] \t Train Loss(MSE): 0.1164 \t Train RMSE: 0.3412\n",
      "Train Epoch: 353 [19248/22032] \t Train Loss(MSE): 0.0861 \t Train RMSE: 0.2934\n",
      "[Epoch: 353 \t Valid MSE: 15.1967 \t Valid RMSE: 3.8983]\n",
      "[Epoch: 353 \t Train MSE: 1.1154 \t Train RMSE: 1.0561]\n",
      "Validation loss decreased (1.116948 --> 1.115358).  Saving model ...\n",
      "Train Epoch: 354 [48/22032] \t Train Loss(MSE): 15.6352 \t Train RMSE: 3.9541\n",
      "Train Epoch: 354 [9648/22032] \t Train Loss(MSE): 0.3134 \t Train RMSE: 0.5598\n",
      "Train Epoch: 354 [19248/22032] \t Train Loss(MSE): 11.7480 \t Train RMSE: 3.4275\n",
      "[Epoch: 354 \t Valid MSE: 15.3149 \t Valid RMSE: 3.9134]\n",
      "[Epoch: 354 \t Train MSE: 1.1098 \t Train RMSE: 1.0535]\n",
      "Validation loss decreased (1.115358 --> 1.109771).  Saving model ...\n",
      "Train Epoch: 355 [48/22032] \t Train Loss(MSE): 0.1862 \t Train RMSE: 0.4315\n",
      "Train Epoch: 355 [9648/22032] \t Train Loss(MSE): 3.5207 \t Train RMSE: 1.8763\n",
      "Train Epoch: 355 [19248/22032] \t Train Loss(MSE): 0.1294 \t Train RMSE: 0.3597\n",
      "[Epoch: 355 \t Valid MSE: 15.2495 \t Valid RMSE: 3.9051]\n",
      "[Epoch: 355 \t Train MSE: 1.1162 \t Train RMSE: 1.0565]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 356 [48/22032] \t Train Loss(MSE): 0.2183 \t Train RMSE: 0.4672\n",
      "Train Epoch: 356 [9648/22032] \t Train Loss(MSE): 1.2796 \t Train RMSE: 1.1312\n",
      "Train Epoch: 356 [19248/22032] \t Train Loss(MSE): 0.5843 \t Train RMSE: 0.7644\n",
      "[Epoch: 356 \t Valid MSE: 15.2425 \t Valid RMSE: 3.9042]\n",
      "[Epoch: 356 \t Train MSE: 1.1162 \t Train RMSE: 1.0565]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 357 [48/22032] \t Train Loss(MSE): 0.8726 \t Train RMSE: 0.9341\n",
      "Train Epoch: 357 [9648/22032] \t Train Loss(MSE): 0.1213 \t Train RMSE: 0.3482\n",
      "Train Epoch: 357 [19248/22032] \t Train Loss(MSE): 0.1527 \t Train RMSE: 0.3907\n",
      "[Epoch: 357 \t Valid MSE: 15.3195 \t Valid RMSE: 3.9140]\n",
      "[Epoch: 357 \t Train MSE: 1.1113 \t Train RMSE: 1.0542]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 358 [48/22032] \t Train Loss(MSE): 0.1592 \t Train RMSE: 0.3990\n",
      "Train Epoch: 358 [9648/22032] \t Train Loss(MSE): 0.1600 \t Train RMSE: 0.4000\n",
      "Train Epoch: 358 [19248/22032] \t Train Loss(MSE): 0.2949 \t Train RMSE: 0.5430\n",
      "[Epoch: 358 \t Valid MSE: 15.1052 \t Valid RMSE: 3.8865]\n",
      "[Epoch: 358 \t Train MSE: 1.1049 \t Train RMSE: 1.0511]\n",
      "Validation loss decreased (1.109771 --> 1.104913).  Saving model ...\n",
      "Train Epoch: 359 [48/22032] \t Train Loss(MSE): 0.6303 \t Train RMSE: 0.7939\n",
      "Train Epoch: 359 [9648/22032] \t Train Loss(MSE): 0.9078 \t Train RMSE: 0.9528\n",
      "Train Epoch: 359 [19248/22032] \t Train Loss(MSE): 0.2646 \t Train RMSE: 0.5144\n",
      "[Epoch: 359 \t Valid MSE: 15.3373 \t Valid RMSE: 3.9163]\n",
      "[Epoch: 359 \t Train MSE: 1.1007 \t Train RMSE: 1.0491]\n",
      "Validation loss decreased (1.104913 --> 1.100694).  Saving model ...\n",
      "Train Epoch: 360 [48/22032] \t Train Loss(MSE): 0.2984 \t Train RMSE: 0.5463\n",
      "Train Epoch: 360 [9648/22032] \t Train Loss(MSE): 0.1174 \t Train RMSE: 0.3426\n",
      "Train Epoch: 360 [19248/22032] \t Train Loss(MSE): 0.1638 \t Train RMSE: 0.4047\n",
      "[Epoch: 360 \t Valid MSE: 15.3445 \t Valid RMSE: 3.9172]\n",
      "[Epoch: 360 \t Train MSE: 1.1046 \t Train RMSE: 1.0510]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 361 [48/22032] \t Train Loss(MSE): 0.2529 \t Train RMSE: 0.5029\n",
      "Train Epoch: 361 [9648/22032] \t Train Loss(MSE): 0.1385 \t Train RMSE: 0.3722\n",
      "Train Epoch: 361 [19248/22032] \t Train Loss(MSE): 2.9855 \t Train RMSE: 1.7279\n",
      "[Epoch: 361 \t Valid MSE: 15.2180 \t Valid RMSE: 3.9010]\n",
      "[Epoch: 361 \t Train MSE: 1.1008 \t Train RMSE: 1.0492]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 362 [48/22032] \t Train Loss(MSE): 0.1332 \t Train RMSE: 0.3649\n",
      "Train Epoch: 362 [9648/22032] \t Train Loss(MSE): 0.1204 \t Train RMSE: 0.3470\n",
      "Train Epoch: 362 [19248/22032] \t Train Loss(MSE): 0.1935 \t Train RMSE: 0.4399\n",
      "[Epoch: 362 \t Valid MSE: 15.3713 \t Valid RMSE: 3.9206]\n",
      "[Epoch: 362 \t Train MSE: 1.1093 \t Train RMSE: 1.0532]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 363 [48/22032] \t Train Loss(MSE): 1.9505 \t Train RMSE: 1.3966\n",
      "Train Epoch: 363 [9648/22032] \t Train Loss(MSE): 0.3595 \t Train RMSE: 0.5996\n",
      "Train Epoch: 363 [19248/22032] \t Train Loss(MSE): 1.9703 \t Train RMSE: 1.4037\n",
      "[Epoch: 363 \t Valid MSE: 15.5236 \t Valid RMSE: 3.9400]\n",
      "[Epoch: 363 \t Train MSE: 1.1483 \t Train RMSE: 1.0716]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 364 [48/22032] \t Train Loss(MSE): 0.4859 \t Train RMSE: 0.6971\n",
      "Train Epoch: 364 [9648/22032] \t Train Loss(MSE): 0.1297 \t Train RMSE: 0.3601\n",
      "Train Epoch: 364 [19248/22032] \t Train Loss(MSE): 0.3692 \t Train RMSE: 0.6076\n",
      "[Epoch: 364 \t Valid MSE: 15.6541 \t Valid RMSE: 3.9565]\n",
      "[Epoch: 364 \t Train MSE: 1.2353 \t Train RMSE: 1.1114]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 365 [48/22032] \t Train Loss(MSE): 0.7421 \t Train RMSE: 0.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 365 [9648/22032] \t Train Loss(MSE): 0.2633 \t Train RMSE: 0.5131\n",
      "Train Epoch: 365 [19248/22032] \t Train Loss(MSE): 0.3150 \t Train RMSE: 0.5612\n",
      "[Epoch: 365 \t Valid MSE: 15.1796 \t Valid RMSE: 3.8961]\n",
      "[Epoch: 365 \t Train MSE: 1.1130 \t Train RMSE: 1.0550]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 366 [48/22032] \t Train Loss(MSE): 1.6289 \t Train RMSE: 1.2763\n",
      "Train Epoch: 366 [9648/22032] \t Train Loss(MSE): 0.2259 \t Train RMSE: 0.4753\n",
      "Train Epoch: 366 [19248/22032] \t Train Loss(MSE): 0.1581 \t Train RMSE: 0.3976\n",
      "[Epoch: 366 \t Valid MSE: 15.2492 \t Valid RMSE: 3.9050]\n",
      "[Epoch: 366 \t Train MSE: 1.0959 \t Train RMSE: 1.0468]\n",
      "Validation loss decreased (1.100694 --> 1.095894).  Saving model ...\n",
      "Train Epoch: 367 [48/22032] \t Train Loss(MSE): 0.9891 \t Train RMSE: 0.9945\n",
      "Train Epoch: 367 [9648/22032] \t Train Loss(MSE): 2.5181 \t Train RMSE: 1.5868\n",
      "Train Epoch: 367 [19248/22032] \t Train Loss(MSE): 1.3423 \t Train RMSE: 1.1586\n",
      "[Epoch: 367 \t Valid MSE: 15.6280 \t Valid RMSE: 3.9532]\n",
      "[Epoch: 367 \t Train MSE: 1.0916 \t Train RMSE: 1.0448]\n",
      "Validation loss decreased (1.095894 --> 1.091621).  Saving model ...\n",
      "Train Epoch: 368 [48/22032] \t Train Loss(MSE): 0.1338 \t Train RMSE: 0.3658\n",
      "Train Epoch: 368 [9648/22032] \t Train Loss(MSE): 0.4360 \t Train RMSE: 0.6603\n",
      "Train Epoch: 368 [19248/22032] \t Train Loss(MSE): 0.2593 \t Train RMSE: 0.5092\n",
      "[Epoch: 368 \t Valid MSE: 15.2350 \t Valid RMSE: 3.9032]\n",
      "[Epoch: 368 \t Train MSE: 1.0884 \t Train RMSE: 1.0433]\n",
      "Validation loss decreased (1.091621 --> 1.088393).  Saving model ...\n",
      "Train Epoch: 369 [48/22032] \t Train Loss(MSE): 0.1174 \t Train RMSE: 0.3426\n",
      "Train Epoch: 369 [9648/22032] \t Train Loss(MSE): 13.0859 \t Train RMSE: 3.6174\n",
      "Train Epoch: 369 [19248/22032] \t Train Loss(MSE): 0.2191 \t Train RMSE: 0.4681\n",
      "[Epoch: 369 \t Valid MSE: 15.2824 \t Valid RMSE: 3.9093]\n",
      "[Epoch: 369 \t Train MSE: 1.0950 \t Train RMSE: 1.0464]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 370 [48/22032] \t Train Loss(MSE): 0.1030 \t Train RMSE: 0.3209\n",
      "Train Epoch: 370 [9648/22032] \t Train Loss(MSE): 0.4030 \t Train RMSE: 0.6348\n",
      "Train Epoch: 370 [19248/22032] \t Train Loss(MSE): 0.2380 \t Train RMSE: 0.4878\n",
      "[Epoch: 370 \t Valid MSE: 15.4035 \t Valid RMSE: 3.9247]\n",
      "[Epoch: 370 \t Train MSE: 1.0875 \t Train RMSE: 1.0428]\n",
      "Validation loss decreased (1.088393 --> 1.087472).  Saving model ...\n",
      "Train Epoch: 371 [48/22032] \t Train Loss(MSE): 0.2089 \t Train RMSE: 0.4571\n",
      "Train Epoch: 371 [9648/22032] \t Train Loss(MSE): 0.3646 \t Train RMSE: 0.6038\n",
      "Train Epoch: 371 [19248/22032] \t Train Loss(MSE): 0.5380 \t Train RMSE: 0.7335\n",
      "[Epoch: 371 \t Valid MSE: 15.3907 \t Valid RMSE: 3.9231]\n",
      "[Epoch: 371 \t Train MSE: 1.0821 \t Train RMSE: 1.0403]\n",
      "Validation loss decreased (1.087472 --> 1.082144).  Saving model ...\n",
      "Train Epoch: 372 [48/22032] \t Train Loss(MSE): 0.2750 \t Train RMSE: 0.5244\n",
      "Train Epoch: 372 [9648/22032] \t Train Loss(MSE): 0.1002 \t Train RMSE: 0.3165\n",
      "Train Epoch: 372 [19248/22032] \t Train Loss(MSE): 0.1970 \t Train RMSE: 0.4438\n",
      "[Epoch: 372 \t Valid MSE: 16.0336 \t Valid RMSE: 4.0042]\n",
      "[Epoch: 372 \t Train MSE: 1.0953 \t Train RMSE: 1.0466]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 373 [48/22032] \t Train Loss(MSE): 2.1456 \t Train RMSE: 1.4648\n",
      "Train Epoch: 373 [9648/22032] \t Train Loss(MSE): 0.1186 \t Train RMSE: 0.3444\n",
      "Train Epoch: 373 [19248/22032] \t Train Loss(MSE): 0.2281 \t Train RMSE: 0.4776\n",
      "[Epoch: 373 \t Valid MSE: 15.5695 \t Valid RMSE: 3.9458]\n",
      "[Epoch: 373 \t Train MSE: 1.0938 \t Train RMSE: 1.0458]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 374 [48/22032] \t Train Loss(MSE): 0.7406 \t Train RMSE: 0.8606\n",
      "Train Epoch: 374 [9648/22032] \t Train Loss(MSE): 3.8325 \t Train RMSE: 1.9577\n",
      "Train Epoch: 374 [19248/22032] \t Train Loss(MSE): 0.2423 \t Train RMSE: 0.4923\n",
      "[Epoch: 374 \t Valid MSE: 15.2626 \t Valid RMSE: 3.9067]\n",
      "[Epoch: 374 \t Train MSE: 1.0916 \t Train RMSE: 1.0448]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 375 [48/22032] \t Train Loss(MSE): 0.1392 \t Train RMSE: 0.3731\n",
      "Train Epoch: 375 [9648/22032] \t Train Loss(MSE): 2.0216 \t Train RMSE: 1.4218\n",
      "Train Epoch: 375 [19248/22032] \t Train Loss(MSE): 0.2086 \t Train RMSE: 0.4567\n",
      "[Epoch: 375 \t Valid MSE: 15.4423 \t Valid RMSE: 3.9297]\n",
      "[Epoch: 375 \t Train MSE: 1.0911 \t Train RMSE: 1.0445]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 376 [48/22032] \t Train Loss(MSE): 0.3425 \t Train RMSE: 0.5852\n",
      "Train Epoch: 376 [9648/22032] \t Train Loss(MSE): 0.0923 \t Train RMSE: 0.3038\n",
      "Train Epoch: 376 [19248/22032] \t Train Loss(MSE): 0.1442 \t Train RMSE: 0.3797\n",
      "[Epoch: 376 \t Valid MSE: 15.3866 \t Valid RMSE: 3.9226]\n",
      "[Epoch: 376 \t Train MSE: 1.0780 \t Train RMSE: 1.0383]\n",
      "Validation loss decreased (1.082144 --> 1.078035).  Saving model ...\n",
      "Train Epoch: 377 [48/22032] \t Train Loss(MSE): 0.7559 \t Train RMSE: 0.8694\n",
      "Train Epoch: 377 [9648/22032] \t Train Loss(MSE): 2.9140 \t Train RMSE: 1.7070\n",
      "Train Epoch: 377 [19248/22032] \t Train Loss(MSE): 0.2185 \t Train RMSE: 0.4674\n",
      "[Epoch: 377 \t Valid MSE: 15.6462 \t Valid RMSE: 3.9555]\n",
      "[Epoch: 377 \t Train MSE: 1.0804 \t Train RMSE: 1.0394]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 378 [48/22032] \t Train Loss(MSE): 0.0909 \t Train RMSE: 0.3015\n",
      "Train Epoch: 378 [9648/22032] \t Train Loss(MSE): 0.1671 \t Train RMSE: 0.4088\n",
      "Train Epoch: 378 [19248/22032] \t Train Loss(MSE): 0.9811 \t Train RMSE: 0.9905\n",
      "[Epoch: 378 \t Valid MSE: 15.3417 \t Valid RMSE: 3.9168]\n",
      "[Epoch: 378 \t Train MSE: 1.0736 \t Train RMSE: 1.0362]\n",
      "Validation loss decreased (1.078035 --> 1.073611).  Saving model ...\n",
      "Train Epoch: 379 [48/22032] \t Train Loss(MSE): 0.3813 \t Train RMSE: 0.6175\n",
      "Train Epoch: 379 [9648/22032] \t Train Loss(MSE): 0.1883 \t Train RMSE: 0.4340\n",
      "Train Epoch: 379 [19248/22032] \t Train Loss(MSE): 0.1888 \t Train RMSE: 0.4345\n",
      "[Epoch: 379 \t Valid MSE: 15.1597 \t Valid RMSE: 3.8936]\n",
      "[Epoch: 379 \t Train MSE: 1.0722 \t Train RMSE: 1.0355]\n",
      "Validation loss decreased (1.073611 --> 1.072223).  Saving model ...\n",
      "Train Epoch: 380 [48/22032] \t Train Loss(MSE): 0.6259 \t Train RMSE: 0.7911\n",
      "Train Epoch: 380 [9648/22032] \t Train Loss(MSE): 0.2612 \t Train RMSE: 0.5110\n",
      "Train Epoch: 380 [19248/22032] \t Train Loss(MSE): 1.0587 \t Train RMSE: 1.0290\n",
      "[Epoch: 380 \t Valid MSE: 15.6790 \t Valid RMSE: 3.9597]\n",
      "[Epoch: 380 \t Train MSE: 1.0734 \t Train RMSE: 1.0360]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 381 [48/22032] \t Train Loss(MSE): 8.3875 \t Train RMSE: 2.8961\n",
      "Train Epoch: 381 [9648/22032] \t Train Loss(MSE): 0.2047 \t Train RMSE: 0.4524\n",
      "Train Epoch: 381 [19248/22032] \t Train Loss(MSE): 0.6488 \t Train RMSE: 0.8055\n",
      "[Epoch: 381 \t Valid MSE: 15.3683 \t Valid RMSE: 3.9202]\n",
      "[Epoch: 381 \t Train MSE: 1.0812 \t Train RMSE: 1.0398]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 382 [48/22032] \t Train Loss(MSE): 0.2110 \t Train RMSE: 0.4593\n",
      "Train Epoch: 382 [9648/22032] \t Train Loss(MSE): 0.1685 \t Train RMSE: 0.4105\n",
      "Train Epoch: 382 [19248/22032] \t Train Loss(MSE): 0.1595 \t Train RMSE: 0.3994\n",
      "[Epoch: 382 \t Valid MSE: 15.3607 \t Valid RMSE: 3.9193]\n",
      "[Epoch: 382 \t Train MSE: 1.0948 \t Train RMSE: 1.0463]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 383 [48/22032] \t Train Loss(MSE): 0.3771 \t Train RMSE: 0.6141\n",
      "Train Epoch: 383 [9648/22032] \t Train Loss(MSE): 7.8408 \t Train RMSE: 2.8001\n",
      "Train Epoch: 383 [19248/22032] \t Train Loss(MSE): 0.2465 \t Train RMSE: 0.4964\n",
      "[Epoch: 383 \t Valid MSE: 15.3124 \t Valid RMSE: 3.9131]\n",
      "[Epoch: 383 \t Train MSE: 1.0737 \t Train RMSE: 1.0362]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 384 [48/22032] \t Train Loss(MSE): 0.2273 \t Train RMSE: 0.4767\n",
      "Train Epoch: 384 [9648/22032] \t Train Loss(MSE): 0.0847 \t Train RMSE: 0.2911\n",
      "Train Epoch: 384 [19248/22032] \t Train Loss(MSE): 0.1581 \t Train RMSE: 0.3976\n",
      "[Epoch: 384 \t Valid MSE: 15.3347 \t Valid RMSE: 3.9160]\n",
      "[Epoch: 384 \t Train MSE: 1.0649 \t Train RMSE: 1.0320]\n",
      "Validation loss decreased (1.072223 --> 1.064947).  Saving model ...\n",
      "Train Epoch: 385 [48/22032] \t Train Loss(MSE): 0.1399 \t Train RMSE: 0.3741\n",
      "Train Epoch: 385 [9648/22032] \t Train Loss(MSE): 0.4879 \t Train RMSE: 0.6985\n",
      "Train Epoch: 385 [19248/22032] \t Train Loss(MSE): 2.1719 \t Train RMSE: 1.4737\n",
      "[Epoch: 385 \t Valid MSE: 15.4373 \t Valid RMSE: 3.9290]\n",
      "[Epoch: 385 \t Train MSE: 1.0772 \t Train RMSE: 1.0379]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 386 [48/22032] \t Train Loss(MSE): 0.2035 \t Train RMSE: 0.4511\n",
      "Train Epoch: 386 [9648/22032] \t Train Loss(MSE): 0.2506 \t Train RMSE: 0.5006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 386 [19248/22032] \t Train Loss(MSE): 0.1436 \t Train RMSE: 0.3789\n",
      "[Epoch: 386 \t Valid MSE: 15.1984 \t Valid RMSE: 3.8985]\n",
      "[Epoch: 386 \t Train MSE: 1.0817 \t Train RMSE: 1.0401]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 387 [48/22032] \t Train Loss(MSE): 0.3877 \t Train RMSE: 0.6227\n",
      "Train Epoch: 387 [9648/22032] \t Train Loss(MSE): 0.1244 \t Train RMSE: 0.3527\n",
      "Train Epoch: 387 [19248/22032] \t Train Loss(MSE): 1.5964 \t Train RMSE: 1.2635\n",
      "[Epoch: 387 \t Valid MSE: 15.3051 \t Valid RMSE: 3.9122]\n",
      "[Epoch: 387 \t Train MSE: 1.0753 \t Train RMSE: 1.0370]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 388 [48/22032] \t Train Loss(MSE): 0.6868 \t Train RMSE: 0.8287\n",
      "Train Epoch: 388 [9648/22032] \t Train Loss(MSE): 0.1761 \t Train RMSE: 0.4196\n",
      "Train Epoch: 388 [19248/22032] \t Train Loss(MSE): 0.1989 \t Train RMSE: 0.4460\n",
      "[Epoch: 388 \t Valid MSE: 15.3637 \t Valid RMSE: 3.9197]\n",
      "[Epoch: 388 \t Train MSE: 1.0810 \t Train RMSE: 1.0397]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 389 [48/22032] \t Train Loss(MSE): 0.2497 \t Train RMSE: 0.4997\n",
      "Train Epoch: 389 [9648/22032] \t Train Loss(MSE): 0.1434 \t Train RMSE: 0.3787\n",
      "Train Epoch: 389 [19248/22032] \t Train Loss(MSE): 1.3431 \t Train RMSE: 1.1589\n",
      "[Epoch: 389 \t Valid MSE: 15.3496 \t Valid RMSE: 3.9179]\n",
      "[Epoch: 389 \t Train MSE: 83.0630 \t Train RMSE: 9.1139]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 390 [48/22032] \t Train Loss(MSE): 15.1110 \t Train RMSE: 3.8873\n",
      "Train Epoch: 390 [9648/22032] \t Train Loss(MSE): 2.5962 \t Train RMSE: 1.6113\n",
      "Train Epoch: 390 [19248/22032] \t Train Loss(MSE): 0.1156 \t Train RMSE: 0.3400\n",
      "[Epoch: 390 \t Valid MSE: 15.5744 \t Valid RMSE: 3.9464]\n",
      "[Epoch: 390 \t Train MSE: 1.0658 \t Train RMSE: 1.0324]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 391 [48/22032] \t Train Loss(MSE): 0.9296 \t Train RMSE: 0.9641\n",
      "Train Epoch: 391 [9648/22032] \t Train Loss(MSE): 0.5606 \t Train RMSE: 0.7487\n",
      "Train Epoch: 391 [19248/22032] \t Train Loss(MSE): 0.2016 \t Train RMSE: 0.4490\n",
      "[Epoch: 391 \t Valid MSE: 15.2635 \t Valid RMSE: 3.9069]\n",
      "[Epoch: 391 \t Train MSE: 1.0545 \t Train RMSE: 1.0269]\n",
      "Validation loss decreased (1.064947 --> 1.054547).  Saving model ...\n",
      "Train Epoch: 392 [48/22032] \t Train Loss(MSE): 0.1213 \t Train RMSE: 0.3483\n",
      "Train Epoch: 392 [9648/22032] \t Train Loss(MSE): 0.2155 \t Train RMSE: 0.4642\n",
      "Train Epoch: 392 [19248/22032] \t Train Loss(MSE): 0.1786 \t Train RMSE: 0.4226\n",
      "[Epoch: 392 \t Valid MSE: 15.3712 \t Valid RMSE: 3.9206]\n",
      "[Epoch: 392 \t Train MSE: 1.0641 \t Train RMSE: 1.0315]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 393 [48/22032] \t Train Loss(MSE): 0.2043 \t Train RMSE: 0.4520\n",
      "Train Epoch: 393 [9648/22032] \t Train Loss(MSE): 0.0866 \t Train RMSE: 0.2944\n",
      "Train Epoch: 393 [19248/22032] \t Train Loss(MSE): 0.1992 \t Train RMSE: 0.4463\n",
      "[Epoch: 393 \t Valid MSE: 15.4060 \t Valid RMSE: 3.9250]\n",
      "[Epoch: 393 \t Train MSE: 1.0572 \t Train RMSE: 1.0282]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 394 [48/22032] \t Train Loss(MSE): 13.2121 \t Train RMSE: 3.6348\n",
      "Train Epoch: 394 [9648/22032] \t Train Loss(MSE): 0.1901 \t Train RMSE: 0.4360\n",
      "Train Epoch: 394 [19248/22032] \t Train Loss(MSE): 0.1656 \t Train RMSE: 0.4070\n",
      "[Epoch: 394 \t Valid MSE: 15.3198 \t Valid RMSE: 3.9141]\n",
      "[Epoch: 394 \t Train MSE: 1.0596 \t Train RMSE: 1.0293]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 395 [48/22032] \t Train Loss(MSE): 0.2938 \t Train RMSE: 0.5420\n",
      "Train Epoch: 395 [9648/22032] \t Train Loss(MSE): 0.4696 \t Train RMSE: 0.6853\n",
      "Train Epoch: 395 [19248/22032] \t Train Loss(MSE): 6.7265 \t Train RMSE: 2.5935\n",
      "[Epoch: 395 \t Valid MSE: 15.5715 \t Valid RMSE: 3.9461]\n",
      "[Epoch: 395 \t Train MSE: 1.0664 \t Train RMSE: 1.0326]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 396 [48/22032] \t Train Loss(MSE): 0.6763 \t Train RMSE: 0.8224\n",
      "Train Epoch: 396 [9648/22032] \t Train Loss(MSE): 2.1875 \t Train RMSE: 1.4790\n",
      "Train Epoch: 396 [19248/22032] \t Train Loss(MSE): 0.2099 \t Train RMSE: 0.4582\n",
      "[Epoch: 396 \t Valid MSE: 15.3339 \t Valid RMSE: 3.9158]\n",
      "[Epoch: 396 \t Train MSE: 1.0543 \t Train RMSE: 1.0268]\n",
      "Validation loss decreased (1.054547 --> 1.054287).  Saving model ...\n",
      "Train Epoch: 397 [48/22032] \t Train Loss(MSE): 0.1743 \t Train RMSE: 0.4175\n",
      "Train Epoch: 397 [9648/22032] \t Train Loss(MSE): 1.1914 \t Train RMSE: 1.0915\n",
      "Train Epoch: 397 [19248/22032] \t Train Loss(MSE): 0.4266 \t Train RMSE: 0.6531\n",
      "[Epoch: 397 \t Valid MSE: 15.3885 \t Valid RMSE: 3.9228]\n",
      "[Epoch: 397 \t Train MSE: 1.0741 \t Train RMSE: 1.0364]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 398 [48/22032] \t Train Loss(MSE): 0.4148 \t Train RMSE: 0.6440\n",
      "Train Epoch: 398 [9648/22032] \t Train Loss(MSE): 14.3813 \t Train RMSE: 3.7923\n",
      "Train Epoch: 398 [19248/22032] \t Train Loss(MSE): 0.3111 \t Train RMSE: 0.5577\n",
      "[Epoch: 398 \t Valid MSE: 15.3292 \t Valid RMSE: 3.9153]\n",
      "[Epoch: 398 \t Train MSE: 1.0518 \t Train RMSE: 1.0256]\n",
      "Validation loss decreased (1.054287 --> 1.051800).  Saving model ...\n",
      "Train Epoch: 399 [48/22032] \t Train Loss(MSE): 0.1405 \t Train RMSE: 0.3748\n",
      "Train Epoch: 399 [9648/22032] \t Train Loss(MSE): 0.0926 \t Train RMSE: 0.3043\n",
      "Train Epoch: 399 [19248/22032] \t Train Loss(MSE): 0.1680 \t Train RMSE: 0.4099\n",
      "[Epoch: 399 \t Valid MSE: 15.3817 \t Valid RMSE: 3.9219]\n",
      "[Epoch: 399 \t Train MSE: 1.0677 \t Train RMSE: 1.0333]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 400 [48/22032] \t Train Loss(MSE): 0.1181 \t Train RMSE: 0.3437\n",
      "Train Epoch: 400 [9648/22032] \t Train Loss(MSE): 0.2302 \t Train RMSE: 0.4798\n",
      "Train Epoch: 400 [19248/22032] \t Train Loss(MSE): 0.3028 \t Train RMSE: 0.5502\n",
      "[Epoch: 400 \t Valid MSE: 15.3680 \t Valid RMSE: 3.9202]\n",
      "[Epoch: 400 \t Train MSE: 1.0889 \t Train RMSE: 1.0435]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 401 [48/22032] \t Train Loss(MSE): 0.0872 \t Train RMSE: 0.2952\n",
      "Train Epoch: 401 [9648/22032] \t Train Loss(MSE): 0.0924 \t Train RMSE: 0.3040\n",
      "Train Epoch: 401 [19248/22032] \t Train Loss(MSE): 0.1460 \t Train RMSE: 0.3820\n",
      "[Epoch: 401 \t Valid MSE: 15.8200 \t Valid RMSE: 3.9774]\n",
      "[Epoch: 401 \t Train MSE: 1.0648 \t Train RMSE: 1.0319]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 402 [48/22032] \t Train Loss(MSE): 0.2105 \t Train RMSE: 0.4588\n",
      "Train Epoch: 402 [9648/22032] \t Train Loss(MSE): 0.1623 \t Train RMSE: 0.4029\n",
      "Train Epoch: 402 [19248/22032] \t Train Loss(MSE): 0.2582 \t Train RMSE: 0.5081\n",
      "[Epoch: 402 \t Valid MSE: 15.4467 \t Valid RMSE: 3.9302]\n",
      "[Epoch: 402 \t Train MSE: 1.0452 \t Train RMSE: 1.0224]\n",
      "Validation loss decreased (1.051800 --> 1.045243).  Saving model ...\n",
      "Train Epoch: 403 [48/22032] \t Train Loss(MSE): 0.1419 \t Train RMSE: 0.3768\n",
      "Train Epoch: 403 [9648/22032] \t Train Loss(MSE): 0.2146 \t Train RMSE: 0.4633\n",
      "Train Epoch: 403 [19248/22032] \t Train Loss(MSE): 0.5947 \t Train RMSE: 0.7712\n",
      "[Epoch: 403 \t Valid MSE: 15.9227 \t Valid RMSE: 3.9903]\n",
      "[Epoch: 403 \t Train MSE: 1.0403 \t Train RMSE: 1.0200]\n",
      "Validation loss decreased (1.045243 --> 1.040335).  Saving model ...\n",
      "Train Epoch: 404 [48/22032] \t Train Loss(MSE): 0.2333 \t Train RMSE: 0.4830\n",
      "Train Epoch: 404 [9648/22032] \t Train Loss(MSE): 0.8737 \t Train RMSE: 0.9347\n",
      "Train Epoch: 404 [19248/22032] \t Train Loss(MSE): 0.0788 \t Train RMSE: 0.2807\n",
      "[Epoch: 404 \t Valid MSE: 15.4171 \t Valid RMSE: 3.9265]\n",
      "[Epoch: 404 \t Train MSE: 1.0474 \t Train RMSE: 1.0234]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 405 [48/22032] \t Train Loss(MSE): 0.5381 \t Train RMSE: 0.7336\n",
      "Train Epoch: 405 [9648/22032] \t Train Loss(MSE): 0.1359 \t Train RMSE: 0.3687\n",
      "Train Epoch: 405 [19248/22032] \t Train Loss(MSE): 0.1723 \t Train RMSE: 0.4150\n",
      "[Epoch: 405 \t Valid MSE: 15.2899 \t Valid RMSE: 3.9102]\n",
      "[Epoch: 405 \t Train MSE: 1.0606 \t Train RMSE: 1.0299]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 406 [48/22032] \t Train Loss(MSE): 0.1125 \t Train RMSE: 0.3355\n",
      "Train Epoch: 406 [9648/22032] \t Train Loss(MSE): 0.1079 \t Train RMSE: 0.3285\n",
      "Train Epoch: 406 [19248/22032] \t Train Loss(MSE): 0.3889 \t Train RMSE: 0.6236\n",
      "[Epoch: 406 \t Valid MSE: 15.4906 \t Valid RMSE: 3.9358]\n",
      "[Epoch: 406 \t Train MSE: 1.0484 \t Train RMSE: 1.0239]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 407 [48/22032] \t Train Loss(MSE): 0.4684 \t Train RMSE: 0.6844\n",
      "Train Epoch: 407 [9648/22032] \t Train Loss(MSE): 2.0737 \t Train RMSE: 1.4400\n",
      "Train Epoch: 407 [19248/22032] \t Train Loss(MSE): 0.1752 \t Train RMSE: 0.4185\n",
      "[Epoch: 407 \t Valid MSE: 16.1854 \t Valid RMSE: 4.0231]\n",
      "[Epoch: 407 \t Train MSE: 1.0612 \t Train RMSE: 1.0301]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 408 [48/22032] \t Train Loss(MSE): 3.9818 \t Train RMSE: 1.9954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 408 [9648/22032] \t Train Loss(MSE): 0.1265 \t Train RMSE: 0.3556\n",
      "Train Epoch: 408 [19248/22032] \t Train Loss(MSE): 0.2220 \t Train RMSE: 0.4711\n",
      "[Epoch: 408 \t Valid MSE: 15.3988 \t Valid RMSE: 3.9241]\n",
      "[Epoch: 408 \t Train MSE: 1.0409 \t Train RMSE: 1.0202]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 409 [48/22032] \t Train Loss(MSE): 0.1111 \t Train RMSE: 0.3332\n",
      "Train Epoch: 409 [9648/22032] \t Train Loss(MSE): 0.1142 \t Train RMSE: 0.3380\n",
      "Train Epoch: 409 [19248/22032] \t Train Loss(MSE): 0.2063 \t Train RMSE: 0.4542\n",
      "[Epoch: 409 \t Valid MSE: 15.4944 \t Valid RMSE: 3.9363]\n",
      "[Epoch: 409 \t Train MSE: 1.0299 \t Train RMSE: 1.0148]\n",
      "Validation loss decreased (1.040335 --> 1.029889).  Saving model ...\n",
      "Train Epoch: 410 [48/22032] \t Train Loss(MSE): 1.1234 \t Train RMSE: 1.0599\n",
      "Train Epoch: 410 [9648/22032] \t Train Loss(MSE): 0.1092 \t Train RMSE: 0.3304\n",
      "Train Epoch: 410 [19248/22032] \t Train Loss(MSE): 0.1618 \t Train RMSE: 0.4022\n",
      "[Epoch: 410 \t Valid MSE: 15.5825 \t Valid RMSE: 3.9475]\n",
      "[Epoch: 410 \t Train MSE: 1.0309 \t Train RMSE: 1.0153]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 411 [48/22032] \t Train Loss(MSE): 2.1056 \t Train RMSE: 1.4511\n",
      "Train Epoch: 411 [9648/22032] \t Train Loss(MSE): 0.2087 \t Train RMSE: 0.4568\n",
      "Train Epoch: 411 [19248/22032] \t Train Loss(MSE): 0.1482 \t Train RMSE: 0.3849\n",
      "[Epoch: 411 \t Valid MSE: 15.5335 \t Valid RMSE: 3.9413]\n",
      "[Epoch: 411 \t Train MSE: 1.0411 \t Train RMSE: 1.0203]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 412 [48/22032] \t Train Loss(MSE): 0.1958 \t Train RMSE: 0.4425\n",
      "Train Epoch: 412 [9648/22032] \t Train Loss(MSE): 1.0867 \t Train RMSE: 1.0425\n",
      "Train Epoch: 412 [19248/22032] \t Train Loss(MSE): 0.2972 \t Train RMSE: 0.5452\n",
      "[Epoch: 412 \t Valid MSE: 15.4801 \t Valid RMSE: 3.9345]\n",
      "[Epoch: 412 \t Train MSE: 1.0439 \t Train RMSE: 1.0217]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 413 [48/22032] \t Train Loss(MSE): 0.1723 \t Train RMSE: 0.4151\n",
      "Train Epoch: 413 [9648/22032] \t Train Loss(MSE): 1.3509 \t Train RMSE: 1.1623\n",
      "Train Epoch: 413 [19248/22032] \t Train Loss(MSE): 0.1200 \t Train RMSE: 0.3464\n",
      "[Epoch: 413 \t Valid MSE: 15.3596 \t Valid RMSE: 3.9191]\n",
      "[Epoch: 413 \t Train MSE: 1.0376 \t Train RMSE: 1.0186]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 414 [48/22032] \t Train Loss(MSE): 0.1355 \t Train RMSE: 0.3682\n",
      "Train Epoch: 414 [9648/22032] \t Train Loss(MSE): 0.1374 \t Train RMSE: 0.3706\n",
      "Train Epoch: 414 [19248/22032] \t Train Loss(MSE): 0.3430 \t Train RMSE: 0.5856\n",
      "[Epoch: 414 \t Valid MSE: 15.6695 \t Valid RMSE: 3.9585]\n",
      "[Epoch: 414 \t Train MSE: 1.0363 \t Train RMSE: 1.0180]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 415 [48/22032] \t Train Loss(MSE): 0.1619 \t Train RMSE: 0.4024\n",
      "Train Epoch: 415 [9648/22032] \t Train Loss(MSE): 1.6482 \t Train RMSE: 1.2838\n",
      "Train Epoch: 415 [19248/22032] \t Train Loss(MSE): 0.1187 \t Train RMSE: 0.3446\n",
      "[Epoch: 415 \t Valid MSE: 15.6561 \t Valid RMSE: 3.9568]\n",
      "[Epoch: 415 \t Train MSE: 1.0396 \t Train RMSE: 1.0196]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 416 [48/22032] \t Train Loss(MSE): 0.1390 \t Train RMSE: 0.3729\n",
      "Train Epoch: 416 [9648/22032] \t Train Loss(MSE): 0.1596 \t Train RMSE: 0.3995\n",
      "Train Epoch: 416 [19248/22032] \t Train Loss(MSE): 0.2124 \t Train RMSE: 0.4609\n",
      "[Epoch: 416 \t Valid MSE: 15.4870 \t Valid RMSE: 3.9353]\n",
      "[Epoch: 416 \t Train MSE: 1.0410 \t Train RMSE: 1.0203]\n",
      "EarlyStopping counter: 7 out of 40\n",
      "Train Epoch: 417 [48/22032] \t Train Loss(MSE): 0.1112 \t Train RMSE: 0.3335\n",
      "Train Epoch: 417 [9648/22032] \t Train Loss(MSE): 0.1171 \t Train RMSE: 0.3422\n",
      "Train Epoch: 417 [19248/22032] \t Train Loss(MSE): 0.2514 \t Train RMSE: 0.5014\n",
      "[Epoch: 417 \t Valid MSE: 15.3422 \t Valid RMSE: 3.9169]\n",
      "[Epoch: 417 \t Train MSE: 1.0513 \t Train RMSE: 1.0253]\n",
      "EarlyStopping counter: 8 out of 40\n",
      "Train Epoch: 418 [48/22032] \t Train Loss(MSE): 5.7311 \t Train RMSE: 2.3940\n",
      "Train Epoch: 418 [9648/22032] \t Train Loss(MSE): 0.1892 \t Train RMSE: 0.4350\n",
      "Train Epoch: 418 [19248/22032] \t Train Loss(MSE): 0.1794 \t Train RMSE: 0.4236\n",
      "[Epoch: 418 \t Valid MSE: 15.5721 \t Valid RMSE: 3.9461]\n",
      "[Epoch: 418 \t Train MSE: 1.0390 \t Train RMSE: 1.0193]\n",
      "EarlyStopping counter: 9 out of 40\n",
      "Train Epoch: 419 [48/22032] \t Train Loss(MSE): 2.2069 \t Train RMSE: 1.4855\n",
      "Train Epoch: 419 [9648/22032] \t Train Loss(MSE): 0.2194 \t Train RMSE: 0.4684\n",
      "Train Epoch: 419 [19248/22032] \t Train Loss(MSE): 0.1410 \t Train RMSE: 0.3754\n",
      "[Epoch: 419 \t Valid MSE: 15.4573 \t Valid RMSE: 3.9316]\n",
      "[Epoch: 419 \t Train MSE: 1.0356 \t Train RMSE: 1.0176]\n",
      "EarlyStopping counter: 10 out of 40\n",
      "Train Epoch: 420 [48/22032] \t Train Loss(MSE): 0.2814 \t Train RMSE: 0.5305\n",
      "Train Epoch: 420 [9648/22032] \t Train Loss(MSE): 8.8385 \t Train RMSE: 2.9730\n",
      "Train Epoch: 420 [19248/22032] \t Train Loss(MSE): 0.3474 \t Train RMSE: 0.5894\n",
      "[Epoch: 420 \t Valid MSE: 15.5382 \t Valid RMSE: 3.9418]\n",
      "[Epoch: 420 \t Train MSE: 1.0308 \t Train RMSE: 1.0153]\n",
      "Epoch   420: reducing learning rate of group 0 to 6.2500e-04.\n",
      "EarlyStopping counter: 11 out of 40\n",
      "Train Epoch: 421 [48/22032] \t Train Loss(MSE): 0.1105 \t Train RMSE: 0.3324\n",
      "Train Epoch: 421 [9648/22032] \t Train Loss(MSE): 0.1361 \t Train RMSE: 0.3689\n",
      "Train Epoch: 421 [19248/22032] \t Train Loss(MSE): 0.1128 \t Train RMSE: 0.3358\n",
      "[Epoch: 421 \t Valid MSE: 15.5121 \t Valid RMSE: 3.9385]\n",
      "[Epoch: 421 \t Train MSE: 1.0100 \t Train RMSE: 1.0050]\n",
      "Validation loss decreased (1.029889 --> 1.009985).  Saving model ...\n",
      "Train Epoch: 422 [48/22032] \t Train Loss(MSE): 0.1248 \t Train RMSE: 0.3532\n",
      "Train Epoch: 422 [9648/22032] \t Train Loss(MSE): 2.8031 \t Train RMSE: 1.6742\n",
      "Train Epoch: 422 [19248/22032] \t Train Loss(MSE): 5.4016 \t Train RMSE: 2.3241\n",
      "[Epoch: 422 \t Valid MSE: 15.4915 \t Valid RMSE: 3.9359]\n",
      "[Epoch: 422 \t Train MSE: 0.9911 \t Train RMSE: 0.9955]\n",
      "Validation loss decreased (1.009985 --> 0.991066).  Saving model ...\n",
      "Train Epoch: 423 [48/22032] \t Train Loss(MSE): 0.0644 \t Train RMSE: 0.2539\n",
      "Train Epoch: 423 [9648/22032] \t Train Loss(MSE): 0.2484 \t Train RMSE: 0.4984\n",
      "Train Epoch: 423 [19248/22032] \t Train Loss(MSE): 2.1300 \t Train RMSE: 1.4594\n",
      "[Epoch: 423 \t Valid MSE: 15.4350 \t Valid RMSE: 3.9287]\n",
      "[Epoch: 423 \t Train MSE: 0.9878 \t Train RMSE: 0.9939]\n",
      "Validation loss decreased (0.991066 --> 0.987803).  Saving model ...\n",
      "Train Epoch: 424 [48/22032] \t Train Loss(MSE): 0.1352 \t Train RMSE: 0.3677\n",
      "Train Epoch: 424 [9648/22032] \t Train Loss(MSE): 0.0779 \t Train RMSE: 0.2791\n",
      "Train Epoch: 424 [19248/22032] \t Train Loss(MSE): 3.1704 \t Train RMSE: 1.7806\n",
      "[Epoch: 424 \t Valid MSE: 15.5893 \t Valid RMSE: 3.9483]\n",
      "[Epoch: 424 \t Train MSE: 0.9863 \t Train RMSE: 0.9931]\n",
      "Validation loss decreased (0.987803 --> 0.986290).  Saving model ...\n",
      "Train Epoch: 425 [48/22032] \t Train Loss(MSE): 0.0419 \t Train RMSE: 0.2048\n",
      "Train Epoch: 425 [9648/22032] \t Train Loss(MSE): 0.0776 \t Train RMSE: 0.2785\n",
      "Train Epoch: 425 [19248/22032] \t Train Loss(MSE): 0.0660 \t Train RMSE: 0.2570\n",
      "[Epoch: 425 \t Valid MSE: 15.4710 \t Valid RMSE: 3.9333]\n",
      "[Epoch: 425 \t Train MSE: 0.9876 \t Train RMSE: 0.9938]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 426 [48/22032] \t Train Loss(MSE): 0.2024 \t Train RMSE: 0.4498\n",
      "Train Epoch: 426 [9648/22032] \t Train Loss(MSE): 0.1086 \t Train RMSE: 0.3295\n",
      "Train Epoch: 426 [19248/22032] \t Train Loss(MSE): 1.0740 \t Train RMSE: 1.0363\n",
      "[Epoch: 426 \t Valid MSE: 15.4510 \t Valid RMSE: 3.9308]\n",
      "[Epoch: 426 \t Train MSE: 0.9847 \t Train RMSE: 0.9923]\n",
      "Validation loss decreased (0.986290 --> 0.984709).  Saving model ...\n",
      "Train Epoch: 427 [48/22032] \t Train Loss(MSE): 0.1787 \t Train RMSE: 0.4227\n",
      "Train Epoch: 427 [9648/22032] \t Train Loss(MSE): 14.3676 \t Train RMSE: 3.7905\n",
      "Train Epoch: 427 [19248/22032] \t Train Loss(MSE): 0.1231 \t Train RMSE: 0.3509\n",
      "[Epoch: 427 \t Valid MSE: 15.4242 \t Valid RMSE: 3.9274]\n",
      "[Epoch: 427 \t Train MSE: 0.9852 \t Train RMSE: 0.9926]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 428 [48/22032] \t Train Loss(MSE): 0.1442 \t Train RMSE: 0.3797\n",
      "Train Epoch: 428 [9648/22032] \t Train Loss(MSE): 0.5492 \t Train RMSE: 0.7411\n",
      "Train Epoch: 428 [19248/22032] \t Train Loss(MSE): 0.1803 \t Train RMSE: 0.4246\n",
      "[Epoch: 428 \t Valid MSE: 15.4620 \t Valid RMSE: 3.9322]\n",
      "[Epoch: 428 \t Train MSE: 0.9864 \t Train RMSE: 0.9932]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 429 [48/22032] \t Train Loss(MSE): 0.8740 \t Train RMSE: 0.9349\n",
      "Train Epoch: 429 [9648/22032] \t Train Loss(MSE): 0.0724 \t Train RMSE: 0.2691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 429 [19248/22032] \t Train Loss(MSE): 0.8644 \t Train RMSE: 0.9297\n",
      "[Epoch: 429 \t Valid MSE: 15.5183 \t Valid RMSE: 3.9393]\n",
      "[Epoch: 429 \t Train MSE: 0.9846 \t Train RMSE: 0.9923]\n",
      "Validation loss decreased (0.984709 --> 0.984615).  Saving model ...\n",
      "Train Epoch: 430 [48/22032] \t Train Loss(MSE): 0.1625 \t Train RMSE: 0.4031\n",
      "Train Epoch: 430 [9648/22032] \t Train Loss(MSE): 0.1097 \t Train RMSE: 0.3312\n",
      "Train Epoch: 430 [19248/22032] \t Train Loss(MSE): 0.1943 \t Train RMSE: 0.4408\n",
      "[Epoch: 430 \t Valid MSE: 15.5109 \t Valid RMSE: 3.9384]\n",
      "[Epoch: 430 \t Train MSE: 0.9852 \t Train RMSE: 0.9926]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 431 [48/22032] \t Train Loss(MSE): 1.0899 \t Train RMSE: 1.0440\n",
      "Train Epoch: 431 [9648/22032] \t Train Loss(MSE): 0.0914 \t Train RMSE: 0.3024\n",
      "Train Epoch: 431 [19248/22032] \t Train Loss(MSE): 0.0926 \t Train RMSE: 0.3043\n",
      "[Epoch: 431 \t Valid MSE: 15.5418 \t Valid RMSE: 3.9423]\n",
      "[Epoch: 431 \t Train MSE: 0.9838 \t Train RMSE: 0.9919]\n",
      "Validation loss decreased (0.984615 --> 0.983794).  Saving model ...\n",
      "Train Epoch: 432 [48/22032] \t Train Loss(MSE): 0.1079 \t Train RMSE: 0.3285\n",
      "Train Epoch: 432 [9648/22032] \t Train Loss(MSE): 0.1031 \t Train RMSE: 0.3210\n",
      "Train Epoch: 432 [19248/22032] \t Train Loss(MSE): 0.1176 \t Train RMSE: 0.3430\n",
      "[Epoch: 432 \t Valid MSE: 15.4933 \t Valid RMSE: 3.9362]\n",
      "[Epoch: 432 \t Train MSE: 0.9850 \t Train RMSE: 0.9925]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 433 [48/22032] \t Train Loss(MSE): 0.1391 \t Train RMSE: 0.3729\n",
      "Train Epoch: 433 [9648/22032] \t Train Loss(MSE): 0.2408 \t Train RMSE: 0.4908\n",
      "Train Epoch: 433 [19248/22032] \t Train Loss(MSE): 0.1572 \t Train RMSE: 0.3964\n",
      "[Epoch: 433 \t Valid MSE: 15.5719 \t Valid RMSE: 3.9461]\n",
      "[Epoch: 433 \t Train MSE: 0.9809 \t Train RMSE: 0.9904]\n",
      "Validation loss decreased (0.983794 --> 0.980899).  Saving model ...\n",
      "Train Epoch: 434 [48/22032] \t Train Loss(MSE): 0.4297 \t Train RMSE: 0.6555\n",
      "Train Epoch: 434 [9648/22032] \t Train Loss(MSE): 0.1845 \t Train RMSE: 0.4295\n",
      "Train Epoch: 434 [19248/22032] \t Train Loss(MSE): 0.9868 \t Train RMSE: 0.9934\n",
      "[Epoch: 434 \t Valid MSE: 15.6347 \t Valid RMSE: 3.9541]\n",
      "[Epoch: 434 \t Train MSE: 0.9805 \t Train RMSE: 0.9902]\n",
      "Validation loss decreased (0.980899 --> 0.980501).  Saving model ...\n",
      "Train Epoch: 435 [48/22032] \t Train Loss(MSE): 0.1570 \t Train RMSE: 0.3962\n",
      "Train Epoch: 435 [9648/22032] \t Train Loss(MSE): 0.3448 \t Train RMSE: 0.5872\n",
      "Train Epoch: 435 [19248/22032] \t Train Loss(MSE): 0.0768 \t Train RMSE: 0.2772\n",
      "[Epoch: 435 \t Valid MSE: 15.5881 \t Valid RMSE: 3.9482]\n",
      "[Epoch: 435 \t Train MSE: 0.9870 \t Train RMSE: 0.9935]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 436 [48/22032] \t Train Loss(MSE): 0.0853 \t Train RMSE: 0.2920\n",
      "Train Epoch: 436 [9648/22032] \t Train Loss(MSE): 0.0810 \t Train RMSE: 0.2846\n",
      "Train Epoch: 436 [19248/22032] \t Train Loss(MSE): 3.1733 \t Train RMSE: 1.7814\n",
      "[Epoch: 436 \t Valid MSE: 15.6216 \t Valid RMSE: 3.9524]\n",
      "[Epoch: 436 \t Train MSE: 0.9824 \t Train RMSE: 0.9912]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 437 [48/22032] \t Train Loss(MSE): 0.0979 \t Train RMSE: 0.3128\n",
      "Train Epoch: 437 [9648/22032] \t Train Loss(MSE): 0.1359 \t Train RMSE: 0.3687\n",
      "Train Epoch: 437 [19248/22032] \t Train Loss(MSE): 0.7196 \t Train RMSE: 0.8483\n",
      "[Epoch: 437 \t Valid MSE: 15.5875 \t Valid RMSE: 3.9481]\n",
      "[Epoch: 437 \t Train MSE: 0.9789 \t Train RMSE: 0.9894]\n",
      "Validation loss decreased (0.980501 --> 0.978853).  Saving model ...\n",
      "Train Epoch: 438 [48/22032] \t Train Loss(MSE): 1.7088 \t Train RMSE: 1.3072\n",
      "Train Epoch: 438 [9648/22032] \t Train Loss(MSE): 0.0878 \t Train RMSE: 0.2963\n",
      "Train Epoch: 438 [19248/22032] \t Train Loss(MSE): 0.0749 \t Train RMSE: 0.2737\n",
      "[Epoch: 438 \t Valid MSE: 15.6135 \t Valid RMSE: 3.9514]\n",
      "[Epoch: 438 \t Train MSE: 0.9806 \t Train RMSE: 0.9903]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 439 [48/22032] \t Train Loss(MSE): 0.5382 \t Train RMSE: 0.7336\n",
      "Train Epoch: 439 [9648/22032] \t Train Loss(MSE): 3.5323 \t Train RMSE: 1.8794\n",
      "Train Epoch: 439 [19248/22032] \t Train Loss(MSE): 0.0782 \t Train RMSE: 0.2797\n",
      "[Epoch: 439 \t Valid MSE: 15.8923 \t Valid RMSE: 3.9865]\n",
      "[Epoch: 439 \t Train MSE: 0.9800 \t Train RMSE: 0.9900]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 440 [48/22032] \t Train Loss(MSE): 0.4712 \t Train RMSE: 0.6864\n",
      "Train Epoch: 440 [9648/22032] \t Train Loss(MSE): 0.0636 \t Train RMSE: 0.2522\n",
      "Train Epoch: 440 [19248/22032] \t Train Loss(MSE): 0.0771 \t Train RMSE: 0.2778\n",
      "[Epoch: 440 \t Valid MSE: 15.6557 \t Valid RMSE: 3.9567]\n",
      "[Epoch: 440 \t Train MSE: 0.9819 \t Train RMSE: 0.9909]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 441 [48/22032] \t Train Loss(MSE): 0.1763 \t Train RMSE: 0.4198\n",
      "Train Epoch: 441 [9648/22032] \t Train Loss(MSE): 0.0731 \t Train RMSE: 0.2703\n",
      "Train Epoch: 441 [19248/22032] \t Train Loss(MSE): 13.1376 \t Train RMSE: 3.6246\n",
      "[Epoch: 441 \t Valid MSE: 15.6673 \t Valid RMSE: 3.9582]\n",
      "[Epoch: 441 \t Train MSE: 0.9779 \t Train RMSE: 0.9889]\n",
      "Validation loss decreased (0.978853 --> 0.977870).  Saving model ...\n",
      "Train Epoch: 442 [48/22032] \t Train Loss(MSE): 0.0983 \t Train RMSE: 0.3136\n",
      "Train Epoch: 442 [9648/22032] \t Train Loss(MSE): 0.1490 \t Train RMSE: 0.3859\n",
      "Train Epoch: 442 [19248/22032] \t Train Loss(MSE): 3.3651 \t Train RMSE: 1.8344\n",
      "[Epoch: 442 \t Valid MSE: 16.0449 \t Valid RMSE: 4.0056]\n",
      "[Epoch: 442 \t Train MSE: 0.9744 \t Train RMSE: 0.9871]\n",
      "Validation loss decreased (0.977870 --> 0.974367).  Saving model ...\n",
      "Train Epoch: 443 [48/22032] \t Train Loss(MSE): 0.2063 \t Train RMSE: 0.4542\n",
      "Train Epoch: 443 [9648/22032] \t Train Loss(MSE): 0.2417 \t Train RMSE: 0.4916\n",
      "Train Epoch: 443 [19248/22032] \t Train Loss(MSE): 0.0596 \t Train RMSE: 0.2442\n",
      "[Epoch: 443 \t Valid MSE: 15.6490 \t Valid RMSE: 3.9559]\n",
      "[Epoch: 443 \t Train MSE: 0.9810 \t Train RMSE: 0.9905]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 444 [48/22032] \t Train Loss(MSE): 14.3113 \t Train RMSE: 3.7830\n",
      "Train Epoch: 444 [9648/22032] \t Train Loss(MSE): 0.3450 \t Train RMSE: 0.5873\n",
      "Train Epoch: 444 [19248/22032] \t Train Loss(MSE): 0.0710 \t Train RMSE: 0.2665\n",
      "[Epoch: 444 \t Valid MSE: 15.5505 \t Valid RMSE: 3.9434]\n",
      "[Epoch: 444 \t Train MSE: 0.9765 \t Train RMSE: 0.9882]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 445 [48/22032] \t Train Loss(MSE): 0.0994 \t Train RMSE: 0.3152\n",
      "Train Epoch: 445 [9648/22032] \t Train Loss(MSE): 0.1401 \t Train RMSE: 0.3742\n",
      "Train Epoch: 445 [19248/22032] \t Train Loss(MSE): 0.0547 \t Train RMSE: 0.2339\n",
      "[Epoch: 445 \t Valid MSE: 15.7970 \t Valid RMSE: 3.9745]\n",
      "[Epoch: 445 \t Train MSE: 0.9807 \t Train RMSE: 0.9903]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 446 [48/22032] \t Train Loss(MSE): 16.7347 \t Train RMSE: 4.0908\n",
      "Train Epoch: 446 [9648/22032] \t Train Loss(MSE): 1.9095 \t Train RMSE: 1.3818\n",
      "Train Epoch: 446 [19248/22032] \t Train Loss(MSE): 0.0752 \t Train RMSE: 0.2742\n",
      "[Epoch: 446 \t Valid MSE: 15.6698 \t Valid RMSE: 3.9585]\n",
      "[Epoch: 446 \t Train MSE: 0.9709 \t Train RMSE: 0.9854]\n",
      "Validation loss decreased (0.974367 --> 0.970918).  Saving model ...\n",
      "Train Epoch: 447 [48/22032] \t Train Loss(MSE): 0.0717 \t Train RMSE: 0.2677\n",
      "Train Epoch: 447 [9648/22032] \t Train Loss(MSE): 0.1456 \t Train RMSE: 0.3816\n",
      "Train Epoch: 447 [19248/22032] \t Train Loss(MSE): 0.0915 \t Train RMSE: 0.3026\n",
      "[Epoch: 447 \t Valid MSE: 15.7844 \t Valid RMSE: 3.9730]\n",
      "[Epoch: 447 \t Train MSE: 0.9730 \t Train RMSE: 0.9864]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 448 [48/22032] \t Train Loss(MSE): 0.0438 \t Train RMSE: 0.2092\n",
      "Train Epoch: 448 [9648/22032] \t Train Loss(MSE): 2.6067 \t Train RMSE: 1.6145\n",
      "Train Epoch: 448 [19248/22032] \t Train Loss(MSE): 0.0939 \t Train RMSE: 0.3064\n",
      "[Epoch: 448 \t Valid MSE: 15.5938 \t Valid RMSE: 3.9489]\n",
      "[Epoch: 448 \t Train MSE: 0.9707 \t Train RMSE: 0.9853]\n",
      "Validation loss decreased (0.970918 --> 0.970746).  Saving model ...\n",
      "Train Epoch: 449 [48/22032] \t Train Loss(MSE): 0.0630 \t Train RMSE: 0.2511\n",
      "Train Epoch: 449 [9648/22032] \t Train Loss(MSE): 0.2000 \t Train RMSE: 0.4472\n",
      "Train Epoch: 449 [19248/22032] \t Train Loss(MSE): 0.0524 \t Train RMSE: 0.2290\n",
      "[Epoch: 449 \t Valid MSE: 15.5575 \t Valid RMSE: 3.9443]\n",
      "[Epoch: 449 \t Train MSE: 0.9713 \t Train RMSE: 0.9855]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 450 [48/22032] \t Train Loss(MSE): 0.0746 \t Train RMSE: 0.2732\n",
      "Train Epoch: 450 [9648/22032] \t Train Loss(MSE): 0.0696 \t Train RMSE: 0.2638\n",
      "Train Epoch: 450 [19248/22032] \t Train Loss(MSE): 0.1685 \t Train RMSE: 0.4105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 450 \t Valid MSE: 15.6684 \t Valid RMSE: 3.9583]\n",
      "[Epoch: 450 \t Train MSE: 0.9689 \t Train RMSE: 0.9843]\n",
      "Validation loss decreased (0.970746 --> 0.968942).  Saving model ...\n",
      "Train Epoch: 451 [48/22032] \t Train Loss(MSE): 0.3843 \t Train RMSE: 0.6199\n",
      "Train Epoch: 451 [9648/22032] \t Train Loss(MSE): 0.1095 \t Train RMSE: 0.3308\n",
      "Train Epoch: 451 [19248/22032] \t Train Loss(MSE): 0.1056 \t Train RMSE: 0.3250\n",
      "[Epoch: 451 \t Valid MSE: 15.5590 \t Valid RMSE: 3.9445]\n",
      "[Epoch: 451 \t Train MSE: 0.9671 \t Train RMSE: 0.9834]\n",
      "Validation loss decreased (0.968942 --> 0.967083).  Saving model ...\n",
      "Train Epoch: 452 [48/22032] \t Train Loss(MSE): 0.0736 \t Train RMSE: 0.2713\n",
      "Train Epoch: 452 [9648/22032] \t Train Loss(MSE): 13.8867 \t Train RMSE: 3.7265\n",
      "Train Epoch: 452 [19248/22032] \t Train Loss(MSE): 0.1553 \t Train RMSE: 0.3940\n",
      "[Epoch: 452 \t Valid MSE: 16.0037 \t Valid RMSE: 4.0005]\n",
      "[Epoch: 452 \t Train MSE: 0.9690 \t Train RMSE: 0.9844]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 453 [48/22032] \t Train Loss(MSE): 0.4744 \t Train RMSE: 0.6888\n",
      "Train Epoch: 453 [9648/22032] \t Train Loss(MSE): 0.1480 \t Train RMSE: 0.3847\n",
      "Train Epoch: 453 [19248/22032] \t Train Loss(MSE): 0.1348 \t Train RMSE: 0.3671\n",
      "[Epoch: 453 \t Valid MSE: 15.6050 \t Valid RMSE: 3.9503]\n",
      "[Epoch: 453 \t Train MSE: 0.9704 \t Train RMSE: 0.9851]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 454 [48/22032] \t Train Loss(MSE): 0.0491 \t Train RMSE: 0.2215\n",
      "Train Epoch: 454 [9648/22032] \t Train Loss(MSE): 8.8472 \t Train RMSE: 2.9744\n",
      "Train Epoch: 454 [19248/22032] \t Train Loss(MSE): 0.2260 \t Train RMSE: 0.4753\n",
      "[Epoch: 454 \t Valid MSE: 15.5554 \t Valid RMSE: 3.9440]\n",
      "[Epoch: 454 \t Train MSE: 0.9665 \t Train RMSE: 0.9831]\n",
      "Validation loss decreased (0.967083 --> 0.966488).  Saving model ...\n",
      "Train Epoch: 455 [48/22032] \t Train Loss(MSE): 0.1177 \t Train RMSE: 0.3431\n",
      "Train Epoch: 455 [9648/22032] \t Train Loss(MSE): 0.1104 \t Train RMSE: 0.3323\n",
      "Train Epoch: 455 [19248/22032] \t Train Loss(MSE): 0.0785 \t Train RMSE: 0.2802\n",
      "[Epoch: 455 \t Valid MSE: 15.6850 \t Valid RMSE: 3.9604]\n",
      "[Epoch: 455 \t Train MSE: 0.9706 \t Train RMSE: 0.9852]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 456 [48/22032] \t Train Loss(MSE): 0.1262 \t Train RMSE: 0.3552\n",
      "Train Epoch: 456 [9648/22032] \t Train Loss(MSE): 0.0538 \t Train RMSE: 0.2320\n",
      "Train Epoch: 456 [19248/22032] \t Train Loss(MSE): 1.2827 \t Train RMSE: 1.1326\n",
      "[Epoch: 456 \t Valid MSE: 15.7027 \t Valid RMSE: 3.9627]\n",
      "[Epoch: 456 \t Train MSE: 0.9683 \t Train RMSE: 0.9840]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 457 [48/22032] \t Train Loss(MSE): 0.1084 \t Train RMSE: 0.3292\n",
      "Train Epoch: 457 [9648/22032] \t Train Loss(MSE): 2.4327 \t Train RMSE: 1.5597\n",
      "Train Epoch: 457 [19248/22032] \t Train Loss(MSE): 0.0868 \t Train RMSE: 0.2945\n",
      "[Epoch: 457 \t Valid MSE: 15.6048 \t Valid RMSE: 3.9503]\n",
      "[Epoch: 457 \t Train MSE: 0.9656 \t Train RMSE: 0.9826]\n",
      "Validation loss decreased (0.966488 --> 0.965593).  Saving model ...\n",
      "Train Epoch: 458 [48/22032] \t Train Loss(MSE): 0.2859 \t Train RMSE: 0.5347\n",
      "Train Epoch: 458 [9648/22032] \t Train Loss(MSE): 0.1324 \t Train RMSE: 0.3639\n",
      "Train Epoch: 458 [19248/22032] \t Train Loss(MSE): 0.0750 \t Train RMSE: 0.2738\n",
      "[Epoch: 458 \t Valid MSE: 15.5273 \t Valid RMSE: 3.9405]\n",
      "[Epoch: 458 \t Train MSE: 0.9651 \t Train RMSE: 0.9824]\n",
      "Validation loss decreased (0.965593 --> 0.965130).  Saving model ...\n",
      "Train Epoch: 459 [48/22032] \t Train Loss(MSE): 0.0761 \t Train RMSE: 0.2759\n",
      "Train Epoch: 459 [9648/22032] \t Train Loss(MSE): 0.1053 \t Train RMSE: 0.3245\n",
      "Train Epoch: 459 [19248/22032] \t Train Loss(MSE): 0.0455 \t Train RMSE: 0.2134\n",
      "[Epoch: 459 \t Valid MSE: 15.9738 \t Valid RMSE: 3.9967]\n",
      "[Epoch: 459 \t Train MSE: 0.9636 \t Train RMSE: 0.9816]\n",
      "Validation loss decreased (0.965130 --> 0.963551).  Saving model ...\n",
      "Train Epoch: 460 [48/22032] \t Train Loss(MSE): 1.6252 \t Train RMSE: 1.2748\n",
      "Train Epoch: 460 [9648/22032] \t Train Loss(MSE): 0.1136 \t Train RMSE: 0.3370\n",
      "Train Epoch: 460 [19248/22032] \t Train Loss(MSE): 2.3959 \t Train RMSE: 1.5479\n",
      "[Epoch: 460 \t Valid MSE: 15.6571 \t Valid RMSE: 3.9569]\n",
      "[Epoch: 460 \t Train MSE: 0.9671 \t Train RMSE: 0.9834]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 461 [48/22032] \t Train Loss(MSE): 0.0401 \t Train RMSE: 0.2003\n",
      "Train Epoch: 461 [9648/22032] \t Train Loss(MSE): 0.1128 \t Train RMSE: 0.3359\n",
      "Train Epoch: 461 [19248/22032] \t Train Loss(MSE): 3.5643 \t Train RMSE: 1.8879\n",
      "[Epoch: 461 \t Valid MSE: 15.5568 \t Valid RMSE: 3.9442]\n",
      "[Epoch: 461 \t Train MSE: 0.9676 \t Train RMSE: 0.9837]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 462 [48/22032] \t Train Loss(MSE): 0.0633 \t Train RMSE: 0.2517\n",
      "Train Epoch: 462 [9648/22032] \t Train Loss(MSE): 0.1047 \t Train RMSE: 0.3235\n",
      "Train Epoch: 462 [19248/22032] \t Train Loss(MSE): 5.9489 \t Train RMSE: 2.4390\n",
      "[Epoch: 462 \t Valid MSE: 15.8436 \t Valid RMSE: 3.9804]\n",
      "[Epoch: 462 \t Train MSE: 0.9614 \t Train RMSE: 0.9805]\n",
      "Validation loss decreased (0.963551 --> 0.961417).  Saving model ...\n",
      "Train Epoch: 463 [48/22032] \t Train Loss(MSE): 2.0837 \t Train RMSE: 1.4435\n",
      "Train Epoch: 463 [9648/22032] \t Train Loss(MSE): 0.0689 \t Train RMSE: 0.2625\n",
      "Train Epoch: 463 [19248/22032] \t Train Loss(MSE): 0.0483 \t Train RMSE: 0.2197\n",
      "[Epoch: 463 \t Valid MSE: 15.6612 \t Valid RMSE: 3.9574]\n",
      "[Epoch: 463 \t Train MSE: 0.9615 \t Train RMSE: 0.9806]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 464 [48/22032] \t Train Loss(MSE): 0.0951 \t Train RMSE: 0.3083\n",
      "Train Epoch: 464 [9648/22032] \t Train Loss(MSE): 0.1113 \t Train RMSE: 0.3337\n",
      "Train Epoch: 464 [19248/22032] \t Train Loss(MSE): 1.0748 \t Train RMSE: 1.0367\n",
      "[Epoch: 464 \t Valid MSE: 15.7273 \t Valid RMSE: 3.9658]\n",
      "[Epoch: 464 \t Train MSE: 0.9715 \t Train RMSE: 0.9856]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 465 [48/22032] \t Train Loss(MSE): 0.0804 \t Train RMSE: 0.2836\n",
      "Train Epoch: 465 [9648/22032] \t Train Loss(MSE): 0.0971 \t Train RMSE: 0.3117\n",
      "Train Epoch: 465 [19248/22032] \t Train Loss(MSE): 0.1397 \t Train RMSE: 0.3737\n",
      "[Epoch: 465 \t Valid MSE: 15.6209 \t Valid RMSE: 3.9523]\n",
      "[Epoch: 465 \t Train MSE: 0.9614 \t Train RMSE: 0.9805]\n",
      "Validation loss decreased (0.961417 --> 0.961408).  Saving model ...\n",
      "Train Epoch: 466 [48/22032] \t Train Loss(MSE): 0.0986 \t Train RMSE: 0.3141\n",
      "Train Epoch: 466 [9648/22032] \t Train Loss(MSE): 3.4236 \t Train RMSE: 1.8503\n",
      "Train Epoch: 466 [19248/22032] \t Train Loss(MSE): 13.3054 \t Train RMSE: 3.6477\n",
      "[Epoch: 466 \t Valid MSE: 15.6864 \t Valid RMSE: 3.9606]\n",
      "[Epoch: 466 \t Train MSE: 0.9608 \t Train RMSE: 0.9802]\n",
      "Validation loss decreased (0.961408 --> 0.960803).  Saving model ...\n",
      "Train Epoch: 467 [48/22032] \t Train Loss(MSE): 0.0460 \t Train RMSE: 0.2145\n",
      "Train Epoch: 467 [9648/22032] \t Train Loss(MSE): 0.9073 \t Train RMSE: 0.9525\n",
      "Train Epoch: 467 [19248/22032] \t Train Loss(MSE): 0.0870 \t Train RMSE: 0.2950\n",
      "[Epoch: 467 \t Valid MSE: 15.6965 \t Valid RMSE: 3.9619]\n",
      "[Epoch: 467 \t Train MSE: 0.9590 \t Train RMSE: 0.9793]\n",
      "Validation loss decreased (0.960803 --> 0.959034).  Saving model ...\n",
      "Train Epoch: 468 [48/22032] \t Train Loss(MSE): 0.5040 \t Train RMSE: 0.7100\n",
      "Train Epoch: 468 [9648/22032] \t Train Loss(MSE): 0.9301 \t Train RMSE: 0.9644\n",
      "Train Epoch: 468 [19248/22032] \t Train Loss(MSE): 1.7846 \t Train RMSE: 1.3359\n",
      "[Epoch: 468 \t Valid MSE: 15.6327 \t Valid RMSE: 3.9538]\n",
      "[Epoch: 468 \t Train MSE: 0.9661 \t Train RMSE: 0.9829]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 469 [48/22032] \t Train Loss(MSE): 0.4096 \t Train RMSE: 0.6400\n",
      "Train Epoch: 469 [9648/22032] \t Train Loss(MSE): 0.0707 \t Train RMSE: 0.2658\n",
      "Train Epoch: 469 [19248/22032] \t Train Loss(MSE): 0.1709 \t Train RMSE: 0.4134\n",
      "[Epoch: 469 \t Valid MSE: 15.6576 \t Valid RMSE: 3.9570]\n",
      "[Epoch: 469 \t Train MSE: 0.9676 \t Train RMSE: 0.9837]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 470 [48/22032] \t Train Loss(MSE): 0.0595 \t Train RMSE: 0.2439\n",
      "Train Epoch: 470 [9648/22032] \t Train Loss(MSE): 0.1198 \t Train RMSE: 0.3461\n",
      "Train Epoch: 470 [19248/22032] \t Train Loss(MSE): 0.0768 \t Train RMSE: 0.2771\n",
      "[Epoch: 470 \t Valid MSE: 15.6451 \t Valid RMSE: 3.9554]\n",
      "[Epoch: 470 \t Train MSE: 0.9602 \t Train RMSE: 0.9799]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 471 [48/22032] \t Train Loss(MSE): 0.0863 \t Train RMSE: 0.2938\n",
      "Train Epoch: 471 [9648/22032] \t Train Loss(MSE): 0.1399 \t Train RMSE: 0.3741\n",
      "Train Epoch: 471 [19248/22032] \t Train Loss(MSE): 0.1722 \t Train RMSE: 0.4150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 471 \t Valid MSE: 15.6949 \t Valid RMSE: 3.9617]\n",
      "[Epoch: 471 \t Train MSE: 0.9599 \t Train RMSE: 0.9797]\n",
      "EarlyStopping counter: 4 out of 40\n",
      "Train Epoch: 472 [48/22032] \t Train Loss(MSE): 0.1991 \t Train RMSE: 0.4462\n",
      "Train Epoch: 472 [9648/22032] \t Train Loss(MSE): 12.0156 \t Train RMSE: 3.4663\n",
      "Train Epoch: 472 [19248/22032] \t Train Loss(MSE): 0.0574 \t Train RMSE: 0.2396\n",
      "[Epoch: 472 \t Valid MSE: 15.5881 \t Valid RMSE: 3.9482]\n",
      "[Epoch: 472 \t Train MSE: 0.9596 \t Train RMSE: 0.9796]\n",
      "EarlyStopping counter: 5 out of 40\n",
      "Train Epoch: 473 [48/22032] \t Train Loss(MSE): 0.0660 \t Train RMSE: 0.2569\n",
      "Train Epoch: 473 [9648/22032] \t Train Loss(MSE): 0.0649 \t Train RMSE: 0.2547\n",
      "Train Epoch: 473 [19248/22032] \t Train Loss(MSE): 0.1184 \t Train RMSE: 0.3441\n",
      "[Epoch: 473 \t Valid MSE: 16.3149 \t Valid RMSE: 4.0392]\n",
      "[Epoch: 473 \t Train MSE: 0.9612 \t Train RMSE: 0.9804]\n",
      "EarlyStopping counter: 6 out of 40\n",
      "Train Epoch: 474 [48/22032] \t Train Loss(MSE): 0.7025 \t Train RMSE: 0.8382\n",
      "Train Epoch: 474 [9648/22032] \t Train Loss(MSE): 1.1782 \t Train RMSE: 1.0854\n",
      "Train Epoch: 474 [19248/22032] \t Train Loss(MSE): 0.1449 \t Train RMSE: 0.3807\n",
      "[Epoch: 474 \t Valid MSE: 15.6784 \t Valid RMSE: 3.9596]\n",
      "[Epoch: 474 \t Train MSE: 0.9615 \t Train RMSE: 0.9806]\n",
      "EarlyStopping counter: 7 out of 40\n",
      "Train Epoch: 475 [48/22032] \t Train Loss(MSE): 4.3036 \t Train RMSE: 2.0745\n",
      "Train Epoch: 475 [9648/22032] \t Train Loss(MSE): 3.5046 \t Train RMSE: 1.8720\n",
      "Train Epoch: 475 [19248/22032] \t Train Loss(MSE): 0.1506 \t Train RMSE: 0.3880\n",
      "[Epoch: 475 \t Valid MSE: 15.5687 \t Valid RMSE: 3.9457]\n",
      "[Epoch: 475 \t Train MSE: 0.9661 \t Train RMSE: 0.9829]\n",
      "EarlyStopping counter: 8 out of 40\n",
      "Train Epoch: 476 [48/22032] \t Train Loss(MSE): 0.0528 \t Train RMSE: 0.2297\n",
      "Train Epoch: 476 [9648/22032] \t Train Loss(MSE): 0.0751 \t Train RMSE: 0.2741\n",
      "Train Epoch: 476 [19248/22032] \t Train Loss(MSE): 0.1402 \t Train RMSE: 0.3745\n",
      "[Epoch: 476 \t Valid MSE: 15.7019 \t Valid RMSE: 3.9626]\n",
      "[Epoch: 476 \t Train MSE: 0.9590 \t Train RMSE: 0.9793]\n",
      "Validation loss decreased (0.959034 --> 0.959002).  Saving model ...\n",
      "Train Epoch: 477 [48/22032] \t Train Loss(MSE): 0.0747 \t Train RMSE: 0.2733\n",
      "Train Epoch: 477 [9648/22032] \t Train Loss(MSE): 2.2285 \t Train RMSE: 1.4928\n",
      "Train Epoch: 477 [19248/22032] \t Train Loss(MSE): 0.1027 \t Train RMSE: 0.3205\n",
      "[Epoch: 477 \t Valid MSE: 15.7275 \t Valid RMSE: 3.9658]\n",
      "[Epoch: 477 \t Train MSE: 0.9567 \t Train RMSE: 0.9781]\n",
      "Validation loss decreased (0.959002 --> 0.956722).  Saving model ...\n",
      "Train Epoch: 478 [48/22032] \t Train Loss(MSE): 0.0419 \t Train RMSE: 0.2048\n",
      "Train Epoch: 478 [9648/22032] \t Train Loss(MSE): 0.0824 \t Train RMSE: 0.2871\n",
      "Train Epoch: 478 [19248/22032] \t Train Loss(MSE): 0.1360 \t Train RMSE: 0.3688\n",
      "[Epoch: 478 \t Valid MSE: 15.7000 \t Valid RMSE: 3.9623]\n",
      "[Epoch: 478 \t Train MSE: 0.9613 \t Train RMSE: 0.9805]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 479 [48/22032] \t Train Loss(MSE): 0.0658 \t Train RMSE: 0.2566\n",
      "Train Epoch: 479 [9648/22032] \t Train Loss(MSE): 6.4430 \t Train RMSE: 2.5383\n",
      "Train Epoch: 479 [19248/22032] \t Train Loss(MSE): 0.0850 \t Train RMSE: 0.2916\n",
      "[Epoch: 479 \t Valid MSE: 15.5840 \t Valid RMSE: 3.9477]\n",
      "[Epoch: 479 \t Train MSE: 0.9615 \t Train RMSE: 0.9806]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 480 [48/22032] \t Train Loss(MSE): 0.1564 \t Train RMSE: 0.3955\n",
      "Train Epoch: 480 [9648/22032] \t Train Loss(MSE): 0.5305 \t Train RMSE: 0.7284\n",
      "Train Epoch: 480 [19248/22032] \t Train Loss(MSE): 2.5197 \t Train RMSE: 1.5874\n",
      "[Epoch: 480 \t Valid MSE: 15.6685 \t Valid RMSE: 3.9583]\n",
      "[Epoch: 480 \t Train MSE: 0.9567 \t Train RMSE: 0.9781]\n",
      "Validation loss decreased (0.956722 --> 0.956659).  Saving model ...\n",
      "Train Epoch: 481 [48/22032] \t Train Loss(MSE): 0.0755 \t Train RMSE: 0.2748\n",
      "Train Epoch: 481 [9648/22032] \t Train Loss(MSE): 0.1389 \t Train RMSE: 0.3728\n",
      "Train Epoch: 481 [19248/22032] \t Train Loss(MSE): 4.9355 \t Train RMSE: 2.2216\n",
      "[Epoch: 481 \t Valid MSE: 15.6834 \t Valid RMSE: 3.9602]\n",
      "[Epoch: 481 \t Train MSE: 0.9598 \t Train RMSE: 0.9797]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 482 [48/22032] \t Train Loss(MSE): 0.1968 \t Train RMSE: 0.4436\n",
      "Train Epoch: 482 [9648/22032] \t Train Loss(MSE): 0.1093 \t Train RMSE: 0.3306\n",
      "Train Epoch: 482 [19248/22032] \t Train Loss(MSE): 0.0892 \t Train RMSE: 0.2986\n",
      "[Epoch: 482 \t Valid MSE: 15.7081 \t Valid RMSE: 3.9633]\n",
      "[Epoch: 482 \t Train MSE: 0.9554 \t Train RMSE: 0.9774]\n",
      "Validation loss decreased (0.956659 --> 0.955353).  Saving model ...\n",
      "Train Epoch: 483 [48/22032] \t Train Loss(MSE): 2.3291 \t Train RMSE: 1.5261\n",
      "Train Epoch: 483 [9648/22032] \t Train Loss(MSE): 0.1574 \t Train RMSE: 0.3967\n",
      "Train Epoch: 483 [19248/22032] \t Train Loss(MSE): 0.0825 \t Train RMSE: 0.2872\n",
      "[Epoch: 483 \t Valid MSE: 15.6645 \t Valid RMSE: 3.9578]\n",
      "[Epoch: 483 \t Train MSE: 0.9602 \t Train RMSE: 0.9799]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 484 [48/22032] \t Train Loss(MSE): 0.1028 \t Train RMSE: 0.3207\n",
      "Train Epoch: 484 [9648/22032] \t Train Loss(MSE): 0.0984 \t Train RMSE: 0.3138\n",
      "Train Epoch: 484 [19248/22032] \t Train Loss(MSE): 1.8663 \t Train RMSE: 1.3661\n",
      "[Epoch: 484 \t Valid MSE: 15.7628 \t Valid RMSE: 3.9702]\n",
      "[Epoch: 484 \t Train MSE: 0.9533 \t Train RMSE: 0.9764]\n",
      "Validation loss decreased (0.955353 --> 0.953306).  Saving model ...\n",
      "Train Epoch: 485 [48/22032] \t Train Loss(MSE): 0.1320 \t Train RMSE: 0.3634\n",
      "Train Epoch: 485 [9648/22032] \t Train Loss(MSE): 0.0731 \t Train RMSE: 0.2705\n",
      "Train Epoch: 485 [19248/22032] \t Train Loss(MSE): 0.0736 \t Train RMSE: 0.2712\n",
      "[Epoch: 485 \t Valid MSE: 15.7368 \t Valid RMSE: 3.9670]\n",
      "[Epoch: 485 \t Train MSE: 0.9548 \t Train RMSE: 0.9771]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 486 [48/22032] \t Train Loss(MSE): 0.2073 \t Train RMSE: 0.4553\n",
      "Train Epoch: 486 [9648/22032] \t Train Loss(MSE): 0.1134 \t Train RMSE: 0.3368\n",
      "Train Epoch: 486 [19248/22032] \t Train Loss(MSE): 0.1820 \t Train RMSE: 0.4267\n",
      "[Epoch: 486 \t Valid MSE: 15.6709 \t Valid RMSE: 3.9587]\n",
      "[Epoch: 486 \t Train MSE: 0.9576 \t Train RMSE: 0.9786]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 487 [48/22032] \t Train Loss(MSE): 0.0757 \t Train RMSE: 0.2751\n",
      "Train Epoch: 487 [9648/22032] \t Train Loss(MSE): 0.0825 \t Train RMSE: 0.2871\n",
      "Train Epoch: 487 [19248/22032] \t Train Loss(MSE): 0.7216 \t Train RMSE: 0.8495\n",
      "[Epoch: 487 \t Valid MSE: 15.7045 \t Valid RMSE: 3.9629]\n",
      "[Epoch: 487 \t Train MSE: 0.9566 \t Train RMSE: 0.9780]\n",
      "EarlyStopping counter: 3 out of 40\n",
      "Train Epoch: 488 [48/22032] \t Train Loss(MSE): 0.0819 \t Train RMSE: 0.2862\n",
      "Train Epoch: 488 [9648/22032] \t Train Loss(MSE): 0.0731 \t Train RMSE: 0.2704\n",
      "Train Epoch: 488 [19248/22032] \t Train Loss(MSE): 0.1380 \t Train RMSE: 0.3715\n",
      "[Epoch: 488 \t Valid MSE: 15.7475 \t Valid RMSE: 3.9683]\n",
      "[Epoch: 488 \t Train MSE: 0.9520 \t Train RMSE: 0.9757]\n",
      "Validation loss decreased (0.953306 --> 0.952010).  Saving model ...\n",
      "Train Epoch: 489 [48/22032] \t Train Loss(MSE): 0.1033 \t Train RMSE: 0.3214\n",
      "Train Epoch: 489 [9648/22032] \t Train Loss(MSE): 0.1196 \t Train RMSE: 0.3459\n",
      "Train Epoch: 489 [19248/22032] \t Train Loss(MSE): 0.0653 \t Train RMSE: 0.2556\n",
      "[Epoch: 489 \t Valid MSE: 15.7409 \t Valid RMSE: 3.9675]\n",
      "[Epoch: 489 \t Train MSE: 0.9518 \t Train RMSE: 0.9756]\n",
      "Validation loss decreased (0.952010 --> 0.951792).  Saving model ...\n",
      "Train Epoch: 490 [48/22032] \t Train Loss(MSE): 0.0617 \t Train RMSE: 0.2485\n",
      "Train Epoch: 490 [9648/22032] \t Train Loss(MSE): 0.1571 \t Train RMSE: 0.3964\n",
      "Train Epoch: 490 [19248/22032] \t Train Loss(MSE): 0.0705 \t Train RMSE: 0.2655\n",
      "[Epoch: 490 \t Valid MSE: 15.7083 \t Valid RMSE: 3.9634]\n",
      "[Epoch: 490 \t Train MSE: 0.9527 \t Train RMSE: 0.9760]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 491 [48/22032] \t Train Loss(MSE): 0.0861 \t Train RMSE: 0.2934\n",
      "Train Epoch: 491 [9648/22032] \t Train Loss(MSE): 0.0817 \t Train RMSE: 0.2858\n",
      "Train Epoch: 491 [19248/22032] \t Train Loss(MSE): 0.0755 \t Train RMSE: 0.2747\n",
      "[Epoch: 491 \t Valid MSE: 15.7824 \t Valid RMSE: 3.9727]\n",
      "[Epoch: 491 \t Train MSE: 0.9497 \t Train RMSE: 0.9745]\n",
      "Validation loss decreased (0.951792 --> 0.949706).  Saving model ...\n",
      "Train Epoch: 492 [48/22032] \t Train Loss(MSE): 2.0480 \t Train RMSE: 1.4311\n",
      "Train Epoch: 492 [9648/22032] \t Train Loss(MSE): 0.1193 \t Train RMSE: 0.3454\n",
      "Train Epoch: 492 [19248/22032] \t Train Loss(MSE): 0.5667 \t Train RMSE: 0.7528\n",
      "[Epoch: 492 \t Valid MSE: 15.7081 \t Valid RMSE: 3.9633]\n",
      "[Epoch: 492 \t Train MSE: 0.9522 \t Train RMSE: 0.9758]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 493 [48/22032] \t Train Loss(MSE): 1.8176 \t Train RMSE: 1.3482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 493 [9648/22032] \t Train Loss(MSE): 2.7563 \t Train RMSE: 1.6602\n",
      "Train Epoch: 493 [19248/22032] \t Train Loss(MSE): 2.0703 \t Train RMSE: 1.4389\n",
      "[Epoch: 493 \t Valid MSE: 15.8291 \t Valid RMSE: 3.9786]\n",
      "[Epoch: 493 \t Train MSE: 0.9480 \t Train RMSE: 0.9736]\n",
      "Validation loss decreased (0.949706 --> 0.947983).  Saving model ...\n",
      "Train Epoch: 494 [48/22032] \t Train Loss(MSE): 0.1198 \t Train RMSE: 0.3461\n",
      "Train Epoch: 494 [9648/22032] \t Train Loss(MSE): 2.2793 \t Train RMSE: 1.5097\n",
      "Train Epoch: 494 [19248/22032] \t Train Loss(MSE): 9.0043 \t Train RMSE: 3.0007\n",
      "[Epoch: 494 \t Valid MSE: 15.8339 \t Valid RMSE: 3.9792]\n",
      "[Epoch: 494 \t Train MSE: 0.9513 \t Train RMSE: 0.9753]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 495 [48/22032] \t Train Loss(MSE): 0.1031 \t Train RMSE: 0.3211\n",
      "Train Epoch: 495 [9648/22032] \t Train Loss(MSE): 0.0726 \t Train RMSE: 0.2695\n",
      "Train Epoch: 495 [19248/22032] \t Train Loss(MSE): 0.1112 \t Train RMSE: 0.3335\n",
      "[Epoch: 495 \t Valid MSE: 15.9677 \t Valid RMSE: 3.9960]\n",
      "[Epoch: 495 \t Train MSE: 0.9523 \t Train RMSE: 0.9759]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 496 [48/22032] \t Train Loss(MSE): 0.2270 \t Train RMSE: 0.4764\n",
      "Train Epoch: 496 [9648/22032] \t Train Loss(MSE): 0.0900 \t Train RMSE: 0.3000\n",
      "Train Epoch: 496 [19248/22032] \t Train Loss(MSE): 0.0911 \t Train RMSE: 0.3018\n",
      "[Epoch: 496 \t Valid MSE: 15.6134 \t Valid RMSE: 3.9514]\n",
      "[Epoch: 496 \t Train MSE: 0.9477 \t Train RMSE: 0.9735]\n",
      "Validation loss decreased (0.947983 --> 0.947743).  Saving model ...\n",
      "Train Epoch: 497 [48/22032] \t Train Loss(MSE): 0.0567 \t Train RMSE: 0.2380\n",
      "Train Epoch: 497 [9648/22032] \t Train Loss(MSE): 1.7171 \t Train RMSE: 1.3104\n",
      "Train Epoch: 497 [19248/22032] \t Train Loss(MSE): 0.3859 \t Train RMSE: 0.6212\n",
      "[Epoch: 497 \t Valid MSE: 16.4546 \t Valid RMSE: 4.0564]\n",
      "[Epoch: 497 \t Train MSE: 0.9527 \t Train RMSE: 0.9761]\n",
      "EarlyStopping counter: 1 out of 40\n",
      "Train Epoch: 498 [48/22032] \t Train Loss(MSE): 0.0681 \t Train RMSE: 0.2609\n",
      "Train Epoch: 498 [9648/22032] \t Train Loss(MSE): 0.0833 \t Train RMSE: 0.2886\n",
      "Train Epoch: 498 [19248/22032] \t Train Loss(MSE): 2.3667 \t Train RMSE: 1.5384\n",
      "[Epoch: 498 \t Valid MSE: 15.7536 \t Valid RMSE: 3.9691]\n",
      "[Epoch: 498 \t Train MSE: 0.9521 \t Train RMSE: 0.9757]\n",
      "EarlyStopping counter: 2 out of 40\n",
      "Train Epoch: 499 [48/22032] \t Train Loss(MSE): 0.0508 \t Train RMSE: 0.2254\n",
      "Train Epoch: 499 [9648/22032] \t Train Loss(MSE): 0.8249 \t Train RMSE: 0.9082\n",
      "Train Epoch: 499 [19248/22032] \t Train Loss(MSE): 0.0875 \t Train RMSE: 0.2958\n",
      "[Epoch: 499 \t Valid MSE: 15.9312 \t Valid RMSE: 3.9914]\n",
      "[Epoch: 499 \t Train MSE: 0.9421 \t Train RMSE: 0.9706]\n",
      "Validation loss decreased (0.947743 --> 0.942132).  Saving model ...\n",
      "Train Epoch: 500 [48/22032] \t Train Loss(MSE): 0.0840 \t Train RMSE: 0.2899\n",
      "Train Epoch: 500 [9648/22032] \t Train Loss(MSE): 0.8915 \t Train RMSE: 0.9442\n",
      "Train Epoch: 500 [19248/22032] \t Train Loss(MSE): 0.0576 \t Train RMSE: 0.2400\n",
      "[Epoch: 500 \t Valid MSE: 15.6893 \t Valid RMSE: 3.9610]\n",
      "[Epoch: 500 \t Train MSE: 0.9504 \t Train RMSE: 0.9749]\n",
      "EarlyStopping counter: 1 out of 40\n"
     ]
    }
   ],
   "source": [
    "Epoch = 500\n",
    "best_rmse = 99999\n",
    "best_train_rmse = 99999\n",
    "\n",
    "train_mse_list = []\n",
    "train_rmse_list = []\n",
    "valid_mse_list = []\n",
    "valid_rmse_list = []\n",
    "\n",
    "for epoch in range(1,(Epoch+1)):\n",
    "    train_mse, train_rmse = train(model, train_dataloader, 200)\n",
    "    valid_mse, valid_rmse = evaluate(model, valid_dataloader)\n",
    "\n",
    "    print(\"[Epoch: {} \\t Valid MSE: {:.4f} \\t Valid RMSE: {:.4f}]\".format(epoch, valid_mse, valid_rmse))\n",
    "    print(\"[Epoch: {} \\t Train MSE: {:.4f} \\t Train RMSE: {:.4f}]\".format(epoch, train_mse, train_rmse))\n",
    "    \n",
    "    scheduler.step(train_mse)       \n",
    "    # Save model\n",
    "    if train_rmse < best_train_rmse:\n",
    "        path = \"./weights/ODD_LSTM_512_Hsw.pth\"\n",
    "        torch.save(model.state_dict(), path) # 모델의 가중치만 저장 구조는 저장 x..?\n",
    "        best_rmse = valid_rmse\n",
    "        best_train_rmse = train_rmse\n",
    "        \n",
    "    train_mse_list.append(train_mse)\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    valid_mse_list.append(valid_mse)\n",
    "    valid_rmse_list.append(valid_rmse)\n",
    "    \n",
    "    early_stopping(train_mse, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid best: 3.991388384478126\n",
      "Train best: 0.9706346607819986\n"
     ]
    }
   ],
   "source": [
    "print('Valid best:',best_rmse)\n",
    "print('Train best:',best_train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(train_mse_list, ls='-', color='blue', label='train')\n",
    "ax1.set_ylim(0,30)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(valid_mse_list, ls='--', color='red', label='valid')\n",
    "ax2.set_ylim(0,30)\n",
    "\n",
    "ax1.set_title('MSE error')\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(train_rmse_list, ls='-', color='blue', label='train')\n",
    "ax1.set_ylim(0,7)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(valid_rmse_list, ls='--', color='red', label='valid')\n",
    "ax2.set_ylim(0,7)\n",
    "ax1.set_title('RMSE error')\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=len(df_train), shuffle=False)\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    train_pred = batch[0]\n",
    "predict_zloc = model(train_pred.reshape(-1,1,input_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zloc</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.41</td>\n",
       "      <td>8.293418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.49</td>\n",
       "      <td>58.325680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.38</td>\n",
       "      <td>34.295490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.22</td>\n",
       "      <td>13.232427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.26</td>\n",
       "      <td>38.895786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51.17</td>\n",
       "      <td>51.228741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.02</td>\n",
       "      <td>23.112610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.22</td>\n",
       "      <td>48.177288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.73</td>\n",
       "      <td>31.475208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.72</td>\n",
       "      <td>19.530210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zloc    predict\n",
       "0   8.41   8.293418\n",
       "1  58.49  58.325680\n",
       "2  34.38  34.295490\n",
       "3  13.22  13.232427\n",
       "4  38.26  38.895786\n",
       "5  51.17  51.228741\n",
       "6  23.02  23.112610\n",
       "7  48.22  48.177288\n",
       "8  31.73  31.475208\n",
       "9  19.72  19.530210"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['predict'] = predict_zloc.cpu().detach().numpy()\n",
    "df_train[['zloc','predict']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.116582\n",
       "1        0.164320\n",
       "2        0.084510\n",
       "3        0.012427\n",
       "4        0.635786\n",
       "           ...   \n",
       "22017    0.046696\n",
       "22018    0.144038\n",
       "22019    0.257161\n",
       "22020    0.974914\n",
       "22021    0.049277\n",
       "Length: 22022, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "abs0 = np.abs(df_train.zloc-df_train.predict)\n",
    "abs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2738130705142891"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs0/len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zloc_Estimaotor(\n",
       "  (rnn): LSTM(14, 512, num_layers=3, batch_first=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): Hardswish()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): Hardswish()\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): Hardswish()\n",
       "    (8): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치 가져오기\n",
    "model = Zloc_Estimaotor(input_dim, hidden_dim,layer_dim)\n",
    "model.load_state_dict(torch.load('./weights/ODD_LSTM_512_Hsw.pth'))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 15.408349 \t Test RMSE: 3.925347\n"
     ]
    }
   ],
   "source": [
    "test_mse, test_rmse = evaluate(model, test_dataloader)\n",
    "print('Test MSE: {:4f} \\t Test RMSE: {:4f}'.format(test_mse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look dataset\n",
    "for idx, batch in enumerate(test_dataloader):\n",
    "    if idx == 1:\n",
    "        break\n",
    "    test_pred = batch[0]\n",
    "predict_zloc = model(test_pred.reshape(-1,1,input_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zloc</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.91</td>\n",
       "      <td>40.591579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.82</td>\n",
       "      <td>33.741894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.98</td>\n",
       "      <td>6.204111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.39</td>\n",
       "      <td>13.591003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.04</td>\n",
       "      <td>13.441332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.00</td>\n",
       "      <td>19.946676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.09</td>\n",
       "      <td>20.534128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.50</td>\n",
       "      <td>48.688763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.45</td>\n",
       "      <td>22.787661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51.44</td>\n",
       "      <td>50.998943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zloc    predict\n",
       "0  44.91  40.591579\n",
       "1  33.82  33.741894\n",
       "2   3.98   6.204111\n",
       "3  11.39  13.591003\n",
       "4  13.04  13.441332\n",
       "5  21.00  19.946676\n",
       "6  21.09  20.534128\n",
       "7  48.50  48.688763\n",
       "8  22.45  22.787661\n",
       "9  51.44  50.998943"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predict'] = predict_zloc.cpu().detach().numpy()\n",
    "df_test[['zloc','predict']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4.318421\n",
       "1        0.078106\n",
       "2        2.224111\n",
       "3        2.201003\n",
       "4        0.401332\n",
       "          ...    \n",
       "4714     1.520321\n",
       "4715     2.290079\n",
       "4716     1.826078\n",
       "4717     1.316422\n",
       "4718    16.246003\n",
       "Length: 4719, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "abs0 = np.abs(df_test.zloc-df_test.predict)\n",
    "abs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.087372659827521"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs0/len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3GgQX9wAHsY2zHAbVwAG/",
   "name": "DistanceEstimator.ipynb",
   "provenance": [
    {
     "file_id": "1WN5OSA-TXiMkTLDr9xyt2F7Z_Hd16-b4",
     "timestamp": 1649567852353
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
